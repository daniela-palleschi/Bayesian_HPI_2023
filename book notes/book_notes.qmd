---
title: "Chapter notes"
author: "Daniela Palleschi"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
    number-sections: true
    number-depth: 3
    code-overflow: wrap
editor_options: 
  chunk_output_type: console
bibliography: references.json
biblio-style: apalike
---

These notes are based on @nicenboim_introduction_nodate, both from a PDF version supplied by the authors and the html version available [here](https://vasishth.github.io/bayescogsci/book/) (accessed in early 2023). Much of the notes are taken verbatim from the book, as are code snippets.

::: {#refs custom-style="Bibliography"}
:::


```{r, eval = T, echo = F, message = F}
# Create references.json file based on the citations in this script
rbbt::bbt_update_bib("book_notes.qmd")
```

# Set up{-}

```{r, results = "hide", warning=F,message=F,error=F}
# set global knit options
knitr::opts_chunk$set(echo = T,
                      eval = T,
                      error = F,
                      warning = F,
                      message = F,
                      cache = T
                      )

# suppress scientific notation
options(scipen=999)

# load packages
## create list of package names
packages <- c( #"SIN", # this package was removed from the CRAN repository
               "MASS", "dplyr", "tidyr", "purrr", "extraDistr", "ggplot2", "loo", "bridgesampling", "brms", "bayesplot", "tictoc", "hypr", "bcogsci", "papaja", "grid", "kableExtra", "gridExtra", "lme4", "cowplot", "pdftools", "cmdstanr", "rootSolve", "rstan"
  )

# NB: if you haven't already installed bcogsci through devtools, it won't be loaded
## Now load or install & load all
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)

# this is also required, taken from the textbook

## Save compiled models:
rstan_options(auto_write = FALSE)
## Parallelize the chains using all the cores:
options(mc.cores = parallel::detectCores())
# To solve some conflicts between packages
select <- dplyr::select
extract <- rstan::extract
```

# Ch. 1 - Intro

- given some data, how to use Bayesâ€™ theorem to ***quantify uncertainty about our belief*** regarding a scientific question of interest
- topics to be understood:
  - the basic concepts behind probability
  - the concept of random variables
  - probability distributions
  - the concept of likelihood

## Probability

Frequency-based versus uncertain-belief perspective of probability:

1. repeatable events, like rolling a die and getting a 6, are *frequentist* because **probability** is related to the *frequency* at which we'd observe an outcome given repeated observations
2. one-of-a-kind events, like earthquakes, don't work with this idea of probability
  - the probability of an earthquake expresses our *uncertainty* about an event happening
  - we also be *uncertain* about how probable an event is: being 90% sure something is 50% likely to happen
  - this is what we're interested in: how uncertain we are of an estimate
  
In Bayesian analysis, we want to express our uncertainty about the probability of observing an outcome (*prior distribution*).

### Conditional probability and Bayes' rule

- A = "the streets are wet"
- B = "it was raining"
- P(A|B) = the probability of A given B
- P(A,B) = P(A|B)P(B) (the probability of A and B happening)

### Law of total probability

- dunno

## Discrete random variables

Generating random sequences of simulated data with a binomial distribution. Imagine a cloze task, where we consider a particular word a success (1) and any other word a failure (0). If we run the experiment 20 times with a sample size of 10, the cloze probabilities for these 20 experiments would be:

```{r, results="asis"}
rbinom(10, n = 20, prob = .5)
```

For discrete random variables such as the binomial, the probability distribution *p(y|$\theta$)* is called a probability mass function (PMF) . The PMF defines the probability of each possible outcome. With *n* = 10 trials, there are 11 possible outcomes (0, 1, 2,...10 succeses). Which outcome is most probable depends on the parameter $\theta$ that represents the probability of success. Above, we set $\theta$ to `0.5`.

### The mean and variance of the binomial distribution

In real exerimental situations we never know the true value of $\theta$ (probability of an outcome), but it can be derived from the data: *$\theta$ hat = k/n*, where *k* = number of observed successess, *n* = number of trials, and *$\theta$ hat* = observed proportion of successes. *$\theta$ hat* = ***maximum likelihood estimate*** of the true but unknown parameter *$\theta$*. Basically, the **mean** of the binomial distribution. The **variance** can also be estimated by computing *(n($\theta$))(1 - $\theta$)*. These estimates can be be used for statistical inference.

### Compute probability of a particular outcome (discrete): dibinom

`dbinom` calculates probability of *k* successes out of *n* given a particular *$\theta$*.

```{r}
dbinom(5, size = 10, prob = .5)
dbinom(5, size = 10, prob = .1)
dbinom(5, size = 10, prob = .9)
```

With continuous data, the probability of obtaining an exact value will always be zero. We'll come ot this later.

### Compute cumulative probability: pbinom

The cumulative distribution function (CDF): essentially the sum of all probabilities of the values of *k* you are interested in. E.g., the probability of observing 2 successes or fewer (0, 1, or 2) is:

```{r}
# sum of probabilities for exact k's
dbinom(0, size = 10, prob = .5) +
  dbinom(1, size = 10, prob = .5) +
  dbinom(2, size = 10, prob = .5)

# or
sum(dbinom(0:2, size = 10, prob = .5))

# or use pbinom()
pbinom(2, size = 10, prob = 0.5, lower.tail = TRUE)
# conversely, what is the $\theta$ of observing THREE successes or more?
pbinom(2, size = 10, prob = 0.5, lower.tail = F)
# or
sum(dbinom(3:10, size = 10, prob = .5))

# the probability of observing 10 or fewer successes (out of 10 trials)
pbinom(10, size = 10, prob = 0.5, lower.tail = TRUE)
```

### Compute the inverse of the CDF (quantile function): qbinom

The quantile function (the inverse CDF) obtains the value of *k* (the quantile) given the probability of obtaining *k* or less than *k* successes given some specific probability value *p*:

```{r}
# reverse of dbinom(2,10,.5) would be:
qbinom(0.0546875, size=10, prob=.5)
```

#### Generage simulated data from binomial distribtion: rbinom

```{r}
# given 1 iteration of 10 trials where p = .5, produce a random value of k
rbinom(1, 10, .5)
```

## Continuous random variables

Imagine vector of reading times data with a normal distribution, defined by its *mean* and its *sd*. The ***probability density function*** (PDF) for particular values of mean and sd (assuming a normal distribution) can be calculated using `dnorm`. The CDF can be found using `pnorm`, and the inverse CDF using `qnorm`. These are 3 different ways of looking at the infrmation.

```{r}
# p of observing a mean of 250ms when the true mean is 500 & sd = 100 (PDF)
dnorm(400,mean = 500, sd = 100)

# p of observing 400ms *or lower* when the true mean is 500 & sd = 100 (CDF)
pnorm(400,mean = 500, sd = 100)

# k with a CDF of 0.1586553 when the true mean is 500 & sd = 100 (inverse CDF)
qnorm(0.1586553, mean = 500, sd = 100)
```

Question: what is the probability of observing values between 200 and 700 from a normal distribution where mean = 500 and sd = 100?

```{r}
pnorm(700,500,100) - pnorm(200,500,100)
```

With continuous data, it is only meaningful to ask about probabilities between two point values (e.g., probability that Y lies between a and b).

What is the quantile *q* such that the probability of observing that value or something less (or more) than it is 0.975 (given the normal(500,100) distribution)?

```{r}
qnorm(0.975, m=500, sd=100)
```

Next task: generate simulated data. generate 10 data points using the `rnorm` function and use this simulated data to compute the mean and stanrdard devaition.

```{r}
x <- rnorm(10,500,100)
mean(x)
sd(x)

# can also computer lower and upper bounds of 95% CIs
quantile(x, probs = c(.025, .975))
```

### An important distinction: probability vs. densitiy in continuous random variables

The probability density function (PDF):
```{r}
# density with default m = 0 and sd = 1
dnorm(1)
```

This is not the probability of observing 1 in this distribution, as the probability of a single value in a continous distribtion will always be 0. This is becaue probability in a continuous distritubion is the ***area under the curve***, and at a single point there is no area under the curve (i.e., p = 0). The `pnorm` function allows us to find the cumulative distribution function (CDF) for the normal distribution.

For example, the probability of obseving a value etween +/-2 in a normal distribution with mean 0 and sd 1:
```{r}
pnorm(2, m = 0, sd = 1) - pnorm(-2, m = 0, sd = 1)
```

For ***discrete*** random variables, the situation is different. These have a probability **mass** function (PMF), the binomial distribution that we saw before. Here, the PMF maps the possible *y* values to the probabilities of those exact values occurring.

```{r}
dbinom(2,size=10,prob=.5)
```

### Truncating a normal distribution

Refers to positive values only (truncating at 0).

## Bivariate and multivariate distributions

Consider a case where two discrete responses were recorded: a binary yes/no response, and a Likert acceptability rating (1-7).

The ***joint probability mass function*** is the joint PMF of two random variables.

Let's play around with some such data:
```{r}
# run if package is not loaded
# library(bcogsci)
data("df_discreteagrmt")
```

#### Marginal distributions

The marginal distribution of each pair of values (let's say *x* = the binary response, *y* = the Likert response) is computed by summing up 

```{r, eval = F}
rowSums(probs)
```

***object `probs` is not defined in the book***

### Generate simulated bivariate (multivariate) data

Suppose we want to generate 100 pairs of correlated data, with correlation rho = 0.6. The two random variables have mean 0, and standard deviations 5 and 10 respectively.

```{r}
## define a variance-covariance matrix:
Sigma <- matrix(c(5^2, 5 * 10 * .6, 5 * 10 * .6, 10^2),
  byrow = FALSE, ncol = 2
)
## generate data:
u <- mvrnorm(
  n = 100,
  mu = c(0, 0),
  Sigma = Sigma
)
head(u, n = 3)
```

```{r}
# plot the data
ggplot(tibble(u_1 = u[, 1], u_2 = u[, 2]), aes(u_1, u_2)) +
  geom_point()
```

## An important concept: the marginal likelihood (integrating out a parameter)

## Exercises

1.1 Practice with pnorm Part 1

Given a normal distribution with mean 500 and standard deviation 100, use the pnorm function to calculate the probability of obtaining values between 200 and 800 from this distribution.

```{r}
pnorm(800, mean = 500, sd = 100) - pnorm(200, mean = 500, sd = 100)
```

1.2 Practice with pnorm Part 2

```{r}
pnorm(700, 800, 150, lower.tail=T)
pnorm(900, 800, 150, lower.tail=F)
pnorm(800, 800, 150, lower.tail=F)
```

1.3 Practice with pnorm Part 3

```{r}
pnorm(550,600,200,lower.tail=T)
pnorm(800,600,200,lower.tail=T) -
  pnorm(300,600,200,lower.tail=T)
pnorm(900,600,200,lower.tail=F)
```

Exercise 1.4 Practice using the qnorm function - Part 1

```{r}
qnorm(c(.1,.9),mean=1,sd=1)
```

Exercise 1.5 Practice using the qnorm function - Part 2

```{r}
qnorm(c(.1,.9), mean=650, sd=125)
```

Exercise 1.6 Practice getting summaries from samples - Part 1

```{r}
data_gen1 <- rnorm(1000, 300, 200)

# mean
mean(data_gen1)
# sd
sd(data_gen1)

# q1 and q2
qnorm(c(.1,.9), mean(data_gen1), sd(data_gen1))

hist(data_gen1)
```

Exercise 1.7 Practice getting summaries from samples - Part 2

```{r}
# generate data with truncated normal distribution
data_gen1 <- rtnorm(1000, 300, 200, a = 0)

# mean
mean(data_gen1)
# sd
sd(data_gen1)

# q1 and q2
qnorm(c(.1,.9), mean(data_gen1), sd(data_gen1))

hist(data_gen1)
```

Exercise 1.8 Practice with a variance-covariance matrix for a bivariate distribution

# Ch. 2 - Intro to Bayesian data analysis

- simple but crucial point: the posterior distribution of a parameter is a compromise between the prior and the likelihood

## Terms {-}

- *posterior*, *p(*\$theta$*|y)*: probability distribution of the parameters conditional on the **data**
- *likelihood*, *p(y|*\$theta$*)*: the PMF or PDF expressed as a function of $\theta$
- *prior*, \$theta$: the initial probability distribution of paramters ***before seeing the data***
- *marginal likelihood, p(y)*: standardizes the posterior distribution to ensure the AUC sums to 1; it ensure the posterior is a valid probability distribution

## Bayes' Rule

- Bayes' rule: when *A* and *B* are observable discrete events (like "it has been raining" or "the streets are wet"), we can state the rule as follows:

$$
P(A\mid B) = \frac{P(B\mid A) P(A)}{P(B)}
\tag{2.1}
$$

- given a vector of data *y*, we can work out the posterior distributions of parameters of interest which we represent as the vector of parameters $\theta$
- to do this, we can re-write equation 2.1 as 2.2:

$$
p(\boldsymbol{\Theta}|\boldsymbol{y}) = \cfrac{ p(\boldsymbol{y}|\boldsymbol{\Theta}) \cdot p(\boldsymbol{\Theta}) }{p(\boldsymbol{y})}
\tag{2.2}
$$

- now, Bayes' rule is writen in terms of probability distributions, where p() is the probability density function (continuous) or probability mass function (discrete)
- in words, this simply means:

$$
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
$$

## Deriving the posterior using Bayes' Rule: an analystical example

- participants are shown sentences like *It's raining. I'm going to take the...*

- if 100 participants complete the sentence, and 80 complete the sentence with *bus*, the estimated cloze probability would be $\frac{80}{100}$=0.8
   - this is the **maximum likelihood estimate** of the probability of producing the word; as this is an estimate let's add a hat: $\hat \theta$=0.8 
   
- in the frequentist paradigm, $\hat \theta$=0.8 is an estimate of an **unknown point value** $\theta$ "out there in nature"

- N.B., the variability in the estimate will be influenced by the sample size
  - if the *true* value of $\theta$ is really 0.80, we will still get some variability in the estimated proportion from a sample size of say 10 pariticpants
  - let's carry out 100 simulated experiments and compute their variability:
  
```{r}
estimated_means <- rbinom(n = 100, # generate 100 random binomial data sets
                          size = 10, # of 10 obvs each
                          prob = .8) / 10 # with prob 8, now divide these by 10 to get 100 means (k/n)

# what is the sd of these 100 means?
round(sd(estimated_means),3)
```
  
- instead, let's imagine that $\theta$ is a ***random variable***; i.e., it has a PDF associated with it
  - this PDDF would now represent our ***belief*** about possible values of $\theta$ *before we have any data*
  - e.g., if we believe from the outset that all possible values between 0 and 1 are equally likely, we would have a uniform prior of $\theta \sim \mathit{Uniform}$(0,1)
  - let's re-run our simulated experiments, but with *two* sources of variability: the data and our uncertainty associated with $\theta$
  
```{r}
theta <- runif(100, min = 0, max = 1) # simulate 100 numbers between 0:1

estimated_means <- rbinom( # generate random binomial data that has...
  n = 100, # 100x
  size = 10, # of 10 obvs
  prob = theta # with prob = theta
)/10 # divided by 10 to give us the mean for each

# sd of the means from these 100 'experiments'
round(sd(estimated_means),3)
```

- the higher standard deviation, representing variability int he estimate of the parameter, comes frm the added uncertainty from the $\theta$ parameter
  - what would happen if we had tighter expectations, i.e., a very tight PDF for $\theta$, say \theta \sim \mathit{Uniform}(0.7,0.9)?
  
```{r}
theta <- runif(100, min = 0.7, max = 0.9) # simulate 100 numbers between 0:1

estimated_means <- rbinom( # generate random binomial data that has...
  n = 100, # 100x
  size = 10, # of 10 obvs
  prob = theta # with prob = theta
)/10 # divided by 10 to give us the mean for each

# sd of the means from these 100 'experiments'
round(sd(estimated_means),3)
```
  
- the variability is smaller; so the greater the uncertainty associated with the $\theta$ parameter, the greater the variability in the data

- this is very different from the frequentist assumption that $\theta$ is a point value; in Bayesian $\theta$ is a **random variable** with a probability density/mass function associated with it
- this PDF is called a **prior distribution** and represents our prior belief or knowledge about a possible value of this parameter
- once we obtain data, these data serve to modify our prior belief about the distribution, called our **posterior distribution**

## Choosing a likelihood

- with a binomial distribution like the cloze probability (chose 'bus' or not), the PMF can be written as:

$$
p(k|n,\theta) = \binom{n}
{k} \theta^k (1-\theta)^{n-k}
\tag{2.3}
$$

- *k* = the number of times "bus" was given as an answer
- *n* = the total number of answers given
- if we collect 100 data points (*n* = 100), and find *k* = 80, we now have 2 fixed data points, *n* and *k*. The only variable is now $\theta$

$$
p(k=80 | n= 100,  \theta) = \binom{n}{k} \theta^{80} (1-\theta)^{20}
$$

- this is now a continuous function of the value of $\theta$, which can have a possible value between 0 and 1
- by contrast, the PMF of the binomial treats $\theta$ as a **fixed** value and defines a discrete distribution over the n+1 possible discrete values *k* that we can observe

- recall: the PMF and the likelihood are the same function seen from different points of view: the only difference being what is considered fixed (PMF: $\theta$, likelihood: data) and what is varying (PMF: data, likelihood: $\theta$)
  - **PMF**: $\theta$ is fixed, data varies
  - **likelihood function**: data is fixed, $\theta$ varies

Now we go back to our main foal: using Bayes' rule to find out the posterior distribution of $\theta$ given our data: *p(*$\theta$*|n,k). We first need to define a prior distribution over the parameter $theta$, thereby expressing our prior uncertainty about plausible values of $\theta$
  
## Choosinga a prior for $\theta$

- priors for a $\theta$ in a binominal distribution: the parameter $\theta$ is a random variable with a PDF whose range is [0,1]

- the ***beta distribution***, which is a PDF for a continuous random variable, is commonly used as a prior for parameters representing probabilities, and has the following PDF:

$$
p(\theta|a,b)=  \frac{1}{B(a,b)} \theta^{a - 1} (1-\theta)^{b-1}   
\tag{2.4}
$$

- *B(a,b)* is a normalising constant that ensures that the area under the curve sums to 1, so that *p(*$\theta$|*a,b)* is a probability
- the beta distribution's paramters *a* and *b* express our prior beliefs about the probability of a success:
  - *a* = number of "successes" (answering "bus")
  - *b* = number of "failures" (not answering "bus")
- the different beta distributions shapes given different values of a and b are shown below (in r, a = `shape1` and b = `shape2`)

```{r}
plot(function(x) 
  dbeta(x,shape1=1,shape2=1), 0,1,
      main = "Beta density",
  ylab="density",xlab="theta",ylim=c(0,3))

text(.5,1.1,"a=1,b=1")

plot(function(x) 
  dbeta(x,shape1=3,shape2=3),0,1,add=TRUE)
text(.5,1.6,"a=3,b=3")


plot(function(x) 
  dbeta(x,shape1=6,shape2=6),0,1,add=TRUE)
text(.5,2.8,"a=6,b=6")

plot(function(x) 
  dbeta(x,shape1=2,shape2=6),0,1,add=TRUE)
text(.15,2.9,"a=2,b=6")

plot(function(x) 
  dbeta(x,shape1=6,shape2=2),0,1,add=TRUE)
text(.85,2.9,"a=6,b=2")
```

- to express our uncertainty, we could compute 95\% ***credible*** intervales, i.e., the region over which we are 95\% certain the value of the parameter lies

```{r}
# compute 95% CrIs
round(
  qbeta(# at what quantiles (points on the x-axis)
  c(.025,.975), # would the PDF cover 95% AUC
  shape1 = 4, # where a = 4
  shape2 = 4), # and b = 4
  3) # rounded to 3 decimal points
```

:::{.callout-tip}
## Sidebar
- in a unimodal distribution, one could use the narrowest interval that contains the mode (the **highest posterior density interval** (HDI))
- in skewed posterior distirbutions, the equal-tailed CrI and the HDI will not be identical, because the HDI will have unequal tail probabilities; this book uses the equal-tailed interval (like we computed above) because it's the standard output in `Stan` and `brms`
:::

- if we were to choose *a* = 10 and *b* = 10, we would still be assuming a prior that "bus" is just as likely as some other word, but now our prior uncertainty about this mean is lower, meaning we have a tighter prior:

```{r}
# compute 95% CrIs
round(
  qbeta(# at what quantiles (points on the x-axis)
  c(.025,.975), # would the PDF cover 95% AUC
  shape1 = 10, # where a = 4
  shape2 = 10), # and b = 4
  3) # rounded to 3 decimal points
```

- compare the AUC for the two beta distributions in Figure \ref{fig-beta2}

```{r}
#| label: fig-beta2
#| fig-cap: "Beta distributions with varying a and b values"

plot(function(x) 
  dbeta(x,shape1=4,shape2=4), 0,1,
      main = "Beta density",
  ylab="density",xlab="theta",ylim=c(0,4))
text(.5,2.35,"a=4,b=4")

plot(function(x) 
  dbeta(x,shape1=10,shape2=10),0,1,add=TRUE,
  ylab="density",xlab="theta",ylim=c(0,4))
text(.5,3.7,"a=10,b=10")
```

- but which prior should we choose? This depends on our prior knowledge
  - if we don't have much prior information, we could use *a* = *b* = 1; this is a uniform prior $\mathit{Uniform}$(0,1), often clled a ***flat***, ***non-informative***, or ***uninformative prior***
  - if we have a lot of prior knowledge or a strong belief regarding the range of plausible values for $\theta$, we can use a different set of *a* and *b* values
  - if we were to use *a* = 4 and *b* = 4, then our prior for $\theta$ would be:

$$
p(\theta) = \frac{1}{B(4,4)} \theta^{3} (1-\theta)^{3}
$$


## Using Baye's rule to computer the posterior *p(*$\theta$*|n,k)*

- recall the equation from earlier:

$$
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
$$

- now that we've got the likelihood and the prior, we can use Bayes' rule to calculate *p(*$\theta$|*n,k)*, as follows:

$$
p(\theta|n=100,k=80) = \frac{\left[\binom{100}{80} \theta^{80} \cdot (1-\theta)^{20}\right]  \times \left[\frac{1}{B(4,4)} \times \theta^{3} (1-\theta)^{3}\right]}{p(k=80)}
\tag{2.6}
$$

- constant values are those that do not depend on the unknown parameter of interest, $\theta$; so *p(k = 80)* will be a constant once we know the number of successes
  - once *k* is known, we already have several constant values

$$
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
$$

- we can gather all the constants (in the square brackets below):

$$
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
$$

- and ignore the constants for now, which will later on make the AUC sum up to 1; so now we say the posterior is proportional to the right-hand side of the equation:

$$
p(\theta|n=100,k=80) \propto   [\theta^{80} (1-\theta)^{20} \times \theta^{3} (1-\theta)^{3} ]
\tag{2.8}
$$

- in other words:

$$
\hbox{Posterior} \propto \hbox{Likelihood} \times \hbox{Prior}
$$

- now we just have to add up the exponents

$$
p(\theta|n=100,k=80) \propto   [\theta^{80+3} (1-\theta)^{20+3}] = \theta^{83} (1-\theta)^{23}
\tag{2.9}
$$

- recall that the beta distribution involves $\theta$ exponentiated to the power of *a*-1 and *b*-1 (see equation 2.4)
  - therefore, the expression in 2.9 above corresponds to a beta distribution with parameters *a* = 84 and *b* = 24 (because 83 and 23 +1 is 84 and 24)
  - all we need now is our  normalising constant to make the AUC sum to one; let's check this:
  
```{r}
PostFun <- function(theta) {
  theta^83 * (1 - theta)^23
}
(AUC <- integrate(PostFun, lower = 0, upper = 1)$value)
```

- this doesn't add up to 1, it's not a probability distribution
- but we can use it to figure out what our normalising constant is; what is the constant *k* such that the AUC sums to 1:

$$
k \int_{0}^{1} \theta^{83} (1-\theta)^{23} = 1
$$

- we know what \int_{0}^{1} \theta^{83} (1-\theta)^{23} is, because we just computed it above (and called it AUC), so:

$$
k  = \frac{1}{\int_{0}^{1} \theta^{83} (1-\theta)^{23}} = \frac{1}{AUC}
$$

- we now have the distribution or $\theta$ given the data, expressed as a PDF:

$$
p(\theta|n=100,k=80) = \frac{1}{B(83,23)} \theta^{84-1} (1-\theta)^{24-1} 
$$

- and our function will now sum to one if we divide it all by AUC

```{r}
PostFun <- function(theta) {
  theta^83 * (1 - theta)^23 / AUC
}
integrate(PostFun, lower = 0, upper = 1)$value
```

## Summary of the procedure

- we started with a binomial likelihood
  - multiplied it with the prior $\theta \sim \mathit{Beta}(4,4)$
  - obtained the posterior *p(*$\theta$|*n,k)* $\sim \mathit{Beta}(4,4)$
  - we ignored the constants when carrying out the multiplication (i.e., computer the posterior *up to proportionality*)
  - then we rescaled the posterior to become a probability distribution by including a proportionality constant (AUC)
  
- this was an example of a **conjugate** analysis: the posterior on the parameter has thes ame form (belongs to the same family of probability distributions) as the prior
- this combo of likelihood and prior is called the ***beta-binomial conjugate case***
  - conjugacy is defined as: Given the likelihood *p(y*|$\theta$*)*, if the prior *p(*$\theta$*)( results in a posterior $p(\theta|y)$ that has some form as $p(\theta)$, then we call $p(\theta)$ a conjugate prior
  
  - given a $Binomial(n,k|\theta)$ likelihood, and a $Beta(a,b)$ prior on $\theta$, the posterior will be $Beta(a + k, b + n - k)$

## Visualising the prior, likelihood, and the posterior

```{r}
k <- 80
n <- 100
## Prior
a <- 4
b <- 4
binom_lh <- function(theta) {
dbinom(x=k, size =n, prob = theta)
}
K <- integrate(f = binom_lh, lower = 0, upper = 1)$value
binom_scaled_lh <- function(theta) 1/K * binom_lh(theta)
  
p_beta <- ggplot(data = tibble(theta = c(0, 1)), aes(theta)) +
  stat_function(
    fun = dbeta,
    args = list(shape1 = a, shape2 = b),
    aes(linetype = "Prior")
  ) +
  ylab("density") +
  stat_function(
    fun = dbeta,
    args = list(shape1 = k + a, shape2 = n - k + b), aes(linetype = "Posterior")
  ) +
  stat_function(
    fun = binom_scaled_lh,
    aes(linetype = "Scaled likelihood")
  ) +
  theme_bw() +
  theme(legend.title = element_blank())
p_beta
```

- if we wanted to produce the 95\% credible interval, i.e., the range over which we are 95\% certain the true value of $\theta$ lies, give *a* = 84 and *b* = 24:

```{r}
round(
  qbeta(c(0.025, 0.975), shape1 = 84, shape2 = 24)
  ,3)
```

## The posterior distribution is ac ompromise between the prior and the likelihood

- let's take four different beta priors with increasing certainty:
  - $Beta(a = 2, b = 2)$
  - $Beta(a = 3, b = 3)$
  - $Beta(a = 6, b = 6)$
  - $Beta(a = 21, b = 21)$

- each reflects a believe that $\theta$ = 0.5 but with a varying degree of certainty
  - we can now "just" plug in the likelihood and the prior to the beta-binomial case to get the posterior:
  
$$
p(\theta | n,k) \propto p(k |n,\theta) p(\theta)
$$

- if we plot the tightest case ($a = 21, b = 21$), we see how the posterior is affected

```{r}
k <- 80
n <- 100
## Prior
a <- 21
b <- 21
binom_lh <- function(theta) {
dbinom(x=k, size =n, prob = theta)
}
K <- integrate(f = binom_lh, lower = 0, upper = 1)$value
binom_scaled_lh <- function(theta) 1/K * binom_lh(theta)
  
p_beta <- ggplot(data = tibble(theta = c(0, 1)), aes(theta)) +
  stat_function(
    fun = dbeta,
    args = list(shape1 = a, shape2 = b),
    aes(linetype = "Prior")
  ) +
  ylab("density") +
  stat_function(
    fun = dbeta,
    args = list(shape1 = k + a, shape2 = n - k + b), aes(linetype = "Posterior")
  ) +
  stat_function(
    fun = binom_scaled_lh,
    aes(linetype = "Scaled likelihood")
  ) +
  theme_bw() +
  theme(legend.title = element_blank())
p_beta
```

- we can say the following about the likelihood-prior-posterior relationship:
  - the posterior distribution is ac ompromise between the prior and the likelihood
  - for a given set of data, the great the certainty in the prior, the more heavily the posterior will be influenced by the prior mean
  - conversely, for a given set of data, the greater the **un**certainty in the prior, the more heavily the posterior will be influenced by the likelihood
  - but because *n* and *k* are included in the posterior Beta distribution ($Beta(a + k, b + n - k)$), the posterior mean will be influenced more heavily by larger sample sizes
    - sensitivity analyses can help check whether your parameter of interest is sensitive to the prior specification

## Incremental knowledge gain using prior knowledge

- we can incrementally gain information about a research question by using information from previous studies and deriving a position, and then using that posterior as a prior for the next experiment

- e.g., in the example above, we currently had a prior $Beta(4,4)$ and observed $k = 80$ successes of $n = 100$ observations, deriving a posterior $Beta(84,24)$
  - if we were to run this experiment again and had $k = 60, n = 100$, we cwould have a posterior as follows $\mathit{Beta}(a+k,b+n-k) = \mathit{Beta}(84+60,24+100-60)=\mathit{Beta}(144,64)$
  - alternatively, if we collected all this data in the first place and had a prior $Beta(4,4)$ and for data $k = 140, n = 200$, we'd have the same posterior: $\mathit{Beta}(4+140,4+200-140)=\mathit{Beta}(144,64)$

- so, we can keep building on our previous findings to inform future priors

## Summary

- we'll continue down the same path we followed in this chapter moving forward:
  1. decide on an appropriate likelihood function
  2. decide on prior for all the parameters involved in the likelihood function
  3. using this model (the likelihood and the priors) derive the posterior distribution of each parameter
  4. draw inferences about our research question basedon the posterior distribution of the parameter
  
# Ch. 3 - Computational Bayesian data analysis

- for real datasets, it was too cumbersome to do all the math to dertermine posterior distributions
  + thanks to probabilistic programming languages, we can define our models without have to do all the math
  
## Deriving the posterior through sampling

- recall the example cloze task for *It's raining, I'm going to take the...*, with the 'correct' answer *bus* ('umbrella' in the book but to me 'bus' is the most natural completion)
  + imagine 80 'successes' and 20 'failures'
  + assuming a binomial distribution as the likelihood function, and $Beta(a = 4, b = 4)$ as a prior distribution for the cloze probability
  + if we can obtain samples from the posterior distribution or $\theta$, instead of an analystically derived posterior distribution, given enough samples we will have a good *approximation* of the posterior distribution
  + '*obtain samples*' here means a situation similar to when we use `rbinom` or `rnorm` to obtain samples from a particular distribution
  + assume we used some probabilistic prgramming langauge to obtain 20,000 samples from the posterior distribution of the cloze probability $\theta$

## Bayesian regression models using Stan: brms

- because of increased computing power and probabilistic programming languages (e.g., WinBUGS, JAGS, R-INLA, pymc3, Turing, Stan), Bayesian statistics is now more popular
  + these languages allow th euser to define models without the complexities of the sampling process
  + however, they require learning a new language as te statistical model must be specified using a specific syntax
  + additionally, some knowledge of the *sampling process* is needed to correctly parametrize the models and avoid convergence issues

- Bayesian inference in `R` is possible without having the fully specify the model thanks to `stanarm` and `brms` packages
  + both packages provide Bayesian equivalents of R model-fitting functions like `(g)lmer`
  + both use Stan as the back-end for estimation and sampling

- for this part of the book we will focus on `brms`
  + it can be useful for a smooth transition from frequentist models to their Bayesian equivalents
  + it has the added benefit that the Stan code can be inspected via `brms::make_stancode()` and `brms::make_standata()`
  + users can then customatize their models or learn from the code produced internally by `brms`
  
### A simple linear model: A single subject pressing a button repeatedly

- imagine having data from a single participant repeatedly pressing the spacebar as fast as possible
  + the data are response times in imilliseconds in each trial; we want to know how long it takes to press a key for this subject
  
- let's model the data with thef ollowing assumptions:
  1. Tehre is a true (unknown) underlying time, $\mu$ ms, that the subject needs to press the psace bar
  2. There is some noise in this process
  3. The noise is normally distributed (this assumption is questionable given that response times are generally skewed, we will fix this assumption later)

This means that the likelihood for each observation $n$ will be:

$$
rt_{n} \sim Normal(\mu, \sigma)
\tag{3.2}
$$
- where $n$ = 1, ..., $N$, and $rt$ is the dependent variable (RTs in ms)
  + the variable $N$ indexes the total number of data points
  + $\mu$ indicates the *location* of the normal distirbution function; the lcoation parameter shifts the distribution left or right on the horizontal axis
  + in the *normal distribution*, the location is also the mean of the distribution
  + $\sigma$ indicates the *scale* of the distribution; as the scale decreases, the distribution gets narrower
  + for the normal distribution, the scale is also the standard deviation
  
- this same equation can be expressed as:

$$
rt_n = \mu + \varepsilon \hbox{, where } \varepsilon_n \stackrel{iid}{\sim} \mathit{Normal}(0,\sigma) \tag{3.3} 
$$
- this version of the model should be understood to mean that each data point $rt_n$ has some variability around a mean value $\mu$, and that variability has standard deviation $\sigma$
  + the term $iid$ ('independent and identically distributed') implies that each data point $rt_n$ is independently generated (i.e., not correlated with any of the other data points), and is coming from the same distribution ($Normal(\mu,\sigma)$)
  
- **Frequentist model**: that will give us the *maximu likelihood estimate* (the sample mean) of the time it takes to press the space bar
  + this owuld be enough ifnmroamtion to write the formular in `R`, `lm(rt ~ 1)`

- **Bayesian linear model**: we will also need to define *priors* for the two parameters of our model
  + let's say we know for sure that the time it takes to press a key will be positive and lower than a minute (0-60,000ms), but we don't want to make a commitment regarding which values are more likely
  + we encode what we know about the noise in the task in $\sigma$: this parameter must be positive and we'll assume any value below 2000ms is equally likely; such *flat* or *uniformative* priors are generaly strongly discouraged: it will almost never be the best approximation of what we know
  + let's start with such priors, regardless:
  
$$
\begin{aligned}
\mu &\sim \mathit{Uniform}(0, 60000) \\
\sigma &\sim \mathit{Uniform}(0, 2000) 
\end{aligned}
\tag{3.4}
$$

- load the data from the `bcogsci` package

```{r}
data("df_spacebar")
head(df_spacebar)
```

- plot the data before you do anything else; as we suspected, the data lock a bit (positively) skewed, but let's ignore that for now

```{r}
#| fig-width: 6
#| fig-align: center

df_spacebar %>%
  ggplot(aes(rt)) +
  labs(title = "Button-press data",
       x = "response times") +
  geom_density() +
  theme_bw()
```

#### Specifying the model in `brms`

- fit the model defined by equations \ref{3.2} and \ref{3.4}

```{r}
fit_press <- brm(
  rt ~ 1,
  data = df_spacebar,
  family = gaussian(),
  prior = c(
    prior(
      uniform(0, 60000),
      class = Intercept, # mean
      lb = 0,
      ub = 60000
    ),
    prior(
      uniform(0, 2000),
      class = sigma, # sd
      lb = 0,
      ub = 2000
    )
  ),
  chains = 4,
  iter = 2000,
  warmup = 1000
)
```

- some differences between this syntax and `lm()`:
  1. `family = gaussian()` makes it explicity that the underlying likelihood function is a normal distribution
    + this is implicit in `lm()`
    + the default for `brms` is `gaussian()`
    + other linking function are possible, just like in the `glm()` function
  2. `prior` takes as argument a vector of priors
    + this is optional, but we should ***always*** explicitly specify each prior; otherwise `brms` will define priors but they may or may not be appropriate
    + this is why we need `lb` (lower bound) and `upper bound` to specify the plausible range of values to sample from in cases where the distribution is restricted (e.g., reaction times cannot be negative, so `lb` must be at least 0)
  3. `chains` refers to the number of independent runs for sampling
    + default = 4
  4. `iter` refers to the number of iteratiosn that a sampler makes to sample from the posterior distribution of each paramter
    + default = 2000
  5. `warmup` refers to the number of iterations from the start of sampling that are eventually discarded
    + default = $\frac{`iter`}{2}$

- the last 3 options determine the behaviour of the sampling algorithm

#### Sampling and convergence in a nutshell

- our 4 chains start independently from each other
  + each chain "searches" for samples of the posterior distribution in a multidimensional space, where each parameter corresponds to a dimension
  + the shape of this space is determined by the priors and likelihood
  + chains start at a random location and each iteraton takes one sample each
  + when sampling begins, the samples may or may not belong to the posterior distributions of the parameters; eventually the chains end up in the vicinity of the posterior and from then on the samples will belong to the posterior
  
- therefore, 