<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daniela Palleschi">

<title>Chapter notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="book_notes_files/libs/clipboard/clipboard.min.js"></script>
<script src="book_notes_files/libs/quarto-html/quarto.js"></script>
<script src="book_notes_files/libs/quarto-html/popper.min.js"></script>
<script src="book_notes_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="book_notes_files/libs/quarto-html/anchor.min.js"></script>
<link href="book_notes_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="book_notes_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="book_notes_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="book_notes_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="book_notes_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="styles.css">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#set-up" id="toc-set-up" class="nav-link active" data-scroll-target="#set-up">Set up</a></li>
  <li><a href="#ch.-1---intro" id="toc-ch.-1---intro" class="nav-link" data-scroll-target="#ch.-1---intro"><span class="toc-section-number">1</span>  Ch. 1 - Intro</a>
  <ul class="collapse">
  <li><a href="#probability" id="toc-probability" class="nav-link" data-scroll-target="#probability"><span class="toc-section-number">1.1</span>  Probability</a>
  <ul class="collapse">
  <li><a href="#conditional-probability-and-bayes-rule" id="toc-conditional-probability-and-bayes-rule" class="nav-link" data-scroll-target="#conditional-probability-and-bayes-rule"><span class="toc-section-number">1.1.1</span>  Conditional probability and Bayes’ rule</a></li>
  <li><a href="#law-of-total-probability" id="toc-law-of-total-probability" class="nav-link" data-scroll-target="#law-of-total-probability"><span class="toc-section-number">1.1.2</span>  Law of total probability</a></li>
  </ul></li>
  <li><a href="#discrete-random-variables" id="toc-discrete-random-variables" class="nav-link" data-scroll-target="#discrete-random-variables"><span class="toc-section-number">1.2</span>  Discrete random variables</a>
  <ul class="collapse">
  <li><a href="#the-mean-and-variance-of-the-binomial-distribution" id="toc-the-mean-and-variance-of-the-binomial-distribution" class="nav-link" data-scroll-target="#the-mean-and-variance-of-the-binomial-distribution"><span class="toc-section-number">1.2.1</span>  The mean and variance of the binomial distribution</a></li>
  <li><a href="#compute-probability-of-a-particular-outcome-discrete-dibinom" id="toc-compute-probability-of-a-particular-outcome-discrete-dibinom" class="nav-link" data-scroll-target="#compute-probability-of-a-particular-outcome-discrete-dibinom"><span class="toc-section-number">1.2.2</span>  Compute probability of a particular outcome (discrete): dibinom</a></li>
  <li><a href="#compute-cumulative-probability-pbinom" id="toc-compute-cumulative-probability-pbinom" class="nav-link" data-scroll-target="#compute-cumulative-probability-pbinom"><span class="toc-section-number">1.2.3</span>  Compute cumulative probability: pbinom</a></li>
  <li><a href="#compute-the-inverse-of-the-cdf-quantile-function-qbinom" id="toc-compute-the-inverse-of-the-cdf-quantile-function-qbinom" class="nav-link" data-scroll-target="#compute-the-inverse-of-the-cdf-quantile-function-qbinom"><span class="toc-section-number">1.2.4</span>  Compute the inverse of the CDF (quantile function): qbinom</a></li>
  </ul></li>
  <li><a href="#continuous-random-variables" id="toc-continuous-random-variables" class="nav-link" data-scroll-target="#continuous-random-variables"><span class="toc-section-number">1.3</span>  Continuous random variables</a>
  <ul class="collapse">
  <li><a href="#an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" id="toc-an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" class="nav-link" data-scroll-target="#an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables"><span class="toc-section-number">1.3.1</span>  An important distinction: probability vs.&nbsp;densitiy in continuous random variables</a></li>
  <li><a href="#truncating-a-normal-distribution" id="toc-truncating-a-normal-distribution" class="nav-link" data-scroll-target="#truncating-a-normal-distribution"><span class="toc-section-number">1.3.2</span>  Truncating a normal distribution</a></li>
  </ul></li>
  <li><a href="#bivariate-and-multivariate-distributions" id="toc-bivariate-and-multivariate-distributions" class="nav-link" data-scroll-target="#bivariate-and-multivariate-distributions"><span class="toc-section-number">1.4</span>  Bivariate and multivariate distributions</a>
  <ul class="collapse">
  <li><a href="#generate-simulated-bivariate-multivariate-data" id="toc-generate-simulated-bivariate-multivariate-data" class="nav-link" data-scroll-target="#generate-simulated-bivariate-multivariate-data"><span class="toc-section-number">1.4.1</span>  Generate simulated bivariate (multivariate) data</a></li>
  </ul></li>
  <li><a href="#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" id="toc-an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" class="nav-link" data-scroll-target="#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter"><span class="toc-section-number">1.5</span>  An important concept: the marginal likelihood (integrating out a parameter)</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">1.6</span>  Exercises</a></li>
  </ul></li>
  <li><a href="#ch.-2---intro-to-bayesian-data-analysis" id="toc-ch.-2---intro-to-bayesian-data-analysis" class="nav-link" data-scroll-target="#ch.-2---intro-to-bayesian-data-analysis"><span class="toc-section-number">2</span>  Ch. 2 - Intro to Bayesian data analysis</a>
  <ul class="collapse">
  <li><a href="#terms" id="toc-terms" class="nav-link" data-scroll-target="#terms">Terms</a></li>
  <li><a href="#bayes-rule" id="toc-bayes-rule" class="nav-link" data-scroll-target="#bayes-rule"><span class="toc-section-number">2.1</span>  Bayes’ Rule</a></li>
  <li><a href="#deriving-the-posterior-using-bayes-rule-an-analystical-example" id="toc-deriving-the-posterior-using-bayes-rule-an-analystical-example" class="nav-link" data-scroll-target="#deriving-the-posterior-using-bayes-rule-an-analystical-example"><span class="toc-section-number">2.2</span>  Deriving the posterior using Bayes’ Rule: an analystical example</a></li>
  <li><a href="#choosing-a-likelihood" id="toc-choosing-a-likelihood" class="nav-link" data-scroll-target="#choosing-a-likelihood"><span class="toc-section-number">2.3</span>  Choosing a likelihood</a></li>
  <li><a href="#choosinga-a-prior-for-theta" id="toc-choosinga-a-prior-for-theta" class="nav-link" data-scroll-target="#choosinga-a-prior-for-theta"><span class="toc-section-number">2.4</span>  Choosinga a prior for <span class="math inline">\theta</span></a></li>
  <li><a href="#using-bayes-rule-to-computer-the-posterior-pthetank" id="toc-using-bayes-rule-to-computer-the-posterior-pthetank" class="nav-link" data-scroll-target="#using-bayes-rule-to-computer-the-posterior-pthetank"><span class="toc-section-number">2.5</span>  Using Baye’s rule to computer the posterior <em>p(</em><span class="math inline">\theta</span><em>|n,k)</em></a></li>
  <li><a href="#summary-of-the-procedure" id="toc-summary-of-the-procedure" class="nav-link" data-scroll-target="#summary-of-the-procedure"><span class="toc-section-number">2.6</span>  Summary of the procedure</a></li>
  <li><a href="#visualising-the-prior-likelihood-and-the-posterior" id="toc-visualising-the-prior-likelihood-and-the-posterior" class="nav-link" data-scroll-target="#visualising-the-prior-likelihood-and-the-posterior"><span class="toc-section-number">2.7</span>  Visualising the prior, likelihood, and the posterior</a></li>
  <li><a href="#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" id="toc-the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" class="nav-link" data-scroll-target="#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood"><span class="toc-section-number">2.8</span>  The posterior distribution is ac ompromise between the prior and the likelihood</a></li>
  <li><a href="#incremental-knowledge-gain-using-prior-knowledge" id="toc-incremental-knowledge-gain-using-prior-knowledge" class="nav-link" data-scroll-target="#incremental-knowledge-gain-using-prior-knowledge"><span class="toc-section-number">2.9</span>  Incremental knowledge gain using prior knowledge</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="toc-section-number">2.10</span>  Summary</a></li>
  </ul></li>
  <li><a href="#ch.-3---computational-bayesian-data-analysis" id="toc-ch.-3---computational-bayesian-data-analysis" class="nav-link" data-scroll-target="#ch.-3---computational-bayesian-data-analysis"><span class="toc-section-number">3</span>  Ch. 3 - Computational Bayesian data analysis</a>
  <ul class="collapse">
  <li><a href="#deriving-the-posterior-through-sampling" id="toc-deriving-the-posterior-through-sampling" class="nav-link" data-scroll-target="#deriving-the-posterior-through-sampling"><span class="toc-section-number">3.1</span>  Deriving the posterior through sampling</a></li>
  <li><a href="#bayesian-regression-models-using-stan-brms" id="toc-bayesian-regression-models-using-stan-brms" class="nav-link" data-scroll-target="#bayesian-regression-models-using-stan-brms"><span class="toc-section-number">3.2</span>  Bayesian regression models using Stan: brms</a>
  <ul class="collapse">
  <li><a href="#a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" id="toc-a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" class="nav-link" data-scroll-target="#a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly"><span class="toc-section-number">3.2.1</span>  A simple linear model: A single subject pressing a button repeatedly</a></li>
  </ul></li>
  <li><a href="#prior-predictive-distribution" id="toc-prior-predictive-distribution" class="nav-link" data-scroll-target="#prior-predictive-distribution"><span class="toc-section-number">3.3</span>  Prior predictive distribution</a></li>
  <li><a href="#the-influence-of-priors-sensitivity-analysis" id="toc-the-influence-of-priors-sensitivity-analysis" class="nav-link" data-scroll-target="#the-influence-of-priors-sensitivity-analysis"><span class="toc-section-number">3.4</span>  The influence of priors: sensitivity analysis</a>
  <ul class="collapse">
  <li><a href="#flat-uninformative-priors" id="toc-flat-uninformative-priors" class="nav-link" data-scroll-target="#flat-uninformative-priors"><span class="toc-section-number">3.4.1</span>  Flat, uninformative priors</a></li>
  <li><a href="#regularising-priors" id="toc-regularising-priors" class="nav-link" data-scroll-target="#regularising-priors"><span class="toc-section-number">3.4.2</span>  Regularising priors</a></li>
  <li><a href="#principled-priors" id="toc-principled-priors" class="nav-link" data-scroll-target="#principled-priors"><span class="toc-section-number">3.4.3</span>  Principled priors</a></li>
  <li><a href="#informative-priors" id="toc-informative-priors" class="nav-link" data-scroll-target="#informative-priors"><span class="toc-section-number">3.4.4</span>  Informative priors</a></li>
  </ul></li>
  <li><a href="#re-visiting-the-button-press-example-with-different-priors" id="toc-re-visiting-the-button-press-example-with-different-priors" class="nav-link" data-scroll-target="#re-visiting-the-button-press-example-with-different-priors"><span class="toc-section-number">3.5</span>  Re-visiting the button-press example with different priors</a></li>
  <li><a href="#posterior-predictive-distribution" id="toc-posterior-predictive-distribution" class="nav-link" data-scroll-target="#posterior-predictive-distribution"><span class="toc-section-number">3.6</span>  Posterior predictive distribution</a>
  <ul class="collapse">
  <li><a href="#comparing-different-likelihoods" id="toc-comparing-different-likelihoods" class="nav-link" data-scroll-target="#comparing-different-likelihoods"><span class="toc-section-number">3.6.1</span>  Comparing different likelihoods</a></li>
  <li><a href="#the-log-normal-likelihood" id="toc-the-log-normal-likelihood" class="nav-link" data-scroll-target="#the-log-normal-likelihood"><span class="toc-section-number">3.6.2</span>  The log-normal likelihood</a></li>
  <li><a href="#re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" id="toc-re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" class="nav-link" data-scroll-target="#re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood"><span class="toc-section-number">3.6.3</span>  Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</a></li>
  </ul></li>
  <li><a href="#list-of-most-important-commands" id="toc-list-of-most-important-commands" class="nav-link" data-scroll-target="#list-of-most-important-commands"><span class="toc-section-number">3.7</span>  List of most important commands</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1"><span class="toc-section-number">3.8</span>  Summary</a></li>
  </ul></li>
  <li><a href="#chapter-4---bayesian-regression-models" id="toc-chapter-4---bayesian-regression-models" class="nav-link" data-scroll-target="#chapter-4---bayesian-regression-models"><span class="toc-section-number">4</span>  Chapter 4 - Bayesian regression models</a>
  <ul class="collapse">
  <li><a href="#a-first-linear-regression-does-attentional-load-affect-pupil-size" id="toc-a-first-linear-regression-does-attentional-load-affect-pupil-size" class="nav-link" data-scroll-target="#a-first-linear-regression-does-attentional-load-affect-pupil-size"><span class="toc-section-number">4.1</span>  A first linear regression: Does attentional load affect pupil size?</a>
  <ul class="collapse">
  <li><a href="#likelihood-and-priors" id="toc-likelihood-and-priors" class="nav-link" data-scroll-target="#likelihood-and-priors"><span class="toc-section-number">4.1.1</span>  Likelihood and priors</a></li>
  <li><a href="#the-brms-model" id="toc-the-brms-model" class="nav-link" data-scroll-target="#the-brms-model"><span class="toc-section-number">4.1.2</span>  The <code>brms</code> model</a></li>
  <li><a href="#how-to-communicate-the-results" id="toc-how-to-communicate-the-results" class="nav-link" data-scroll-target="#how-to-communicate-the-results"><span class="toc-section-number">4.1.3</span>  How to communicate the results</a></li>
  <li><a href="#descriptive-adequacy" id="toc-descriptive-adequacy" class="nav-link" data-scroll-target="#descriptive-adequacy"><span class="toc-section-number">4.1.4</span>  Descriptive adequacy</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter notes</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Daniela Palleschi </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>These notes are based on <span class="citation" data-cites="nicenboim_introduction_nodate">Nicenboim, Schad, and Vasishth (<a href="#ref-nicenboim_introduction_nodate" role="doc-biblioref">n.d.</a>)</span>, both from a PDF version supplied by the authors and the html version available <a href="https://vasishth.github.io/bayescogsci/book/">here</a> (accessed in early 2023). Much of the notes are taken verbatim from the book, as are code snippets.</p>
<div id="refs" class="references csl-bib-body hanging-indent" data-custom-style="Bibliography" role="doc-bibliography">
<div id="ref-nicenboim_introduction_nodate" class="csl-entry" role="doc-biblioentry">
Nicenboim, Bruno, Daniel Schad, and Shravan Vasishth. n.d. <span>“An Introduction to Bayesian Data Analysis for Cognitive Science.”</span>
</div>
</div>
<div class="cell">

</div>
<section id="set-up" class="level1 unnumbered">
<h1 class="unnumbered">Set up</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set global knit options</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> T, <span class="co"># print chunks?</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">eval =</span> T, <span class="co"># run chunks?</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">error =</span> F, <span class="co"># print errors?</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">warning =</span> F, <span class="co"># print warnings?</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">message =</span> F, <span class="co"># print messages?</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cache =</span> T <span class="co"># cache?</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                      )</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># suppress scientific notation</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">999</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="do">## create list of package names</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>packages <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="co">#"SIN", # this package was removed from the CRAN repository</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>               <span class="st">"MASS"</span>, <span class="st">"dplyr"</span>, <span class="st">"tidyr"</span>, <span class="st">"purrr"</span>, <span class="st">"extraDistr"</span>, <span class="st">"ggplot2"</span>, <span class="st">"loo"</span>, <span class="st">"bridgesampling"</span>, <span class="st">"brms"</span>, <span class="st">"bayesplot"</span>, <span class="st">"tictoc"</span>, <span class="st">"hypr"</span>, <span class="st">"bcogsci"</span>, <span class="st">"papaja"</span>, <span class="st">"grid"</span>, <span class="st">"kableExtra"</span>, <span class="st">"gridExtra"</span>, <span class="st">"lme4"</span>, <span class="st">"cowplot"</span>, <span class="st">"pdftools"</span>, <span class="st">"cmdstanr"</span>, <span class="st">"rootSolve"</span>, <span class="st">"rstan"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># NB: if you haven't already installed bcogsci through devtools, it won't be loaded</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Now load or install &amp; load all</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>package.check <span class="ot">&lt;-</span> <span class="fu">lapply</span>(</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  packages,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">install.packages</span>(x, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">library</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># this is also required, taken from the textbook</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="do">## Save compiled models:</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="do">## Parallelize the chains using all the cores:</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># To solve some conflicts between packages</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>select <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>select</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>extract <span class="ot">&lt;-</span> rstan<span class="sc">::</span>extract</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="ch.-1---intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Ch. 1 - Intro</h1>
<ul>
<li>given some data, how to use Bayes’ theorem to <strong><em>quantify uncertainty about our belief</em></strong> regarding a scientific question of interest</li>
<li>topics to be understood:
<ul>
<li>the basic concepts behind probability</li>
<li>the concept of random variables</li>
<li>probability distributions</li>
<li>the concept of likelihood</li>
</ul></li>
</ul>
<section id="probability" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="probability"><span class="header-section-number">1.1</span> Probability</h2>
<p>Frequency-based versus uncertain-belief perspective of probability:</p>
<ol type="1">
<li>repeatable events, like rolling a die and getting a 6, are <em>frequentist</em> because <strong>probability</strong> is related to the <em>frequency</em> at which we’d observe an outcome given repeated observations</li>
<li>one-of-a-kind events, like earthquakes, don’t work with this idea of probability</li>
</ol>
<ul>
<li>the probability of an earthquake expresses our <em>uncertainty</em> about an event happening</li>
<li>we also be <em>uncertain</em> about how probable an event is: being 90% sure something is 50% likely to happen</li>
<li>this is what we’re interested in: how uncertain we are of an estimate</li>
</ul>
<p>In Bayesian analysis, we want to express our uncertainty about the probability of observing an outcome (<em>prior distribution</em>).</p>
<section id="conditional-probability-and-bayes-rule" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="conditional-probability-and-bayes-rule"><span class="header-section-number">1.1.1</span> Conditional probability and Bayes’ rule</h3>
<ul>
<li>A = “the streets are wet”</li>
<li>B = “it was raining”</li>
<li>P(A|B) = the probability of A given B</li>
<li>P(A,B) = P(A|B)P(B) (the probability of A and B happening)</li>
</ul>
</section>
<section id="law-of-total-probability" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="law-of-total-probability"><span class="header-section-number">1.1.2</span> Law of total probability</h3>
<ul>
<li>dunno</li>
</ul>
</section>
</section>
<section id="discrete-random-variables" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="discrete-random-variables"><span class="header-section-number">1.2</span> Discrete random variables</h2>
<p>Generating random sequences of simulated data with a binomial distribution. Imagine a cloze task, where we consider a particular word a success (1) and any other word a failure (0). If we run the experiment 20 times with a sample size of 10, the cloze probabilities for these 20 experiments would be:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-3_dcf0300472f36b30f2095c4c2b7889b4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="at">n =</span> <span class="dv">20</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[1] 4 5 4 8 4 5 7 7 5 6 6 6 4 7 3 7 4 7 6 4</p>
</div>
<p>For discrete random variables such as the binomial, the probability distribution <em>p(y|<span class="math inline">\theta</span>)</em> is called a probability mass function (PMF) . The PMF defines the probability of each possible outcome. With <em>n</em> = 10 trials, there are 11 possible outcomes (0, 1, 2,…10 succeses). Which outcome is most probable depends on the parameter <span class="math inline">\theta</span> that represents the probability of success. Above, we set <span class="math inline">\theta</span> to <code>0.5</code>.</p>
<section id="the-mean-and-variance-of-the-binomial-distribution" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="the-mean-and-variance-of-the-binomial-distribution"><span class="header-section-number">1.2.1</span> The mean and variance of the binomial distribution</h3>
<p>In real exerimental situations we never know the true value of <span class="math inline">\theta</span> (probability of an outcome), but it can be derived from the data: <em><span class="math inline">\theta</span> hat = k/n</em>, where <em>k</em> = number of observed successess, <em>n</em> = number of trials, and <em><span class="math inline">\theta</span> hat</em> = observed proportion of successes. <em><span class="math inline">\theta</span> hat</em> = <strong><em>maximum likelihood estimate</em></strong> of the true but unknown parameter <em><span class="math inline">\theta</span></em>. Basically, the <strong>mean</strong> of the binomial distribution. The <strong>variance</strong> can also be estimated by computing <em>(n(<span class="math inline">\theta</span>))(1 - <span class="math inline">\theta</span>)</em>. These estimates can be be used for statistical inference.</p>
</section>
<section id="compute-probability-of-a-particular-outcome-discrete-dibinom" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="compute-probability-of-a-particular-outcome-discrete-dibinom"><span class="header-section-number">1.2.2</span> Compute probability of a particular outcome (discrete): dibinom</h3>
<p><code>dbinom</code> calculates probability of <em>k</em> successes out of <em>n</em> given a particular <em><span class="math inline">\theta</span></em>.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-4_feb64baf49c8efb27238d50359b0f38d">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2460938</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.001488035</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.001488035</code></pre>
</div>
</div>
<p>With continuous data, the probability of obtaining an exact value will always be zero. We’ll come ot this later.</p>
</section>
<section id="compute-cumulative-probability-pbinom" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="compute-cumulative-probability-pbinom"><span class="header-section-number">1.2.3</span> Compute cumulative probability: pbinom</h3>
<p>The cumulative distribution function (CDF): essentially the sum of all probabilities of the values of <em>k</em> you are interested in. E.g., the probability of observing 2 successes or fewer (0, 1, or 2) is:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-5_c6eb9f03e7ea0c6716d42e4425076dcb">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sum of probabilities for exact k's</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">0</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbinom</span>(<span class="dv">1</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or use pbinom()</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># conversely, what is the $\theta$ of observing THREE successes or more?</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9453125</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9453125</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the probability of observing 10 or fewer successes (out of 10 trials)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">10</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
</section>
<section id="compute-the-inverse-of-the-cdf-quantile-function-qbinom" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="compute-the-inverse-of-the-cdf-quantile-function-qbinom"><span class="header-section-number">1.2.4</span> Compute the inverse of the CDF (quantile function): qbinom</h3>
<p>The quantile function (the inverse CDF) obtains the value of <em>k</em> (the quantile) given the probability of obtaining <em>k</em> or less than <em>k</em> successes given some specific probability value <em>p</em>:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-6_468a585a716cf9e15d47ff12302e06c9">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse of dbinom(2,10,.5) would be:</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="fl">0.0546875</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">prob=</span>.<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>
<section id="generage-simulated-data-from-binomial-distribtion-rbinom" class="level4">
<h4 class="anchored" data-anchor-id="generage-simulated-data-from-binomial-distribtion-rbinom">Generage simulated data from binomial distribtion: rbinom</h4>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-7_cdd24d52c08d814747ba37bfe12b1e9c">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># given 1 iteration of 10 trials where p = .5, produce a random value of k</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="continuous-random-variables" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="continuous-random-variables"><span class="header-section-number">1.3</span> Continuous random variables</h2>
<p>Imagine vector of reading times data with a normal distribution, defined by its <em>mean</em> and its <em>sd</em>. The <strong><em>probability density function</em></strong> (PDF) for particular values of mean and sd (assuming a normal distribution) can be calculated using <code>dnorm</code>. The CDF can be found using <code>pnorm</code>, and the inverse CDF using <code>qnorm</code>. These are 3 different ways of looking at the infrmation.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-8_3de1e2c750391888c01a4c89190c2ad1">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p of observing a mean of 250ms when the true mean is 500 &amp; sd = 100 (PDF)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">400</span>,<span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.002419707</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p of observing 400ms *or lower* when the true mean is 500 &amp; sd = 100 (CDF)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">400</span>,<span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1586553</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k with a CDF of 0.1586553 when the true mean is 500 &amp; sd = 100 (inverse CDF)</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.1586553</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 400</code></pre>
</div>
</div>
<p>Question: what is the probability of observing values between 200 and 700 from a normal distribution where mean = 500 and sd = 100?</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-9_4dca3855ba1a5341cc6713c511074e97">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">700</span>,<span class="dv">500</span>,<span class="dv">100</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">200</span>,<span class="dv">500</span>,<span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9759</code></pre>
</div>
</div>
<p>With continuous data, it is only meaningful to ask about probabilities between two point values (e.g., probability that Y lies between a and b).</p>
<p>What is the quantile <em>q</em> such that the probability of observing that value or something less (or more) than it is 0.975 (given the normal(500,100) distribution)?</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-10_90741c89699886c4e49e0124fba7a698">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="at">m=</span><span class="dv">500</span>, <span class="at">sd=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 695.9964</code></pre>
</div>
</div>
<p>Next task: generate simulated data. generate 10 data points using the <code>rnorm</code> function and use this simulated data to compute the mean and stanrdard devaition.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-11_da277f64c6bb46a513ea2c4a02c24bf3">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">500</span>,<span class="dv">100</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 502.8496</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 118.7594</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># can also computer lower and upper bounds of 95% CIs</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(x, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    2.5%    97.5% 
305.8623 617.6222 </code></pre>
</div>
</div>
<section id="an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables"><span class="header-section-number">1.3.1</span> An important distinction: probability vs.&nbsp;densitiy in continuous random variables</h3>
<p>The probability density function (PDF):</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-12_f2c3c52c1a65b82475534ad31626a7cd">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># density with default m = 0 and sd = 1</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2419707</code></pre>
</div>
</div>
<p>This is not the probability of observing 1 in this distribution, as the probability of a single value in a continous distribtion will always be 0. This is becaue probability in a continuous distritubion is the <strong><em>area under the curve</em></strong>, and at a single point there is no area under the curve (i.e., p = 0). The <code>pnorm</code> function allows us to find the cumulative distribution function (CDF) for the normal distribution.</p>
<p>For example, the probability of obseving a value etween +/-2 in a normal distribution with mean 0 and sd 1:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-13_340d4c2c586e9d12ad15804c4674c4bd">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">2</span>, <span class="at">m =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="at">m =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9544997</code></pre>
</div>
</div>
<p>For <strong><em>discrete</em></strong> random variables, the situation is different. These have a probability <strong>mass</strong> function (PMF), the binomial distribution that we saw before. Here, the PMF maps the possible <em>y</em> values to the probabilities of those exact values occurring.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-14_c609d1d5866b343656751d3c7f468b01">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">2</span>,<span class="at">size=</span><span class="dv">10</span>,<span class="at">prob=</span>.<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.04394531</code></pre>
</div>
</div>
</section>
<section id="truncating-a-normal-distribution" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="truncating-a-normal-distribution"><span class="header-section-number">1.3.2</span> Truncating a normal distribution</h3>
<p>Refers to positive values only (truncating at 0).</p>
</section>
</section>
<section id="bivariate-and-multivariate-distributions" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="bivariate-and-multivariate-distributions"><span class="header-section-number">1.4</span> Bivariate and multivariate distributions</h2>
<p>Consider a case where two discrete responses were recorded: a binary yes/no response, and a Likert acceptability rating (1-7).</p>
<p>The <strong><em>joint probability mass function</em></strong> is the joint PMF of two random variables.</p>
<p>Let’s play around with some such data:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-15_95bbf77a67dd1a6f20c52f23741a8e77">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run if package is not loaded</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(bcogsci)</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_discreteagrmt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="marginal-distributions" class="level4">
<h4 class="anchored" data-anchor-id="marginal-distributions">Marginal distributions</h4>
<p>The marginal distribution of each pair of values (let’s say <em>x</em> = the binary response, <em>y</em> = the Likert response) is computed by summing up</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-16_aab6cada25037f0fdd450016ae6845d6">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rowSums</span>(probs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong><em>object <code>probs</code> is not defined in the book</em></strong></p>
</section>
<section id="generate-simulated-bivariate-multivariate-data" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="generate-simulated-bivariate-multivariate-data"><span class="header-section-number">1.4.1</span> Generate simulated bivariate (multivariate) data</h3>
<p>Suppose we want to generate 100 pairs of correlated data, with correlation rho = 0.6. The two random variables have mean 0, and standard deviations 5 and 10 respectively.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-17_c84d2e1a7734d1da1225ffbdc4e58636">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="do">## define a variance-covariance matrix:</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">5</span><span class="sc">^</span><span class="dv">2</span>, <span class="dv">5</span> <span class="sc">*</span> <span class="dv">10</span> <span class="sc">*</span> .<span class="dv">6</span>, <span class="dv">5</span> <span class="sc">*</span> <span class="dv">10</span> <span class="sc">*</span> .<span class="dv">6</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">byrow =</span> <span class="cn">FALSE</span>, <span class="at">ncol =</span> <span class="dv">2</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="do">## generate data:</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sigma =</span> Sigma</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(u, <span class="at">n =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]       [,2]
[1,] 10.995044  13.852577
[2,]  3.535926  -5.899776
[3,] -8.437371 -20.000435</code></pre>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-18_6e171bf5d5f0b7ee792c0c237268427b">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">u_1 =</span> u[, <span class="dv">1</span>], <span class="at">u_2 =</span> u[, <span class="dv">2</span>]), <span class="fu">aes</span>(u_1, u_2)) <span class="sc">+</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter"><span class="header-section-number">1.5</span> An important concept: the marginal likelihood (integrating out a parameter)</h2>
</section>
<section id="exercises" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="exercises"><span class="header-section-number">1.6</span> Exercises</h2>
<p>1.1 Practice with pnorm Part 1</p>
<p>Given a normal distribution with mean 500 and standard deviation 100, use the pnorm function to calculate the probability of obtaining values between 200 and 800 from this distribution.</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-19_25e7d8a628f4d15934293c462df6a6d9">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">200</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9973002</code></pre>
</div>
</div>
<p>1.2 Practice with pnorm Part 2</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-20_3cfd8e9ef212cb6a076ea5a8e0f0b82a">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">700</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2524925</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">900</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2524925</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5</code></pre>
</div>
</div>
<p>1.3 Practice with pnorm Part 3</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-21_605f2d9f858e55297e3ba9f8d2b69c85">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">550</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4012937</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T) <span class="sc">-</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pnorm</span>(<span class="dv">300</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7745375</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">900</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0668072</code></pre>
</div>
</div>
<p>Exercise 1.4 Practice using the qnorm function - Part 1</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-22_e7a3b19604cfe6e3b57d991d145d72a2">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>),<span class="at">mean=</span><span class="dv">1</span>,<span class="at">sd=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.2815516  2.2815516</code></pre>
</div>
</div>
<p>Exercise 1.5 Practice using the qnorm function - Part 2</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-23_f7ee5437ced7022f3ee3ab16b2125cdd">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="at">mean=</span><span class="dv">650</span>, <span class="at">sd=</span><span class="dv">125</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 489.8061 810.1939</code></pre>
</div>
</div>
<p>Exercise 1.6 Practice getting summaries from samples - Part 1</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-24_4637c661d395ae66f40abbdf0feadfec">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>data_gen1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">300</span>, <span class="dv">200</span>)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 297.4517</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sd</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 205.8063</code></pre>
</div>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># q1 and q2</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="fu">mean</span>(data_gen1), <span class="fu">sd</span>(data_gen1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  33.70032 561.20313</code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exercise 1.7 Practice getting summaries from samples - Part 2</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-25_e843c241ed45f01c8eb6aeec6a583a4e">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data with truncated normal distribution</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>data_gen1 <span class="ot">&lt;-</span> <span class="fu">rtnorm</span>(<span class="dv">1000</span>, <span class="dv">300</span>, <span class="dv">200</span>, <span class="at">a =</span> <span class="dv">0</span>)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 321.4014</code></pre>
</div>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sd</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 174.0302</code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># q1 and q2</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="fu">mean</span>(data_gen1), <span class="fu">sd</span>(data_gen1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  98.3727 544.4300</code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exercise 1.8 Practice with a variance-covariance matrix for a bivariate distribution</p>
</section>
</section>
<section id="ch.-2---intro-to-bayesian-data-analysis" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Ch. 2 - Intro to Bayesian data analysis</h1>
<ul>
<li>simple but crucial point: the posterior distribution of a parameter is a compromise between the prior and the likelihood</li>
</ul>
<section id="terms" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="terms">Terms</h2>
<ul>
<li><em>posterior</em>, <em>p(</em>$theta$<em>|y)</em>: probability distribution of the parameters conditional on the <strong>data</strong></li>
<li><em>likelihood</em>, <em>p(y|</em>$theta$<em>)</em>: the PMF or PDF expressed as a function of <span class="math inline">\theta</span></li>
<li><em>prior</em>, $theta$: the initial probability distribution of paramters <strong><em>before seeing the data</em></strong></li>
<li><em>marginal likelihood, p(y)</em>: standardizes the posterior distribution to ensure the AUC sums to 1; it ensure the posterior is a valid probability distribution</li>
</ul>
</section>
<section id="bayes-rule" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="bayes-rule"><span class="header-section-number">2.1</span> Bayes’ Rule</h2>
<ul>
<li>Bayes’ rule: when <em>A</em> and <em>B</em> are observable discrete events (like “it has been raining” or “the streets are wet”), we can state the rule as follows:</li>
</ul>
<p><span class="math display">
P(A\mid B) = \frac{P(B\mid A) P(A)}{P(B)}
\tag{2.1}
</span></p>
<ul>
<li>given a vector of data <em>y</em>, we can work out the posterior distributions of parameters of interest which we represent as the vector of parameters <span class="math inline">\theta</span></li>
<li>to do this, we can re-write equation 2.1 as 2.2:</li>
</ul>
<p><span class="math display">
p(\boldsymbol{\Theta}|\boldsymbol{y}) = \cfrac{ p(\boldsymbol{y}|\boldsymbol{\Theta}) \cdot p(\boldsymbol{\Theta}) }{p(\boldsymbol{y})}
\tag{2.2}
</span></p>
<ul>
<li>now, Bayes’ rule is writen in terms of probability distributions, where p() is the probability density function (continuous) or probability mass function (discrete)</li>
<li>in words, this simply means:</li>
</ul>
<p><span class="math display">
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
</span></p>
</section>
<section id="deriving-the-posterior-using-bayes-rule-an-analystical-example" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="deriving-the-posterior-using-bayes-rule-an-analystical-example"><span class="header-section-number">2.2</span> Deriving the posterior using Bayes’ Rule: an analystical example</h2>
<ul>
<li><p>participants are shown sentences like <em>It’s raining. I’m going to take the…</em></p></li>
<li><p>if 100 participants complete the sentence, and 80 complete the sentence with <em>bus</em>, the estimated cloze probability would be <span class="math inline">\frac{80}{100}</span>=0.8</p>
<ul>
<li>this is the <strong>maximum likelihood estimate</strong> of the probability of producing the word; as this is an estimate let’s add a hat: <span class="math inline">\hat \theta</span>=0.8</li>
</ul></li>
<li><p>in the frequentist paradigm, <span class="math inline">\hat \theta</span>=0.8 is an estimate of an <strong>unknown point value</strong> <span class="math inline">\theta</span> “out there in nature”</p></li>
<li><p>N.B., the variability in the estimate will be influenced by the sample size</p>
<ul>
<li>if the <em>true</em> value of <span class="math inline">\theta</span> is really 0.80, we will still get some variability in the estimated proportion from a sample size of say 10 pariticpants</li>
<li>let’s carry out 100 simulated experiments and compute their variability:</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-26_520c6f709f0c0ce91c7b6afd536069ad">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="co"># generate 100 random binomial data sets</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs each</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">prob =</span> .<span class="dv">8</span>) <span class="sc">/</span> <span class="dv">10</span> <span class="co"># with prob 8, now divide these by 10 to get 100 means (k/n)</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co"># what is the sd of these 100 means?</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.131</code></pre>
</div>
</div>
<ul>
<li>instead, let’s imagine that <span class="math inline">\theta</span> is a <strong><em>random variable</em></strong>; i.e., it has a PDF associated with it
<ul>
<li>this PDDF would now represent our <strong><em>belief</em></strong> about possible values of <span class="math inline">\theta</span> <em>before we have any data</em></li>
<li>e.g., if we believe from the outset that all possible values between 0 and 1 are equally likely, we would have a uniform prior of <span class="math inline">\theta \sim \mathit{Uniform}</span>(0,1)</li>
<li>let’s re-run our simulated experiments, but with <em>two</em> sources of variability: the data and our uncertainty associated with <span class="math inline">\theta</span></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-27_9f19e17e7639a65708a9d73479b32a3b">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>) <span class="co"># simulate 100 numbers between 0:1</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="co"># generate random binomial data that has...</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, <span class="co"># 100x</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> theta <span class="co"># with prob = theta</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>)<span class="sc">/</span><span class="dv">10</span> <span class="co"># divided by 10 to give us the mean for each</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sd of the means from these 100 'experiments'</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.324</code></pre>
</div>
</div>
<ul>
<li>the higher standard deviation, representing variability int he estimate of the parameter, comes frm the added uncertainty from the <span class="math inline">\theta</span> parameter
<ul>
<li>what would happen if we had tighter expectations, i.e., a very tight PDF for <span class="math inline">\theta</span>, say (0.7,0.9)?</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-28_bfb2c1ae07a51324fe3b787d371d404e">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="fl">0.7</span>, <span class="at">max =</span> <span class="fl">0.9</span>) <span class="co"># simulate 100 numbers between 0:1</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="co"># generate random binomial data that has...</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, <span class="co"># 100x</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> theta <span class="co"># with prob = theta</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>)<span class="sc">/</span><span class="dv">10</span> <span class="co"># divided by 10 to give us the mean for each</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sd of the means from these 100 'experiments'</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.138</code></pre>
</div>
</div>
<ul>
<li><p>the variability is smaller; so the greater the uncertainty associated with the <span class="math inline">\theta</span> parameter, the greater the variability in the data</p></li>
<li><p>this is very different from the frequentist assumption that <span class="math inline">\theta</span> is a point value; in Bayesian <span class="math inline">\theta</span> is a <strong>random variable</strong> with a probability density/mass function associated with it</p></li>
<li><p>this PDF is called a <strong>prior distribution</strong> and represents our prior belief or knowledge about a possible value of this parameter</p></li>
<li><p>once we obtain data, these data serve to modify our prior belief about the distribution, called our <strong>posterior distribution</strong></p></li>
</ul>
</section>
<section id="choosing-a-likelihood" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="choosing-a-likelihood"><span class="header-section-number">2.3</span> Choosing a likelihood</h2>
<ul>
<li>with a binomial distribution like the cloze probability (chose ‘bus’ or not), the PMF can be written as:</li>
</ul>
<p><span class="math display">
p(k|n,\theta) = \binom{n}
{k} \theta^k (1-\theta)^{n-k}
\tag{2.3}
</span></p>
<ul>
<li><em>k</em> = the number of times “bus” was given as an answer</li>
<li><em>n</em> = the total number of answers given</li>
<li>if we collect 100 data points (<em>n</em> = 100), and find <em>k</em> = 80, we now have 2 fixed data points, <em>n</em> and <em>k</em>. The only variable is now <span class="math inline">\theta</span></li>
</ul>
<p><span class="math display">
p(k=80 | n= 100,  \theta) = \binom{n}{k} \theta^{80} (1-\theta)^{20}
</span></p>
<ul>
<li><p>this is now a continuous function of the value of <span class="math inline">\theta</span>, which can have a possible value between 0 and 1</p></li>
<li><p>by contrast, the PMF of the binomial treats <span class="math inline">\theta</span> as a <strong>fixed</strong> value and defines a discrete distribution over the n+1 possible discrete values <em>k</em> that we can observe</p></li>
<li><p>recall: the PMF and the likelihood are the same function seen from different points of view: the only difference being what is considered fixed (PMF: <span class="math inline">\theta</span>, likelihood: data) and what is varying (PMF: data, likelihood: <span class="math inline">\theta</span>)</p>
<ul>
<li><strong>PMF</strong>: <span class="math inline">\theta</span> is fixed, data varies</li>
<li><strong>likelihood function</strong>: data is fixed, <span class="math inline">\theta</span> varies</li>
</ul></li>
</ul>
<p>Now we go back to our main foal: using Bayes’ rule to find out the posterior distribution of <span class="math inline">\theta</span> given our data: <em>p(</em><span class="math inline">\theta</span>*|n,k). We first need to define a prior distribution over the parameter <span class="math inline">theta</span>, thereby expressing our prior uncertainty about plausible values of <span class="math inline">\theta</span></p>
</section>
<section id="choosinga-a-prior-for-theta" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="choosinga-a-prior-for-theta"><span class="header-section-number">2.4</span> Choosinga a prior for <span class="math inline">\theta</span></h2>
<ul>
<li><p>priors for a <span class="math inline">\theta</span> in a binominal distribution: the parameter <span class="math inline">\theta</span> is a random variable with a PDF whose range is [0,1]</p></li>
<li><p>the <strong><em>beta distribution</em></strong>, which is a PDF for a continuous random variable, is commonly used as a prior for parameters representing probabilities, and has the following PDF:</p></li>
</ul>
<p><span class="math display">
p(\theta|a,b)=  \frac{1}{B(a,b)} \theta^{a - 1} (1-\theta)^{b-1}   
\tag{2.4}
</span></p>
<ul>
<li><em>B(a,b)</em> is a normalising constant that ensures that the area under the curve sums to 1, so that <em>p(</em><span class="math inline">\theta</span>|<em>a,b)</em> is a probability</li>
<li>the beta distribution’s paramters <em>a</em> and <em>b</em> express our prior beliefs about the probability of a success:
<ul>
<li><em>a</em> = number of “successes” (answering “bus”)</li>
<li><em>b</em> = number of “failures” (not answering “bus”)</li>
</ul></li>
<li>the different beta distributions shapes given different values of a and b are shown below (in r, a = <code>shape1</code> and b = <code>shape2</code>)</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-29_f984cc6ada576f899fc771f44f4c3311">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">1</span>,<span class="at">shape2=</span><span class="dv">1</span>), <span class="dv">0</span>,<span class="dv">1</span>,</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Beta density"</span>,</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">1.1</span>,<span class="st">"a=1,b=1"</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">3</span>,<span class="at">shape2=</span><span class="dv">3</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">1.6</span>,<span class="st">"a=3,b=3"</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">6</span>,<span class="at">shape2=</span><span class="dv">6</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">2.8</span>,<span class="st">"a=6,b=6"</span>)</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">2</span>,<span class="at">shape2=</span><span class="dv">6</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">15</span>,<span class="fl">2.9</span>,<span class="st">"a=2,b=6"</span>)</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">6</span>,<span class="at">shape2=</span><span class="dv">2</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">85</span>,<span class="fl">2.9</span>,<span class="st">"a=6,b=2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>to express our uncertainty, we could compute 95% <strong><em>credible</em></strong> intervales, i.e., the region over which we are 95% certain the value of the parameter lies</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-30_5ec2922c5140ba194d8a5e09a1ae5c07">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 95% CrIs</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="co"># at what quantiles (points on the x-axis)</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), <span class="co"># would the PDF cover 95% AUC</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape1 =</span> <span class="dv">4</span>, <span class="co"># where a = 4</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape2 =</span> <span class="dv">4</span>), <span class="co"># and b = 4</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">3</span>) <span class="co"># rounded to 3 decimal points</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.184 0.816</code></pre>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Sidebar
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>in a unimodal distribution, one could use the narrowest interval that contains the mode (the <strong>highest posterior density interval</strong> (HDI))</li>
<li>in skewed posterior distirbutions, the equal-tailed CrI and the HDI will not be identical, because the HDI will have unequal tail probabilities; this book uses the equal-tailed interval (like we computed above) because it’s the standard output in <code>Stan</code> and <code>brms</code></li>
</ul>
</div>
</div>
<ul>
<li>if we were to choose <em>a</em> = 10 and <em>b</em> = 10, we would still be assuming a prior that “bus” is just as likely as some other word, but now our prior uncertainty about this mean is lower, meaning we have a tighter prior:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-31_2e1c643b0220c2b5d6bf362858e6c66c">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 95% CrIs</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="co"># at what quantiles (points on the x-axis)</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), <span class="co"># would the PDF cover 95% AUC</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape1 =</span> <span class="dv">10</span>, <span class="co"># where a = 4</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape2 =</span> <span class="dv">10</span>), <span class="co"># and b = 4</span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">3</span>) <span class="co"># rounded to 3 decimal points</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.289 0.711</code></pre>
</div>
</div>
<ul>
<li>compare the AUC for the two beta distributions in Figure </li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/fig-beta2_068bef6dbd0447230da78d8164a9d426">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">4</span>,<span class="at">shape2=</span><span class="dv">4</span>), <span class="dv">0</span>,<span class="dv">1</span>,</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Beta density"</span>,</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>))</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">2.35</span>,<span class="st">"a=4,b=4"</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">10</span>,<span class="at">shape2=</span><span class="dv">10</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>,</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>))</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">3.7</span>,<span class="st">"a=10,b=10"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beta2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="book_notes_files/figure-html/fig-beta2-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Beta distributions with varying a and b values</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li>but which prior should we choose? This depends on our prior knowledge
<ul>
<li>if we don’t have much prior information, we could use <em>a</em> = <em>b</em> = 1; this is a uniform prior <span class="math inline">\mathit{Uniform}</span>(0,1), often clled a <strong><em>flat</em></strong>, <strong><em>non-informative</em></strong>, or <strong><em>uninformative prior</em></strong></li>
<li>if we have a lot of prior knowledge or a strong belief regarding the range of plausible values for <span class="math inline">\theta</span>, we can use a different set of <em>a</em> and <em>b</em> values</li>
<li>if we were to use <em>a</em> = 4 and <em>b</em> = 4, then our prior for <span class="math inline">\theta</span> would be:</li>
</ul></li>
</ul>
<p><span class="math display">
p(\theta) = \frac{1}{B(4,4)} \theta^{3} (1-\theta)^{3}
</span></p>
</section>
<section id="using-bayes-rule-to-computer-the-posterior-pthetank" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="using-bayes-rule-to-computer-the-posterior-pthetank"><span class="header-section-number">2.5</span> Using Baye’s rule to computer the posterior <em>p(</em><span class="math inline">\theta</span><em>|n,k)</em></h2>
<ul>
<li>recall the equation from earlier:</li>
</ul>
<p><span class="math display">
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
</span></p>
<ul>
<li>now that we’ve got the likelihood and the prior, we can use Bayes’ rule to calculate <em>p(</em><span class="math inline">\theta</span>|<em>n,k)</em>, as follows:</li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) = \frac{\left[\binom{100}{80} \theta^{80} \cdot (1-\theta)^{20}\right]  \times \left[\frac{1}{B(4,4)} \times \theta^{3} (1-\theta)^{3}\right]}{p(k=80)}
\tag{2.6}
</span></p>
<ul>
<li>constant values are those that do not depend on the unknown parameter of interest, <span class="math inline">\theta</span>; so <em>p(k = 80)</em> will be a constant once we know the number of successes
<ul>
<li>once <em>k</em> is known, we already have several constant values</li>
</ul></li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
</span></p>
<ul>
<li>we can gather all the constants (in the square brackets below):</li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
</span></p>
<ul>
<li>and ignore the constants for now, which will later on make the AUC sum up to 1; so now we say the posterior is proportional to the right-hand side of the equation:</li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) \propto   [\theta^{80} (1-\theta)^{20} \times \theta^{3} (1-\theta)^{3} ]
\tag{2.8}
</span></p>
<ul>
<li>in other words:</li>
</ul>
<p><span class="math display">
\hbox{Posterior} \propto \hbox{Likelihood} \times \hbox{Prior}
</span></p>
<ul>
<li>now we just have to add up the exponents</li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) \propto   [\theta^{80+3} (1-\theta)^{20+3}] = \theta^{83} (1-\theta)^{23}
\tag{2.9}
</span></p>
<ul>
<li>recall that the beta distribution involves <span class="math inline">\theta</span> exponentiated to the power of <em>a</em>-1 and <em>b</em>-1 (see equation 2.4)
<ul>
<li>therefore, the expression in 2.9 above corresponds to a beta distribution with parameters <em>a</em> = 84 and <em>b</em> = 24 (because 83 and 23 +1 is 84 and 24)</li>
<li>all we need now is our normalising constant to make the AUC sum to one; let’s check this:</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-33_b80acc900bfb083506a6d48efb9704a6">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>PostFun <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>  theta<span class="sc">^</span><span class="dv">83</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span><span class="dv">23</span></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>(AUC <span class="ot">&lt;-</span> <span class="fu">integrate</span>(PostFun, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000000000000000000000000831619</code></pre>
</div>
</div>
<ul>
<li>this doesn’t add up to 1, it’s not a probability distribution</li>
<li>but we can use it to figure out what our normalising constant is; what is the constant <em>k</em> such that the AUC sums to 1:</li>
</ul>
<p><span class="math display">
k \int_{0}^{1} \theta^{83} (1-\theta)^{23} = 1
</span></p>
<ul>
<li>we know what _{0}^{1} ^{83} (1-)^{23} is, because we just computed it above (and called it AUC), so:</li>
</ul>
<p><span class="math display">
k  = \frac{1}{\int_{0}^{1} \theta^{83} (1-\theta)^{23}} = \frac{1}{AUC}
</span></p>
<ul>
<li>we now have the distribution or <span class="math inline">\theta</span> given the data, expressed as a PDF:</li>
</ul>
<p><span class="math display">
p(\theta|n=100,k=80) = \frac{1}{B(83,23)} \theta^{84-1} (1-\theta)^{24-1}
</span></p>
<ul>
<li>and our function will now sum to one if we divide it all by AUC</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-34_72b0f5c8f5df7e21e8216eb02b7e7b0f">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>PostFun <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>  theta<span class="sc">^</span><span class="dv">83</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span><span class="dv">23</span> <span class="sc">/</span> AUC</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(PostFun, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
</section>
<section id="summary-of-the-procedure" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="summary-of-the-procedure"><span class="header-section-number">2.6</span> Summary of the procedure</h2>
<ul>
<li>we started with a binomial likelihood
<ul>
<li>multiplied it with the prior <span class="math inline">\theta \sim \mathit{Beta}(4,4)</span></li>
<li>obtained the posterior <em>p(</em><span class="math inline">\theta</span>|<em>n,k)</em> <span class="math inline">\sim \mathit{Beta}(4,4)</span></li>
<li>we ignored the constants when carrying out the multiplication (i.e., computer the posterior <em>up to proportionality</em>)</li>
<li>then we rescaled the posterior to become a probability distribution by including a proportionality constant (AUC)</li>
</ul></li>
<li>this was an example of a <strong>conjugate</strong> analysis: the posterior on the parameter has thes ame form (belongs to the same family of probability distributions) as the prior</li>
<li>this combo of likelihood and prior is called the <strong><em>beta-binomial conjugate case</em></strong>
<ul>
<li><p>conjugacy is defined as: Given the likelihood <em>p(y</em>|<span class="math inline">\theta</span><em>)</em>, if the prior <em>p(</em><span class="math inline">\theta</span>*)( results in a posterior <span class="math inline">p(\theta|y)</span> that has some form as <span class="math inline">p(\theta)</span>, then we call <span class="math inline">p(\theta)</span> a conjugate prior</p></li>
<li><p>given a <span class="math inline">Binomial(n,k|\theta)</span> likelihood, and a <span class="math inline">Beta(a,b)</span> prior on <span class="math inline">\theta</span>, the posterior will be <span class="math inline">Beta(a + k, b + n - k)</span></p></li>
</ul></li>
</ul>
</section>
<section id="visualising-the-prior-likelihood-and-the-posterior" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="visualising-the-prior-likelihood-and-the-posterior"><span class="header-section-number">2.7</span> Visualising the prior, likelihood, and the posterior</h2>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-35_4f3ad098cf95ea580af48fc0deaacd8a">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>binom_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x=</span>k, <span class="at">size =</span>n, <span class="at">prob =</span> theta)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">integrate</span>(<span class="at">f =</span> binom_lh, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>binom_scaled_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) <span class="dv">1</span><span class="sc">/</span>K <span class="sc">*</span> <span class="fu">binom_lh</span>(theta)</span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>p_beta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)), <span class="fu">aes</span>(theta)) <span class="sc">+</span></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb100-15"><a href="#cb100-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> a, <span class="at">shape2 =</span> b),</span>
<span id="cb100-16"><a href="#cb100-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Prior"</span>)</span>
<span id="cb100-17"><a href="#cb100-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-18"><a href="#cb100-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"density"</span>) <span class="sc">+</span></span>
<span id="cb100-19"><a href="#cb100-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-20"><a href="#cb100-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb100-21"><a href="#cb100-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> k <span class="sc">+</span> a, <span class="at">shape2 =</span> n <span class="sc">-</span> k <span class="sc">+</span> b), <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Posterior"</span>)</span>
<span id="cb100-22"><a href="#cb100-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-23"><a href="#cb100-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-24"><a href="#cb100-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> binom_scaled_lh,</span>
<span id="cb100-25"><a href="#cb100-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Scaled likelihood"</span>)</span>
<span id="cb100-26"><a href="#cb100-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-27"><a href="#cb100-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb100-28"><a href="#cb100-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb100-29"><a href="#cb100-29" aria-hidden="true" tabindex="-1"></a>p_beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>if we wanted to produce the 95% credible interval, i.e., the range over which we are 95% certain the true value of <span class="math inline">\theta</span> lies, give <em>a</em> = 84 and <em>b</em> = 24:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-36_3c0f2819ec538c3e7ffdaf275c354621">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">shape1 =</span> <span class="dv">84</span>, <span class="at">shape2 =</span> <span class="dv">24</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.695 0.851</code></pre>
</div>
</div>
</section>
<section id="the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood"><span class="header-section-number">2.8</span> The posterior distribution is ac ompromise between the prior and the likelihood</h2>
<ul>
<li>let’s take four different beta priors with increasing certainty:
<ul>
<li><span class="math inline">Beta(a = 2, b = 2)</span></li>
<li><span class="math inline">Beta(a = 3, b = 3)</span></li>
<li><span class="math inline">Beta(a = 6, b = 6)</span></li>
<li><span class="math inline">Beta(a = 21, b = 21)</span></li>
</ul></li>
<li>each reflects a believe that <span class="math inline">\theta</span> = 0.5 but with a varying degree of certainty
<ul>
<li>we can now “just” plug in the likelihood and the prior to the beta-binomial case to get the posterior:</li>
</ul></li>
</ul>
<p><span class="math display">
p(\theta | n,k) \propto p(k |n,\theta) p(\theta)
</span></p>
<ul>
<li>if we plot the tightest case (<span class="math inline">a = 21, b = 21</span>), we see how the posterior is affected</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-37_5d32bbeb94fa3a774f731a8826282b6c">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">21</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">21</span></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>binom_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x=</span>k, <span class="at">size =</span>n, <span class="at">prob =</span> theta)</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">integrate</span>(<span class="at">f =</span> binom_lh, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>binom_scaled_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) <span class="dv">1</span><span class="sc">/</span>K <span class="sc">*</span> <span class="fu">binom_lh</span>(theta)</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>p_beta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)), <span class="fu">aes</span>(theta)) <span class="sc">+</span></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> a, <span class="at">shape2 =</span> b),</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Prior"</span>)</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"density"</span>) <span class="sc">+</span></span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> k <span class="sc">+</span> a, <span class="at">shape2 =</span> n <span class="sc">-</span> k <span class="sc">+</span> b), <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Posterior"</span>)</span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> binom_scaled_lh,</span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Scaled likelihood"</span>)</span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>p_beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-37-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>we can say the following about the likelihood-prior-posterior relationship:
<ul>
<li>the posterior distribution is ac ompromise between the prior and the likelihood</li>
<li>for a given set of data, the great the certainty in the prior, the more heavily the posterior will be influenced by the prior mean</li>
<li>conversely, for a given set of data, the greater the <strong>un</strong>certainty in the prior, the more heavily the posterior will be influenced by the likelihood</li>
<li>but because <em>n</em> and <em>k</em> are included in the posterior Beta distribution (<span class="math inline">Beta(a + k, b + n - k)</span>), the posterior mean will be influenced more heavily by larger sample sizes
<ul>
<li>sensitivity analyses can help check whether your parameter of interest is sensitive to the prior specification</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="incremental-knowledge-gain-using-prior-knowledge" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="incremental-knowledge-gain-using-prior-knowledge"><span class="header-section-number">2.9</span> Incremental knowledge gain using prior knowledge</h2>
<ul>
<li><p>we can incrementally gain information about a research question by using information from previous studies and deriving a position, and then using that posterior as a prior for the next experiment</p></li>
<li><p>e.g., in the example above, we currently had a prior <span class="math inline">Beta(4,4)</span> and observed <span class="math inline">k = 80</span> successes of <span class="math inline">n = 100</span> observations, deriving a posterior <span class="math inline">Beta(84,24)</span></p>
<ul>
<li>if we were to run this experiment again and had <span class="math inline">k = 60, n = 100</span>, we cwould have a posterior as follows <span class="math inline">\mathit{Beta}(a+k,b+n-k) = \mathit{Beta}(84+60,24+100-60)=\mathit{Beta}(144,64)</span></li>
<li>alternatively, if we collected all this data in the first place and had a prior <span class="math inline">Beta(4,4)</span> and for data <span class="math inline">k = 140, n = 200</span>, we’d have the same posterior: <span class="math inline">\mathit{Beta}(4+140,4+200-140)=\mathit{Beta}(144,64)</span></li>
</ul></li>
<li><p>so, we can keep building on our previous findings to inform future priors</p></li>
</ul>
</section>
<section id="summary" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="summary"><span class="header-section-number">2.10</span> Summary</h2>
<ul>
<li>we’ll continue down the same path we followed in this chapter moving forward:
<ol type="1">
<li>decide on an appropriate likelihood function</li>
<li>decide on prior for all the parameters involved in the likelihood function</li>
<li>using this model (the likelihood and the priors) derive the posterior distribution of each parameter</li>
<li>draw inferences about our research question basedon the posterior distribution of the parameter</li>
</ol></li>
</ul>
</section>
</section>
<section id="ch.-3---computational-bayesian-data-analysis" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Ch. 3 - Computational Bayesian data analysis</h1>
<ul>
<li>for real datasets, it was too cumbersome to do all the math to dertermine posterior distributions
<ul>
<li>thanks to probabilistic programming languages, we can define our models without have to do all the math</li>
</ul></li>
</ul>
<section id="deriving-the-posterior-through-sampling" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="deriving-the-posterior-through-sampling"><span class="header-section-number">3.1</span> Deriving the posterior through sampling</h2>
<ul>
<li>recall the example cloze task for <em>It’s raining, I’m going to take the…</em>, with the ‘correct’ answer <em>bus</em> (‘umbrella’ in the book but to me ‘bus’ is the most natural completion)
<ul>
<li>imagine 80 ‘successes’ and 20 ‘failures’</li>
<li>assuming a binomial distribution as the likelihood function, and <span class="math inline">Beta(a = 4, b = 4)</span> as a prior distribution for the cloze probability</li>
<li>if we can obtain samples from the posterior distribution or <span class="math inline">\theta</span>, instead of an analystically derived posterior distribution, given enough samples we will have a good <em>approximation</em> of the posterior distribution</li>
<li>‘<em>obtain samples</em>’ here means a situation similar to when we use <code>rbinom</code> or <code>rnorm</code> to obtain samples from a particular distribution</li>
<li>assume we used some probabilistic prgramming langauge to obtain 20,000 samples from the posterior distribution of the cloze probability <span class="math inline">\theta</span></li>
</ul></li>
</ul>
</section>
<section id="bayesian-regression-models-using-stan-brms" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="bayesian-regression-models-using-stan-brms"><span class="header-section-number">3.2</span> Bayesian regression models using Stan: brms</h2>
<ul>
<li>because of increased computing power and probabilistic programming languages (e.g., WinBUGS, JAGS, R-INLA, pymc3, Turing, Stan), Bayesian statistics is now more popular
<ul>
<li>these languages allow th euser to define models without the complexities of the sampling process</li>
<li>however, they require learning a new language as te statistical model must be specified using a specific syntax</li>
<li>additionally, some knowledge of the <em>sampling process</em> is needed to correctly parametrize the models and avoid convergence issues</li>
</ul></li>
<li>Bayesian inference in <code>R</code> is possible without having the fully specify the model thanks to <code>stanarm</code> and <code>brms</code> packages
<ul>
<li>both packages provide Bayesian equivalents of R model-fitting functions like <code>(g)lmer</code></li>
<li>both use Stan as the back-end for estimation and sampling</li>
</ul></li>
<li>for this part of the book we will focus on <code>brms</code>
<ul>
<li>it can be useful for a smooth transition from frequentist models to their Bayesian equivalents</li>
<li>it has the added benefit that the Stan code can be inspected via <code>brms::make_stancode()</code> and <code>brms::make_standata()</code></li>
<li>users can then customatize their models or learn from the code produced internally by <code>brms</code></li>
</ul></li>
</ul>
<section id="a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly"><span class="header-section-number">3.2.1</span> A simple linear model: A single subject pressing a button repeatedly</h3>
<ul>
<li>imagine having data from a single participant repeatedly pressing the spacebar as fast as possible
<ul>
<li>the data are response times in imilliseconds in each trial; we want to know how long it takes to press a key for this subject</li>
</ul></li>
<li>let’s model the data with thef ollowing assumptions:
<ol type="1">
<li>Tehre is a true (unknown) underlying time, <span class="math inline">\mu</span> ms, that the subject needs to press the psace bar</li>
<li>There is some noise in this process</li>
<li>The noise is normally distributed (this assumption is questionable given that response times are generally skewed, we will fix this assumption later)</li>
</ol></li>
</ul>
<p>This means that the likelihood for each observation <span class="math inline">n</span> will be:</p>
<p><span class="math display">
rt_{n} \sim Normal(\mu, \sigma)
\tag{3.2}
</span></p>
<ul>
<li>where <span class="math inline">n</span> = 1, …, <span class="math inline">N</span>, and <span class="math inline">rt</span> is the dependent variable (RTs in ms)
<ul>
<li>the variable <span class="math inline">N</span> indexes the total number of data points</li>
<li><span class="math inline">\mu</span> indicates the <em>location</em> of the normal distirbution function; the lcoation parameter shifts the distribution left or right on the horizontal axis</li>
<li>in the <em>normal distribution</em>, the location is also the mean of the distribution</li>
<li><span class="math inline">\sigma</span> indicates the <em>scale</em> of the distribution; as the scale decreases, the distribution gets narrower</li>
<li>for the normal distribution, the scale is also the standard deviation</li>
</ul></li>
<li>this same equation can be expressed as:</li>
</ul>
<p><span class="math display">
rt_n = \mu + \varepsilon \hbox{, where } \varepsilon_n \stackrel{iid}{\sim} \mathit{Normal}(0,\sigma) \tag{3.3}
</span></p>
<ul>
<li>this version of the model should be understood to mean that each data point <span class="math inline">rt_n</span> has some variability around a mean value <span class="math inline">\mu</span>, and that variability has standard deviation <span class="math inline">\sigma</span>
<ul>
<li>the term <span class="math inline">iid</span> (‘independent and identically distributed’) implies that each data point <span class="math inline">rt_n</span> is independently generated (i.e., not correlated with any of the other data points), and is coming from the same distribution (<span class="math inline">Normal(\mu,\sigma)</span>)</li>
</ul></li>
<li><strong>Frequentist model</strong>: that will give us the <em>maximu likelihood estimate</em> (the sample mean) of the time it takes to press the space bar
<ul>
<li>this owuld be enough ifnmroamtion to write the formular in <code>R</code>, <code>lm(rt ~ 1)</code></li>
</ul></li>
<li><strong>Bayesian linear model</strong>: we will also need to define <em>priors</em> for the two parameters of our model
<ul>
<li>let’s say we know for sure that the time it takes to press a key will be positive and lower than a minute (0-60,000ms), but we don’t want to make a commitment regarding which values are more likely</li>
<li>we encode what we know about the noise in the task in <span class="math inline">\sigma</span>: this parameter must be positive and we’ll assume any value below 2000ms is equally likely; such <em>flat</em> or <em>uniformative</em> priors are generaly strongly discouraged: it will almost never be the best approximation of what we know</li>
<li>let’s start with such priors, regardless:</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(0, 60000) \\
\sigma &amp;\sim \mathit{Uniform}(0, 2000)
\end{aligned}
\tag{3.4}
</span></p>
<ul>
<li>load the data from the <code>bcogsci</code> package</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-38_9f5ef3b6ed9ed26acedffb67af452867">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_spacebar"</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_spacebar)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
     rt trial
  &lt;int&gt; &lt;int&gt;
1   141     1
2   138     2
3   128     3
4   132     4
5   126     5
6   134     6</code></pre>
</div>
</div>
<ul>
<li>plot the data before you do anything else; as we suspected, the data lock a bit (positively) skewed, but let’s ignore that for now</li>
</ul>
<div class="cell" data-layout-align="center" data-hash="book_notes_cache/html/unnamed-chunk-39_b8dee431a3a4e167108085d05c522f29">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt)) <span class="sc">+</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Button-press data"</span>,</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"response times"</span>) <span class="sc">+</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>() <span class="sc">+</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="book_notes_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<section id="specifying-the-model-in-brms" class="level4">
<h4 class="anchored" data-anchor-id="specifying-the-model-in-brms">Specifying the model in <code>brms</code></h4>
<ul>
<li>fit the model defined by equations and </li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-40_c9fc59eec33f4624ea3164d657f88e0f">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>  rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>),</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> Intercept, <span class="co"># mean</span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">60000</span></span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>),</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> sigma, <span class="co"># sd</span></span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">2000</span></span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span></span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>some differences between this syntax and <code>lm()</code>:
<ol type="1">
<li><code>family = gaussian()</code> makes it explicity that the underlying likelihood function is a normal distribution</li>
</ol>
<ul>
<li>this is implicit in <code>lm()</code></li>
<li>the default for <code>brms</code> is <code>gaussian()</code></li>
<li>other linking function are possible, just like in the <code>glm()</code> function</li>
</ul>
<ol start="2" type="1">
<li><code>prior</code> takes as argument a vector of priors</li>
</ol>
<ul>
<li>this is optional, but we should <strong><em>always</em></strong> explicitly specify each prior; otherwise <code>brms</code> will define priors but they may or may not be appropriate</li>
<li>this is why we need <code>lb</code> (lower bound) and <code>upper bound</code> to specify the plausible range of values to sample from in cases where the distribution is restricted (e.g., reaction times cannot be negative, so <code>lb</code> must be at least 0)</li>
</ul>
<ol start="3" type="1">
<li><code>chains</code> refers to the number of independent runs for sampling</li>
</ol>
<ul>
<li>default = 4</li>
</ul>
<ol start="4" type="1">
<li><code>iter</code> refers to the number of iteratiosn that a sampler makes to sample from the posterior distribution of each paramter</li>
</ol>
<ul>
<li>default = 2000</li>
</ul>
<ol start="5" type="1">
<li><code>warmup</code> refers to the number of iterations from the start of sampling that are eventually discarded</li>
</ol>
<ul>
<li>default = <span class="math inline">\frac{`iter`}{2}</span></li>
</ul></li>
<li>the last 3 options determine the behaviour of the sampling algorithm</li>
</ul>
</section>
<section id="sampling-and-convergence-in-a-nutshell" class="level4">
<h4 class="anchored" data-anchor-id="sampling-and-convergence-in-a-nutshell">Sampling and convergence in a nutshell</h4>
<ul>
<li>our 4 chains start independently from each other
<ul>
<li>each chain “searches” for samples of the posterior distribution in a multidimensional space, where each parameter corresponds to a dimension</li>
<li>the shape of this space is determined by the priors and likelihood</li>
<li>chains start at a random location and each iteraton takes one sample each</li>
<li>when sampling begins, the samples may or may not belong to the posterior distributions of the parameters; eventually the chains end up in the vicinity of the posterior and from then on the samples will belong to the posterior</li>
</ul></li>
<li>therefore, when sampling starts the samples from the different chains can be far from each other; at some point they will <strong>converge</strong> and start delivering samples from the posterior distributions
<ul>
<li>typically the default values of <code>brms</code> will be sufficient to achieve convergence</li>
<li>if not, <code>brms</code> (but really <code>Stan</code>) will print out warnings with suggestions for fixin the convergence problems</li>
<li>this is why we remove the <code>warmup</code> samples, because the chains can start far apart and not in the posterior distribution</li>
<li>so, if we run 4 chains with 2000 iterations, we will obtain a total of 4000 iterations (<span class="math inline">\frac{4 chains * 2000 iterations}{2} = \frac{8000}{2}</span>)</li>
</ul></li>
</ul>
</section>
<section id="output-of-brms" class="level4">
<h4 class="anchored" data-anchor-id="output-of-brms">Output of <code>brms</code></h4>
<ul>
<li>once the model has ben fit (and assuming we didn’t get any warning messages about convergence), we can print out the samples of the posterior distributions using <code>as_draws_df()</code></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-41_eb75e4cb9a1bb13c284b4dd50eda319f">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press) <span class="sc">%&gt;%</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A draws_df: 3 iterations, 1 chains, and 4 variables
  b_Intercept sigma lprior  lp__
1         168    25    -19 -1683
2         168    25    -19 -1683
3         169    26    -19 -1683
# ... hidden reserved variables {'.chain', '.iteration', '.draw'}</code></pre>
</div>
</div>
<ul>
<li><code>b_Intercept</code> corresponds to our <span class="math inline">\mu</span>; we can ignore the last 2 columns</li>
<li>plot the density and trace plot of each paramter after warmup:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-42_adc3c8c618758d0609231d79f38ac160">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>and print the object with the brms fit</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-43_1223c1b5eb264840bd5151cdd9442b9b">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>fit_press</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.64      1.26   166.21   171.08 1.00     3771     2796

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    25.00      0.94    23.27    26.90 1.00     3089     2657

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>or with <code>posterior_summary()</code></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-44_b5bc7f721abd33a0097ba432b600477c">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior_summary</span>(fit_press)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Estimate Est.Error        Q2.5       Q97.5
b_Intercept   168.64110 1.2633950   166.20903   171.08023
sigma          24.99744 0.9378402    23.27317    26.90361
lprior        -18.60300 0.0000000   -18.60300   -18.60300
lp__        -1683.71541 0.9553365 -1686.36606 -1682.77021</code></pre>
</div>
</div>
<ul>
<li><code>Estimate</code> is just the <em>mean</em> of the posterior samples</li>
<li><code>Est.Error</code> is the <em>standard deviation</em> of the posterior</li>
<li><code>CI</code>s mark the upper and lower bounds of the 95% <em>credible intervals</em></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-45_0e30f4d64784c44c6fdc742a34456e19">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 168.6411</code></pre>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-46_033074605d6d103327086150ae912e1f">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sd</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.263395</code></pre>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-47_af533705d521c2b5a3a7262380b6fe12">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">quantile</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    2.5%    97.5% 
166.2090 171.0802 </code></pre>
</div>
</div>
<ul>
<li>summary also provides:
<ul>
<li><code>Rhat</code>: compares between- and within-chain estimate of each parameter
<ul>
<li>is &gt;1 when chains have not mixed well; we can only rely on the model if the R-hats for <em>all</em> parameters are &lt;1.05 (warnings will appear otherwise)</li>
</ul></li>
<li><code>Bulk_ESS</code>: ‘bulk effective sample size’ is a measure of sampling efficienty in the bulk of the posterior distribution
<ul>
<li>i.e., the effectice sample size for the mean and median estimates</li>
</ul></li>
<li><code>Tail_ESS</code>: ‘tail effective sample size’: the sampling efficiency at the tails of the distribution
<ul>
<li>i.e., the minimum of effective sample sizes for 5% and 95% quantiles</li>
</ul></li>
<li>the number of post-warmup samples is generally lower than the effective sample size, because the samples from the chains are not independent (they are correlated to some extent) , and carry less information about the posterior distribution in comparison to <em>independent</em> samples</li>
</ul></li>
<li>very low sample size indicates sampling problems (and will produce warnings) and in general appear when chains are not properly mixed
<ul>
<li>as a rule of thumb, a minimum of 400 effective sample size is required for statistical summaries</li>
</ul></li>
<li>we wee our model fits without problems, and we get some posterior distribution for our parameters, but we should ask the following questions:</li>
</ul>
<ol type="1">
<li>What informationa re the priors encoding? Do the priors make sense?</li>
<li>Does the likelihood assumed int he model make sense for the data?</li>
</ol>
<ul>
<li>to answer these questions we can look at the <em>prior</em> and <em>posterior distributions</em> and we can do sensitivity analyses</li>
</ul>
</section>
</section>
</section>
<section id="prior-predictive-distribution" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="prior-predictive-distribution"><span class="header-section-number">3.3</span> Prior predictive distribution</h2>
<ul>
<li>we had the following priors in our linear model:</li>
</ul>
<p><span class="math display">
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(0, 60000) \\
\sigma &amp;\sim \mathit{Uniform}(0, 2000)
\end{aligned}
\tag{3.5}
</span></p>
<ul>
<li>these priors encode assumptions about our data</li>
<li>to understand these assumptions, we are going to generate data from the model
<ul>
<li>such data, which is generated entirely by the <em>prior distributions</em>, is called the <strong>prior predictive distribution</strong></li>
<li>generating prior predictive distributions repeatedly helps us to check whether the priors make sense; we want to know whether the priors generate realistic-looking data</li>
</ul></li>
<li>to do this, repeat the following many times:
<ol type="1">
<li>Tae one sample from each of the priors</li>
<li>Plug those samples into the porbability density/mass function used as the likelihood int he model to generate a dataset <span class="math inline">y_{pred_1}, ..., y_{pred_n}</span></li>
</ol>
<ul>
<li>each sample is an imaginary or potential data set</li>
</ul></li>
<li>create a function that does this:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-48_f1917a2079269d8329d422a7a90fd135">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>normal_predictive_distribution <span class="ot">&lt;-</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(mu_samples, sigma_samples, N_obs) {</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># empty data frame with headers:</span></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>    df_pred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">trialn =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">rt_pred =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="fu">numeric</span>(<span class="dv">0</span>)</span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i iterates from 1 to the length of mu_samples,</span></span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># which we assume is identical to</span></span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the length of the sigma_samples:</span></span>
<span id="cb122-12"><a href="#cb122-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(mu_samples)) {</span>
<span id="cb122-13"><a href="#cb122-13" aria-hidden="true" tabindex="-1"></a>      mu <span class="ot">&lt;-</span> mu_samples[i]</span>
<span id="cb122-14"><a href="#cb122-14" aria-hidden="true" tabindex="-1"></a>      sigma <span class="ot">&lt;-</span> sigma_samples[i]</span>
<span id="cb122-15"><a href="#cb122-15" aria-hidden="true" tabindex="-1"></a>      df_pred <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb122-16"><a href="#cb122-16" aria-hidden="true" tabindex="-1"></a>        df_pred,</span>
<span id="cb122-17"><a href="#cb122-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">tibble</span>(</span>
<span id="cb122-18"><a href="#cb122-18" aria-hidden="true" tabindex="-1"></a>          <span class="at">trialn =</span> <span class="fu">seq_len</span>(N_obs), <span class="co"># 1, 2,... N_obs</span></span>
<span id="cb122-19"><a href="#cb122-19" aria-hidden="true" tabindex="-1"></a>          <span class="at">rt_pred =</span> <span class="fu">rnorm</span>(N_obs, mu, sigma),</span>
<span id="cb122-20"><a href="#cb122-20" aria-hidden="true" tabindex="-1"></a>          <span class="at">iter =</span> i</span>
<span id="cb122-21"><a href="#cb122-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb122-22"><a href="#cb122-22" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb122-23"><a href="#cb122-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb122-24"><a href="#cb122-24" aria-hidden="true" tabindex="-1"></a>    df_pred</span>
<span id="cb122-25"><a href="#cb122-25" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>the code below produces 1000 samples of the prior predictive distribution of the model we defined for <code>fit_press</code> from the <code>df_spacebar</code> data, that had 361 trials
<ul>
<li>this code will produce 361,000 predicted values (361 observations x 1000 simulations)</li>
<li>we could also use the option <code>sample_prior = "only"</code> in our <code>brms</code> model, but it still depends on Stam’s sampler which uses Hamiltonian Monte Carlo, and can fail to converge especially with uninformative priors</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-49_97a59d49c4684232da3f2ab2374c72fe">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">60000</span>)</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">2000</span>)</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>22.529 sec elapsed</code></pre>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-50_df18d052849e2f0b94b24879d98b994e">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>prior_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 361,000 × 3
   trialn rt_pred  iter
    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1      1  25994.     1
 2      2  26023.     1
 3      3  25844.     1
 4      4  25733.     1
 5      5  25895.     1
 6      6  25843.     1
 7      7  25943.     1
 8      8  26099.     1
 9      9  26201.     1
10     10  25676.     1
# … with 360,990 more rows</code></pre>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Box 3.1: A more efficint prior predictive distribution function
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>alternatively, we could use the <code>purr::map2_dfr()</code> functions as below, which would run a bit faster:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-51_fd1f659253a8c55141ca22afe32eadfc">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the function:</span></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>normal_predictive_distribution <span class="ot">&lt;-</span> <span class="cf">function</span>(mu_samples,</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>                                           sigma_samples,</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>                                           N_obs) {</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map2_dfr</span>(mu_samples, sigma_samples, <span class="cf">function</span>(mu, sigma) {</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">trialn =</span> <span class="fu">seq_len</span>(N_obs),</span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">rt_pred =</span> <span class="fu">rnorm</span>(N_obs, mu, sigma)</span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">.id =</span> <span class="st">"iter"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .id is always a string and</span></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># needs to be converted to a number</span></span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> <span class="fu">as.numeric</span>(iter))</span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb127-16"><a href="#cb127-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the timing:</span></span>
<span id="cb127-17"><a href="#cb127-17" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb127-18"><a href="#cb127-18" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb127-19"><a href="#cb127-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb127-20"><a href="#cb127-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb127-21"><a href="#cb127-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb127-22"><a href="#cb127-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb127-23"><a href="#cb127-23" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<ul>
<li>let’s look at the first 18 samples of the <em>prior predictive distribution</em></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/fig-samples18_f928f3f32aee64c9e7601a097f8b7593">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="sc">%&gt;%</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter <span class="sc">&lt;=</span> <span class="dv">18</span>) <span class="sc">%&gt;%</span></span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt_pred)) <span class="sc">+</span></span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"18 samples"</span>,</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x=</span><span class="st">"predicted rt (ms)"</span>) <span class="sc">+</span></span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..)) <span class="sc">+</span></span>
<span id="cb128-7"><a href="#cb128-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb128-8"><a href="#cb128-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb128-9"><a href="#cb128-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.x =</span></span>
<span id="cb128-10"><a href="#cb128-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">40</span>, <span class="at">vjust =</span> <span class="dv">1</span>, <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">14</span>)</span>
<span id="cb128-11"><a href="#cb128-11" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb128-12"><a href="#cb128-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb128-13"><a href="#cb128-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.0005</span>),</span>
<span id="cb128-14"><a href="#cb128-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.00025</span>, <span class="fl">0.0005</span>), <span class="at">name =</span> <span class="st">"density"</span></span>
<span id="cb128-15"><a href="#cb128-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb128-16"><a href="#cb128-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>iter, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-samples18" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="book_notes_files/figure-html/fig-samples18-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: 18 samples</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Figure @fig-samples18 shows prior data sets that are not realistic: the data shows RT distributions are symmetrical (and we know they are generally right-skewed)
<ul>
<li>worse, a few have <em>negative</em> RT values</li>
</ul></li>
<li>so, our priors led to unrealistic values in our prior predictive distribution
<ul>
<li>so our priors weren’t very useful</li>
</ul></li>
<li>so, what priors should we have used?</li>
</ul>
</section>
<section id="the-influence-of-priors-sensitivity-analysis" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="the-influence-of-priors-sensitivity-analysis"><span class="header-section-number">3.4</span> The influence of priors: sensitivity analysis</h2>
<ul>
<li>there are 4 main classes of priors in this book
<ul>
<li>but there is no fixed nomenclature for these kind of priors, there’s no current naming convention in the field</li>
</ul></li>
</ul>
<section id="flat-uninformative-priors" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="flat-uninformative-priors"><span class="header-section-number">3.4.1</span> Flat, uninformative priors</h3>
<ul>
<li>the idea behind uninformative priors is to let the data ‘speak fo ritself’ and to not bias the statistical inference iwth ’subjective priors</li>
<li>issues with this approach:
<ul>
<li>the prior is as subjective as the likelihood, and different choices of likelihood might have a stronger mpace on the posterior than choice of priors</li>
<li>uninformative priors are in general unrealistic and give equal weight to all values within the support of the prior distribution</li>
<li>unifnromative priors m ake the sampling slower and might lead to convergence problems</li>
<li>it is not always clear which parametrization of a given distribution the flat priors should be assigned to</li>
</ul></li>
<li>in our space bar button press example, and uniformative prior would be:</li>
</ul>
<p><span class="math display">
\mu \sim Uniform(-10^{20}, 10^{20})
</span> - this is a strange prior because it’s on them millisecond scale, and allows for impossibly large positive values, as well as negative values which are not possible at all</p>
</section>
<section id="regularising-priors" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="regularising-priors"><span class="header-section-number">3.4.2</span> Regularising priors</h3>
<ul>
<li><p>used when we don’t have <em>much</em> prior information or knowledge</p>
<ul>
<li>sometimes called <em>weakly informative</em> or <em>mildly informative</em></li>
</ul></li>
<li><p>these are priors that down-weight extreme values (they provide <em>regularization</em>)</p>
<ul>
<li>usually not very informative, and mostly let the likelihood dominate in determining the posteriors</li>
</ul></li>
<li><p>these are <strong>theory-neutral</strong> priors; they do not bias the parameters to values spported by any prior belief or theory</p></li>
<li><p>these priors help stabilize computation</p></li>
<li><p>in our button press example, a regularizing prior owuld be</p></li>
</ul>
<p><span class="math display">
\mu \sim Normal_+(0,1000)
</span> - where <span class="math inline">Normal_+</span> indicates that the normal distribution is truncated at 0ms (i.e., is cut off at 0, so no negative values are possible) - this is regularizing because it rules out negative button-pressing times and down-weights extreme values over 2000ms</p>
</section>
<section id="principled-priors" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="principled-priors"><span class="header-section-number">3.4.3</span> Principled priors</h3>
<ul>
<li>these priors encode all (or most of) the theory-neutral information
<ul>
<li>one generally knows what one’s data do and do not look like, it is possible to build priors that truly reflect the properties of potential data sets</li>
</ul></li>
<li>in our button press example, a principled prior could be</li>
</ul>
<p><span class="math display">
\mu \sim Normal_+(250,100)
</span> - it is not overly restrictive, but represents a guess about plausible button-pressing tiems - <em>prior predictive checks</em> using principled priors should produce realisitic distributions of the dependent variable</p>
</section>
<section id="informative-priors" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="informative-priors"><span class="header-section-number">3.4.4</span> Informative priors</h3>
<ul>
<li>for cases wehre a lot of prior knowledge exists, and not much data</li>
<li>unless there is a <em>very</em> good reason to use informative priors, it is not a good idea to let the priors have too much influence on the posterior
<ul>
<li>e.g., investigating a language-imparied population from which we can’t get many subjects, but a lot of previous published work exists on the topic</li>
</ul></li>
<li>in our button press data, an informative prior could be based on the meta-analysis of previously published or existing data, or the result of prior elicitation from an expert on the topic under investigation
<ul>
<li>e.g., the following prior:</li>
</ul></li>
</ul>
<p><span class="math display">
\mu \sim Normal_+(200,20)
</span></p>
<ul>
<li>this will have some influence ont he posterior for <span class="math inline">\mu</span>, especially when one has relatively sparse data</li>
</ul>
</section>
</section>
<section id="re-visiting-the-button-press-example-with-different-priors" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="re-visiting-the-button-press-example-with-different-priors"><span class="header-section-number">3.5</span> Re-visiting the button-press example with different priors</h2>
<ul>
<li>what would happen if even wider priors were used for the model we defined earlier?
<ul>
<li>suppose every mean between -10^6 and 10^6 is assumed to be equally likely</li>
<li>this is clearly unrealistic and nonsensical; we don’t expect negative values</li>
<li>for the sd, we could assume any value between 0 and 10^6 is equally likely; the likelihood remains unchanged</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(-10^{6}, 10^{6}) \\
\sigma &amp;\sim \mathit{Uniform}(0,  10^{6})
\end{aligned}
\tag{3.6}
</span></p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-53_87542645f9928363f5a332cfd47adca0">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The default settings are used when they are not set explicitly:</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4 chains, with half of the iterations (set as 3000) as warmup.</span></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>fit_press_unif <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> Intercept,</span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,</span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> sigma,</span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>)</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb129-16"><a href="#cb129-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">3000</span>,</span>
<span id="cb129-17"><a href="#cb129-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the following needed to be changed to achieve convergence</span></span>
<span id="cb129-18"><a href="#cb129-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">99</span>,</span>
<span id="cb129-19"><a href="#cb129-19" aria-hidden="true" tabindex="-1"></a>                 <span class="at">max_treedepth =</span> <span class="dv">15</span>)</span>
<span id="cb129-20"><a href="#cb129-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>even with these priors, the output of the model is virtually dientical to the previous one</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-54_4141d53681a4837fdc0cdcaccea83cf2">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>fit_press_unif</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 3000; warmup = 1500; thin = 1;
         total post-warmup draws = 6000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.63      1.36   165.98   171.31 1.00     4038     3257

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    25.03      0.93    23.20    26.95 1.01      549      499

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-55_b9f4dca95f29e5ee71bc75421a0a9fb0">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>fit_press</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.64      1.26   166.21   171.08 1.00     3771     2796

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    25.00      0.94    23.27    26.90 1.00     3089     2657

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>what about very informative priors?
<ul>
<li>assume the mean values very close to 400ms are the most likely, and that the sd of RTs is very close to 100ms</li>
<li>this is not very sensical, 200ms seems like a more realistic mean for button-press</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{aligned}
\mu &amp;\sim \mathit{Normal}(400, 10) \\
\sigma &amp;\sim \mathit{Normal}_+(100, 10) \end{aligned}
\tag{3.7}
</span> - if we refit our model:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-56_a3b159c51c3ebc62c320e1af6fd3aa28">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>fit_press_inf <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">400</span>, <span class="dv">10</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># brms knows that SDs need to be bounded</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to exclude values below zero:</span></span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="at">class =</span> sigma)</span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>we see that the likelihood mostly dominates again, and the new posterior means and CrIs are only shifted by a few milliseconds when these unrealistic but informative priors are used:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-57_f8f4615eb3d2349b530d150bcf01ccea">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>fit_press_inf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   172.93      1.43   170.12   175.68 1.00     2591     2528

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    26.09      1.04    24.13    28.23 1.00     2380     2404

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>as a final example of sensitivity analysis, let’s choose some <em>principled</em> priors</li>
<li>assuming we have some prior experience, let’s suppose the mean RT is expected to be arround 200ms, with a 95% probability of the mean ranging from 0 to 400ms
<ul>
<li>this uncertainty is perhaps unreasonably large, but one might want to allow a bit more uncertainty than one really thinks is reasonable (sometimes called <em>Cromwell’s rules</em>)</li>
<li>let’s then decide on the prior <span class="math inline">Normal(200,100)</span></li>
<li>with just a single participnt and a simple task, the residual standard deviation <span class="math inline">\sigma</span> shouldn’t be very large: let’s settle on a location of 50ms for a trucnated normal distribution, but still allow for relatively large uncertainty:</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{aligned}
\mu &amp;\sim \mathit{Normal}(200, 100) \\
\sigma &amp;\sim \mathit{Normal}_+(50, 50)
\end{aligned}
</span></p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-58_50b9ba09a17faa11ef884e2f6d724cb1">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>fit_press_prin <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">200</span>, <span class="dv">100</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="at">class =</span> sigma)</span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>again, the estimates are virtually the same as before:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-59_77d923aae1827bf7eec7c7240239a855">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>fit_press_prin</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.66      1.31   166.08   171.30 1.00     3670     2579

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    24.99      0.92    23.27    26.84 1.00     2768     2877

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li><p>these examples do not mean priors <em>never</em> matter</p></li>
<li><p>when there is enough data, the likelihood will dominate in determing the posterior distributions</p>
<ul>
<li>what constitutes ‘enough’ data is also a function of the complexity of the model; more complex models require more data, as a rule</li>
</ul></li>
<li><p>regularized, principled priors (i.e., those that are more consistent with our a priori beliefs about the data) in general speed-up model convergence</p></li>
<li><p>to see how influenced by the priors the posterior is, it’s wise to carry out a <strong>sensitivity analysis</strong>: try different priors and either verify that the posterior doesn’t chagne drastically, or report how the posterior is affected by some specific priors</p></li>
</ul>
</section>
<section id="posterior-predictive-distribution" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="posterior-predictive-distribution"><span class="header-section-number">3.6</span> Posterior predictive distribution</h2>
<ul>
<li>the <strong>posterior predictive distribution</strong> is a <em>collection of data sets generated from the model</em> (the likelihood and the priors)</li>
<li>having obtained the posterior distributions of the parameters after taking into account the data, the posterior distributions can be used to generate future data from the model
<ul>
<li><p>i.e., given the <em>posterior distribution</em> of the parameters of the model, the <em>posterior</em> <strong><em>predictive</em></strong> <em>distribution</em> gives us some indication of what future data might look like</p></li>
<li><p>once the posterior distributions <span class="math inline">p(\theta|y)</span> are available, the predictions based on these distributions, by integrating out the parameters</p></li>
</ul></li>
</ul>
<p><span class="math display">
p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} ) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}, \boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}= \int_{\boldsymbol{\Theta}}
p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta},\boldsymbol{y})p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}
</span> - assuming the past and future observations are conditionally independent given <span class="math inline">\theta</span>, the above equation can be written as:</p>
<p><span class="math display">
p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} )=\int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta}) p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}
\tag{3.8}
</span></p>
<ul>
<li>this <strong>posterior predictive distribution</strong> has important differences from predictions obtained with the <em>frequentist</em> approach
<ul>
<li><strong>frequentist</strong>: gives a point estimate of each predicted observation given the maximum likelihood estimate of <span class="math inline">\theta</span> (a point value)</li>
<li><strong>Bayesian</strong>: gives a <em>distribution</em> of values for each predicated observation</li>
</ul></li>
<li>as with the <em>prior</em> predictive distribution, the integration can be carried out computationally by generating samples from the posterior predictive distribution
<ul>
<li>we can use the same function <code>normal_predictive_distribution()</code> as created above; the only difference is that the samples come from the <strong>posterior</strong>, not from <code>mu</code> and <code>sigma</code></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-60_fb0eda7ccd0bc4488bc58c313706ad8a">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>sigma</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a><span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,444,000 × 3
   trialn rt_pred  iter
    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1      1    149.     1
 2      2    129.     1
 3      3    141.     1
 4      4    168.     1
 5      5    142.     1
 6      6    150.     1
 7      7    195.     1
 8      8    149.     1
 9      9    137.     1
10     10    177.     1
# … with 1,443,990 more rows</code></pre>
</div>
</div>
<ul>
<li>the function <code>brms::posterior_predict()</code> is convenient, as it delivers samples from the posterior predictive distribution
<ul>
<li>in a matrix, with the samples as rows and observations (data-points) as columns; so for <code>fit_press</code> there’d be 361 columns</li>
<li>N.B., if the model is fit with <code>sample_prior = "only"</code>, the dependent variable is ignored and <code>posterior_predict</code> will give samples from the <em>prior</em> predictive distribution</li>
</ul></li>
<li>the <strong>posterior predictive distirubtion</strong> can be used to examine the ‘descriptive adequacy’ of the model under consideration
<ul>
<li>this is called <strong><em>posterior predictive checks</em></strong></li>
<li>the goal is to establish that the posterior predictive data look more or less similar to the observed data</li>
<li>achieveing ‘descriptive adequacy’ means the current data <em>could</em> have been generated by the model</li>
</ul></li>
<li>pass a test of descriptive adequacy is not strong evidence in favour of a model, but a major failure in descriptive adequacy can be interpreted as strong evidence against a model (i.e., passing the test is <strong><em>necessary but not sufficient</em></strong> evidence in favour of the model)</li>
<li>in addition, one should check that the <em>range</em> of predictions that the model makes is reasonably constrained
<ul>
<li>if a model can capture any possible outcome, then the model fit to a particular data set is not so informative</li>
<li>thus, posterior predictive checking is important but only a sanity check to assess whether the model behaviour is reasonable</li>
</ul></li>
<li>we can usually just use the plot functions from <code>brms</code>
<ul>
<li>e.g., <code>ppcheck()</code> takes as arguments the model, number of predicted data sets, and the type of visualisation
<ul>
<li>in these plots, the <strong>observed data</strong> are plotted as <span class="math inline">y</span>, and <strong>predicted data</strong> as <span class="math inline">y_{rep}</span></li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-61_552cb911b282e9156b51e3ed6f1d9e81">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co"># histograms</span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">11</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"hist"</span> <span class="co"># plot type</span></span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-61-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-62_c6348d064c91b185cedacac811d78618">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># layered density plots</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"dens_overlay"</span> <span class="co"># plot type</span></span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-62-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>we see the data (<span class="math inline">y</span>) is slightly skewed and has no values smaller than 100ms, but the predictive distributions are centered and symmetrical
<ul>
<li>so the posterior predictive check shows a slight mismatch between the observed and predicted data</li>
</ul></li>
<li>Can we build a better model? Let’s see…</li>
</ul>
<section id="comparing-different-likelihoods" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="comparing-different-likelihoods"><span class="header-section-number">3.6.1</span> Comparing different likelihoods</h3>
<ul>
<li>response times are not usually normally distributed
<ul>
<li><em>log-normal</em> distribution would be more realistic</li>
</ul></li>
</ul>
</section>
<section id="the-log-normal-likelihood" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="the-log-normal-likelihood"><span class="header-section-number">3.6.2</span> The log-normal likelihood</h3>
<ul>
<li>if <span class="math inline">y</span> is log-normally distributed, that means that <span class="math inline">log(y)</span> is normally distributed
<ul>
<li>the log-normal distribution is also defined using the parameters location (<span class="math inline">\mu</span>) and scale (<span class="math inline">\sigma</span>), but these are on the log ms scale and correspond to the mean and standard deviation of the logarithm of the data <span class="math inline">y</span>, <span class="math inline">log(y)</span>, which will be normally distributed</li>
<li>therefore, when we model some data <span class="math inline">y</span> using the log-normal likelihood, the parameters <span class="math inline">\mu</span> and <span class="math inline">\sigma</span> are on a different scale than the data <span class="math inline">y</span>, which is represented here:</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{aligned}
\log(\boldsymbol{y}) &amp;\sim \mathit{Normal}( \mu, \sigma)\\
\boldsymbol{y} &amp;\sim \mathit{LogNormal}( \mu, \sigma)
\end{aligned}
\tag{3.9}
</span></p>
<ul>
<li>we can obtain samples from the log-normal distribution, using the normal distribution by first setting an auxiliary variable, <span class="math inline">z</span>, so that <span class="math inline">z = log(y)</span>
<ul>
<li>so, <span class="math inline">z \sim Normal(\mu, \sigma)</span></li>
<li>then we can use <span class="math inline">exp(z)</span> as samples from the <span class="math inline">LogNormal(\mu,\sigma)</span></li>
<li>since exp(<span class="math inline">z</span>) = exp(log(<span class="math inline">y</span>)) = <span class="math inline">y</span></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-63_d1371b520358a8b7c28c2a1a77b7a542">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">500000</span></span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a log-normal distribution</span></span>
<span id="cb147-5"><a href="#cb147-5" aria-hidden="true" tabindex="-1"></a>sl <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(N, mu, sigma)</span>
<span id="cb147-6"><a href="#cb147-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sl), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb147-7"><a href="#cb147-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb147-8"><a href="#cb147-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Log-normal distribution</span><span class="sc">\n</span><span class="st">"</span>) <span class="sc">+</span></span>
<span id="cb147-9"><a href="#cb147-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-63-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a normal distribution,</span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and then exponentiate them</span></span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>sn <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(N, mu, sigma))</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sn), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Exponentiated samples from</span><span class="sc">\n</span><span class="st">a normal distribution"</span>) <span class="sc">+</span></span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-63-2.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood"><span class="header-section-number">3.6.3</span> Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</h3>
<ul>
<li>if we assume that response times are log-normally distributed, we’ll need to change our likelihood function as follows:</li>
</ul>
<p><span class="math display">
rt_n \sim LogNormal(\mu, \sigma)
</span></p>
<ul>
<li>but now <strong><em>the scale of our priors needs to change</em></strong>!
<ul>
<li>starting with uniform priors for ease of exposition, although these are really not appropriate:</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{align}
\mu &amp;\sim Uniform(0,11)\\
\sigma &amp;\sim Uniform(0,1)
\end{align}
</span></p>
<ul>
<li>because the parameters are on a different scale than the dependent variable, their interpretation chagnes and it is more complex than dealing with a linear model that assumes a normal likelihood (<strong>location and scale do not coincide with the mean and standard deviation of the log-normal</strong>)
<ul>
<li><strong><em>the location, <span class="math inline">\mu</span></em></strong>: in our previous linear model, <span class="math inline">\mu</span> represented the mean
<ul>
<li>now the mean needs to be calculated in the following way: exp(<span class="math inline">\frac{\mu + \sigma^2}{2}</span>)</li>
<li>i.e., in the log-normal, the mean is dependent on both <span class="math inline">\mu</span> and <span class="math inline">\sigma</span></li>
<li>the median is just exp(<span class="math inline">\mu</span>)</li>
<li>N.B., the prior of <span class="math inline">\mu</span> is not on the milliseconds scale, but the log milliseconds scale</li>
</ul></li>
<li><strong><em>the scale, <span class="math inline">\sigma</span></em></strong>: the standard deviation of the normal distribution of log(<span class="math inline">y</span>)
<ul>
<li>the standard deviation of a log-normal distribution with <em>location</em> <span class="math inline">\mu</span> and <em>scale</em> <span class="math inline">\sigma</span> will be exp(<span class="math inline">\frac{\mu + \sigma^2}{2} \times \sqrt{exp(\sigma^2) - 1}</span>)</li>
<li>unlike the normal distribution, the spread of the log-normal distribution depends on both <span class="math inline">\mu</span> and <span class="math inline">\sigma</span></li>
</ul></li>
</ul></li>
<li>to understand the meaning of our priors on the millisecond scale, we need to take into account both the priors and the likelihood; this can be done by generating a <strong>prior predictive distribution</strong>
<ul>
<li>we can just exponentiate the samples produced by <code>normal_predictive_distribution()</code></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-64_4076add2d9501ea9826a7cade0bcd64e">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">11</span>)</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>prior_pred_ln <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt_pred =</span> <span class="fu">exp</span>(rt_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>we can’t generate negative values anymore (exp(any finite number) &gt; 0)
<ul>
<li>these priors might work in the sense that the model might converge, but it would be better to have <strong>regularizing priors</strong> for the model, such as:</li>
</ul></li>
</ul>
<p><span class="math display">
\begin{align}
\mu &amp;\sim Normal(6,1.5)\\
\sigma &amp;\sim Normal_+(0,1)
\end{align}
</span></p>
<ul>
<li>the prior for <span class="math inline">\sigma</span> is a truncated distribution
<ul>
<li>although its location is 0, this is not the mean</li>
<li>we can calculate its approximate mean from a large number of random samples of the prior distribution using the function <code>extraDistr::rtnorm()</code>, where the parameter <code>a = 0</code> expresses the fact that the normal distribution is truncated from the left at 0</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-65_b55d7b3c09ab9194b06765476210e80f">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">rtnorm</span>(<span class="dv">100000</span>, <span class="co"># generate n = 100,000</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>            <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">a =</span> <span class="dv">0</span> <span class="co"># truncate at 0</span></span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7964096</code></pre>
</div>
</div>
<ul>
<li>and even before generating the prior predictive distribution, we can calculate the values within which we are 95% sure the expected median of the observations will lie
<ul>
<li>we can do this by looking at what happens at 2 standard deviations away from the mean of the prior, <span class="math inline">\mu</span>, that is <span class="math inline">6 - 2 \times 1.5</span> and <span class="math inline">6 + 2 \times 1.5</span>, and exponentiating these values</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-66_a0036016992c71ca018f994923b9deb2">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(<span class="at">lower =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>),</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">higher =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>)),</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> lower higher 
  20.1 8103.1 </code></pre>
</div>
</div>
<ul>
<li>so our prior for <span class="math inline">\mu</span> is still not too informative (these are medians, the actual values generated by the log-normal distribution can be much more spread out)
<ul>
<li>we can now plot the distribution of some representative statistics of the prior preditive distributions using <code>brms</code> to sample from the priors ignoring the <code>rt</code> data, by setting <code>sample_prior = "only"</code></li>
<li>if we want to use <code>brms</code> to generate prior predictive data <em>before</em> collecting the data, we do need to have some non-<code>NA</code> vlaues as the dependent variable, <code>rt</code></li>
<li>setting <code>sample_prior = "only"</code> will ignore the data, but we still need to add it: in this case, we add a vector of 1 as “data”</li>
<li>we need to specify that the familiy is <code>lognormal()</code></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-67_c47c93cdd9cf85fee749fe3aaeeed2b6">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create place-holder data (for cases where we don't yet have any data but want to check out the prior predictive distribution)</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>df_spacebar_ref <span class="ot">&lt;-</span> df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">n</span>()))</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a><span class="co"># now run a model that runs only prior samples</span></span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>fit_prior_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar_ref,</span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_prior =</span> <span class="st">"only"</span>, <span class="co"># this is how we tell the model to only produce priors!</span></span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">9</span>)</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li><p>to avoid the warnings, we need to increase the <code>adapt_delta</code> parameter’s default value from 0.8 to 0.95 to simulate the data</p></li>
<li><p>plot the prior predictive distribution of means with the following code</p>
<ul>
<li>to get a prior predictive distribution, we want to ignore the data, so set <code>prefix = "ppd"</code></li>
<li>IMPORTANTLY, this should be run on a model that had <code>sample_prior = "only"</code>, and therefore ignored the data; otherwise we’d just be plotting the posterior</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-68_c2acd6ec3228f39671c1080937ab46e9">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb156-7"><a href="#cb156-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb156-8"><a href="#cb156-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb156-9"><a href="#cb156-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb156-10"><a href="#cb156-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb156-11"><a href="#cb156-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-68-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>to plot the distribution of mimimum and maximum values, replace <code>mean</code> with <code>min</code> and <code>max</code></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-69_4be0255179ffe25255489648f6b2cc29">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb157-11"><a href="#cb157-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span>
<span id="cb157-12"><a href="#cb157-12" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb157-13"><a href="#cb157-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb157-14"><a href="#cb157-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb157-15"><a href="#cb157-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb157-16"><a href="#cb157-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb157-17"><a href="#cb157-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb157-18"><a href="#cb157-18" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb157-19"><a href="#cb157-19" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb157-20"><a href="#cb157-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb157-21"><a href="#cb157-21" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb157-22"><a href="#cb157-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of minimum values"</span>)</span>
<span id="cb157-23"><a href="#cb157-23" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb157-24"><a href="#cb157-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb157-25"><a href="#cb157-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb157-26"><a href="#cb157-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb157-27"><a href="#cb157-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb157-28"><a href="#cb157-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb157-29"><a href="#cb157-29" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"10"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb157-30"><a href="#cb157-30" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb157-31"><a href="#cb157-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb157-32"><a href="#cb157-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb157-33"><a href="#cb157-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of maximum values"</span>)</span>
<span id="cb157-34"><a href="#cb157-34" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_grid</span>(p1, p2, p3, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-69-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>these plots show that the priors that we are using are still quite uninformative
<ul>
<li>the tails of the prior predictive distributions that correspond to our normal priors (shown above) are even further to the right, reaching more extreme values than for the prior predictive distributions generated by uniform priors</li>
<li>our new priors are still far from representing our prior knowledge</li>
<li>we can use summary statistics to test whether the priors are in a plausible range by defining the extreme data that would be very implausible to ever observe</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-70_83bf472891222ab2a89825c24387f7af">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>fit_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb158-7"><a href="#cb158-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb158-8"><a href="#cb158-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>when we look at the summary of the posterior, the parameters are on the log-scale</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-71_a93447dc3922dc693a56d0f14ec37d00">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>fit_press_ln</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     5.12      0.01     5.11     5.13 1.00     4595     2847

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.13      0.00     0.13     0.14 1.00     3373     3134

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>if we want to know how long it takes to press the space bar in milliseconds, we need to transform the <span class="math inline">\mu</span> (or <code>Intercept</code> in the model) to milliseconds; we know that the median of the log-normal distribution is exp(<span class="math inline">\mu</span>), so we do the following to calculate an estimate in milliseconds:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-72_275fa1e870454d278da3a45d3c782922">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>estimate_ms <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">as_draws_df</span>(fit_press_ln)<span class="sc">$</span>b_Intercept)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>if we want to know the mean and 95% CrI of these samples:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-73_96c8c20ad3770e7771c115cc532a272e">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(estimate_ms), <span class="fu">quantile</span>(estimate_ms, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    mean     2.5%    97.5% 
167.0970 164.8475 169.3246 </code></pre>
</div>
</div>
<ul>
<li>we can now check whether our <em>predicted data sets</em> look similar to the observed data</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-74_fc3dc9101db75606726f929f24f7e982">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press_ln, <span class="at">ndraws =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-74-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>here it seems the posterior predicted data are more similar to the observed data, compared to when we had the normal likelihood
<ul>
<li>but it’s not easy to tell</li>
</ul></li>
<li>another way to examine the extent to which the prediced data looks similar to the observed data: look at the distribution of some summary statistics
<ul>
<li>just like with the prior predictive distributions, examine the distribution of representative summary statistics for the data sets generated by different models</li>
<li>however, unlike with <em>prior</em> predictive distributions, we now have a clear reference: our observed data (which we ignore/don’t have yet for prior predictive distributions)</li>
</ul></li>
<li>we suspect that the normal distribution would generate response times that are too fast (since it’s symmetrical) and that the log-normal distribution may capture the long tail better than the normal model
<ul>
<li>based on this, we compute the distribution of minimum and maximum values for the posterior predictive distributions, adn compare them with the minimum and maximum values respectively in the data</li>
<li>we cn use <code>pp_check()</code> to do this, by using as stat <code>min</code> or <code>max</code> for our models <code>fit_press</code> (normal distribution) and <code>fit_press_ln</code> (log-normal distribution)</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-75_1648cdcc7050b2d08be8669919cd2c58">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>ggpubr<span class="sc">::</span><span class="fu">ggarrange</span>(</span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal min</span></span>
<span id="cb166-3"><a href="#cb166-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb166-4"><a href="#cb166-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb166-5"><a href="#cb166-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb166-6"><a href="#cb166-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal max</span></span>
<span id="cb166-7"><a href="#cb166-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb166-8"><a href="#cb166-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb166-9"><a href="#cb166-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb166-10"><a href="#cb166-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal min</span></span>
<span id="cb166-11"><a href="#cb166-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb166-12"><a href="#cb166-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb166-13"><a href="#cb166-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb166-14"><a href="#cb166-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal max</span></span>
<span id="cb166-15"><a href="#cb166-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb166-16"><a href="#cb166-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb166-17"><a href="#cb166-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb166-18"><a href="#cb166-18" aria-hidden="true" tabindex="-1"></a>  cowplot<span class="sc">::</span><span class="fu">get_legend</span>(<span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)),</span>
<span id="cb166-19"><a href="#cb166-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">2</span>, </span>
<span id="cb166-20"><a href="#cb166-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">45</span>,.<span class="dv">45</span>,.<span class="dv">1</span>),</span>
<span id="cb166-21"><a href="#cb166-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>,<span class="st">"D"</span>)</span>
<span id="cb166-22"><a href="#cb166-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-75-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>here we see the log-normal does a slightly better job since the minimum value is contained in the bulk of the log-normal distribution and in the tai of the normal one</li>
</ul>
</section>
</section>
<section id="list-of-most-important-commands" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="list-of-most-important-commands"><span class="header-section-number">3.7</span> List of most important commands</h2>
<ul>
<li>core <code>brms</code> function for fitting models, for generating prior predictive and posterior predictive data</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-76_581e54550938d0b44fb7548ff79e6253">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb167-3"><a href="#cb167-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb167-4"><a href="#cb167-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb167-5"><a href="#cb167-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>), <span class="at">class =</span> Intercept, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">60000</span>),</span>
<span id="cb167-6"><a href="#cb167-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>), <span class="at">class =</span> sigma, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">2000</span>)</span>
<span id="cb167-7"><a href="#cb167-7" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb167-8"><a href="#cb167-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb167-9"><a href="#cb167-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb167-10"><a href="#cb167-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span></span>
<span id="cb167-11"><a href="#cb167-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment for prior predictive:</span></span>
<span id="cb167-12"><a href="#cb167-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## sample_prior = "only",</span></span>
<span id="cb167-13"><a href="#cb167-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment when dealing with divergent transitions</span></span>
<span id="cb167-14"><a href="#cb167-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## control = list(adapt_delta = .9)</span></span>
<span id="cb167-15"><a href="#cb167-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li>extract samples from fitted model:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-77_914505217de2c3b0f592cc10688c3c35">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A draws_df: 1000 iterations, 4 chains, and 4 variables
   b_Intercept sigma lprior  lp__
1          169    26    -19 -1683
2          168    25    -19 -1683
3          170    25    -19 -1683
4          166    25    -19 -1685
5          168    25    -19 -1683
6          169    25    -19 -1683
7          169    27    -19 -1684
8          169    25    -19 -1683
9          169    26    -19 -1683
10         169    26    -19 -1683
# ... with 3990 more draws
# ... hidden reserved variables {'.chain', '.iteration', '.draw'}</code></pre>
</div>
</div>
<ul>
<li>basic plot of posteriors</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-78_431bb6654b708a3b51cc10fc5d775fcc">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-78-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>plot prior predictive/posterior predictive data</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-79_48e004ec98de86dad9c5658cfd99bdcf">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Posterior predictive check:</span></span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"dens_overlay"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-79-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot posterior predictive distribution of statistical summaries:</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>) <span class="sc">+</span></span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior predictive distribution"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-79-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot prior predictive distribution of statistical summaries:</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>,</span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prior predictive distribution"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-79-3.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="summary-1" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="summary-1"><span class="header-section-number">3.8</span> Summary</h2>
<ul>
<li>in this chapter we:
<ul>
<li>learned how to fit and interpret a Bayesian model with a normal likelihood</li>
<li>looked at the effect of priors by means of prior predictive distributions and sensitivity analysis</li>
<li>looked at the fit of the posterior by inspecting the posterior predictive distribution (which givees us some idea about the descriptive adequacy of the model)</li>
<li>learned how to fit a Bayesian model with a log-normal likelihood, and how to compare the predictive accuracy of different models</li>
</ul></li>
</ul>
</section>
</section>
<section id="chapter-4---bayesian-regression-models" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Chapter 4 - Bayesian regression models</h1>
<ul>
<li>regression tells us how our <em>dependent variable</em> (response/outcome variable; e.g., pupil size, response times, accuracy, etc.) is affected by one or many <em>independent variables</em> (predictors/explanatory variables)</li>
<li>predictors can be categrocial (e.g., male or female), ordinal (first, second, third, etc.), or continuous (e.g., age)</li>
<li>this chapter: simple regression with different likelihood functions</li>
</ul>
<section id="a-first-linear-regression-does-attentional-load-affect-pupil-size" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="a-first-linear-regression-does-attentional-load-affect-pupil-size"><span class="header-section-number">4.1</span> A first linear regression: Does attentional load affect pupil size?</h2>
<ul>
<li>pupil size is mostly related to the amount of light that reaches the retina or the distance to a perceived object
<ul>
<li>it is <em>also</em> systematically influenced by <strong>cognitive processing</strong>: increased cognitive load <span class="math inline">\rightarrow</span> increase in pupil size</li>
</ul></li>
<li>we’ll use data from one subject’s pupil size of a control experiment in Wahn et al.&nbsp;(2016), <em>averaged by trial</em> (<code>df_pupil</code> data in the <code>bcogsci</code> package)
<ul>
<li>the subject covertly tracks between 0-5 objects among several randomly moving on a screen (multiple object tracking (MOT) task)</li>
<li>our goal: investigate how the number of moving objects being tracked (i.e., attentional load) affects pupil size</li>
</ul></li>
</ul>
<section id="likelihood-and-priors" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="likelihood-and-priors"><span class="header-section-number">4.1.1</span> Likelihood and priors</h3>
<ul>
<li>we’ll model pupil size as normally distributed (we’re not expecting skew, and have no further information available about the distribution of pupil sizes)
<ul>
<li>we know this isn’t exactly right, given the units used here in which pipil sizes cannot equal 0 or be negative</li>
</ul></li>
<li>for simplicity’s sake, let’s assume a linear relationship between load and pupil size</li>
</ul>
<p>Our assumptions: 1. There is some average pupil size, <span class="math inline">\alpha</span> 2. the increase of attentional load has a linear relationship with pupil size, <span class="math inline">\beta</span> 3. There is some noise in this process (variability around true pupil size), represented by the scale <span class="math inline">\sigma</span></p>
<ul>
<li>the generative probability density function will be:</li>
</ul>
<p><span class="math display">
p\_size_n \sim \mathit{Normal}(\alpha + c\_load_n \cdot \beta,\sigma)
</span> - this translates to the <code>brms</code> formula:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-80_73ac32eca3469403705c6dfcf8a6e0c3">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>p_size <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> c_load</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><p>where <code>1</code> represents the intercept, <span class="math inline">\alpha</span>, which doens’t depend on the predictor</p></li>
<li><p><code>c_load</code> is the predictor that is multiplied by <span class="math inline">\beta</span></p>
<ul>
<li>the prefix <code>c_</code>will be used to indicate a predictor is <em>centred</em> (the mean of all the values is subtracted from each value)</li>
<li>with load centred, the intercept represents the pupil size at the <em>average load</em> in the expeirment (because at the average load, the centered load is zero, yielding <span class="math inline">\alpha + 0 \cdot\beta</span>)</li>
<li>if the load had <em>not</em> been centered, then the intercept would represent the pupil size when there is no load</li>
</ul></li>
<li><p>we could fit a frequentist model simply with <code>lm(p_size ~ 1 + c_load, data)</code>, but for a Bayesian model we have to specify priors for each of the parameters</p></li>
<li><p>to set plausible priors, some research into info on pupil sizes needs to first be done</p>
<ul>
<li>e.g., we may know pupil diameters range between 2 to 4mm in bright light to 4-8mm in the dark, this experiment was run with the Eyelink-II eyetracker which uses arbitrary units</li>
<li>we need to first know something about measures of pupil sizes (assuming this is our first experiment with such data)</li>
<li>luckily we have some <em>pilot data</em>, which will tell us something about the order of magnitude of our dependent variable
<ul>
<li>importantly: the pilot data presented no attentional load for the first 100 ms, measured every 10 ms</li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-81_4211c8571cd6e830a7c2f426f29756d9">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_pupil_pilot"</span>)</span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>df_pupil_pilot<span class="sc">$</span>p_size <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  851.5   856.0   862.0   860.8   866.5   868.0 </code></pre>
</div>
</div>
<ul>
<li>we can now set a regularizing prior for <span class="math inline">\alpha</span>:
<ul>
<li>center the prior around 1000 to be in the right order of magnitude</li>
<li>since we don’t know much yet about pupil size variation by load, we should include a rather wide prior by defining it as a normal distribution and setting its standard deviation as 500</li>
</ul></li>
</ul>
<p><span class="math display">
\alpha \sim Normal(1000, 500)
</span> - our predictor load is centered, so with the prior for <span class="math inline">\alpha</span> we are saying that we suspect that the average pupil size for the average load int he experiment will be in a 95% CrI of approximately <span class="math inline">1000 \pm (2\times500) = [0, 2000]</span> + or, more precisely:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-82_1f5a0888f6c3b542847ce2bd153dbf62">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), <span class="at">mean =</span> <span class="dv">1000</span>, <span class="at">sd =</span> <span class="dv">500</span>),</span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]   20 1980</code></pre>
</div>
</div>
<ul>
<li>since the measurements of the pilot data are strongly correlated because they were taken 10 milliseconds apart; so they won’t give realistic estimate of variation in pupil size
<ul>
<li>so, set up an uninformative prior for <span class="math inline">\sigma</span> that encodes this lack of precise information: <span class="math inline">\sigma</span> is surely longer than zero, and has to be in the order of magnitude of the pupil size with no load</li>
</ul></li>
</ul>
<p><span class="math display">
\sigma \sim Normal_+(0, 1000)
</span> - so we are saying that we expect that the standard deviation of the pupil sizes should be in the following 95% CrI:</p>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-83_7d19750896c24aa9294bd9d11cd34fd2">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qtnorm</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), </span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">mean =</span> <span class="dv">0</span>, </span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">sd =</span> <span class="dv">1000</span>, </span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">a =</span> <span class="dv">0</span> <span class="co"># truncate at 0</span></span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>       )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]   31.33798 2241.40273</code></pre>
</div>
</div>
<ul>
<li>reminder: the mean of <span class="math inline">Normal_+</span> does not coincide with its location indicated with <span class="math inline">\mu</span>
<ul>
<li>neither does the standard deviation coincide with the scale <span class="math inline">\sigma</span></li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-84_c1c4e6964f5fc850991cee95ac84c79d">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">rtnorm</span>(<span class="dv">20000</span>, </span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">mean =</span> <span class="dv">0</span>, <span class="co"># mean of Normal_+ distri</span></span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sd =</span> <span class="dv">1000</span>,  <span class="co"># sd of Normal_+ distri</span></span>
<span id="cb182-4"><a href="#cb182-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">a =</span> <span class="dv">0</span>) <span class="co"># truncate at 0</span></span>
<span id="cb182-5"><a href="#cb182-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(samples), <span class="co"># sample mean</span></span>
<span id="cb182-6"><a href="#cb182-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="fu">sd</span>(samples)) <span class="co"># sample sd</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    mean       sd 
804.1260 605.8548 </code></pre>
</div>
</div>
<ul>
<li>still need the prior for <span class="math inline">\beta</span>, i.e., the change in pupil size produced by attentional load
<ul>
<li>since these changes in pupil size usually aren’t perceptible in day-to-day life, they should be much smaller than the pupil size (which we assume ahs a mean of 1000 units), so:</li>
</ul></li>
</ul>
<p><span class="math display">
\beta \sim Normal(0,100)
</span></p>
<ul>
<li>so we are saying we don’t really know if the attentional load will increase or decrease the pupil size (it’s centered at 0)
<ul>
<li>but we do know one unit of load will potentially change the pupil size in a way that is consistent with the following 95% CrI:</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-85_e1912a677f5a3f4b4d7bded48a3e8981">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>),</span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean =</span> <span class="dv">0</span>,</span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="dv">100</span>),<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -196  196</code></pre>
</div>
</div>
<ul>
<li><p>so, we don’t expect changes in size that increase or decrease the pupil size more than 200 units for one unit increase in load</p></li>
<li><p>these priors are relatively uninformative, if we had more previous knowledge about pupil size variation we could have more principled priors</p></li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Sidebar: Truncated distributions
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>looks intense</li>
</ul>
</div>
</div>
</section>
<section id="the-brms-model" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="the-brms-model"><span class="header-section-number">4.1.2</span> The <code>brms</code> model</h3>
<ul>
<li>before fittings the <code>brms</code> model, load the data and center the predictor</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-86_0e604c0a83b55c3795787a3e4a6be96b">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_pupil"</span>)</span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>(df_pupil <span class="ot">&lt;-</span> df_pupil <span class="sc">%&gt;%</span></span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">c_load =</span> load <span class="sc">-</span> <span class="fu">mean</span>(load)) <span class="co"># centre</span></span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 41 × 5
    subj trial  load p_size c_load
   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1   701     1     2  1021. -0.439
 2   701     2     1   951. -1.44 
 3   701     3     5  1064.  2.56 
 4   701     4     4   913.  1.56 
 5   701     5     0   603. -2.44 
 6   701     6     3   826.  0.561
 7   701     7     0   464. -2.44 
 8   701     8     4   758.  1.56 
 9   701     9     2   733. -0.439
10   701    10     3   591.  0.561
# … with 31 more rows</code></pre>
</div>
</div>
<ul>
<li>fit the brms model:</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-87_a6bf61ca184a96468e8313f48d277a4d">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>fit_pupil <span class="ot">&lt;-</span> <span class="fu">brm</span>(p_size <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> c_load,</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> df_pupil,</span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">1000</span>,<span class="dv">500</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>,<span class="dv">1000</span>), <span class="at">class =</span> sigma),</span>
<span id="cb188-7"><a href="#cb188-7" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>,<span class="dv">100</span>), </span>
<span id="cb188-8"><a href="#cb188-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">class =</span> b, <span class="at">coef =</span> c_load) <span class="co"># predictor prior</span></span>
<span id="cb188-9"><a href="#cb188-9" aria-hidden="true" tabindex="-1"></a>                 )</span>
<span id="cb188-10"><a href="#cb188-10" aria-hidden="true" tabindex="-1"></a>                 )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rcpp/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/unsupported"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/BH/include" -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/src/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppParallel/include/"  -I"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/rstan/include" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:88:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'
namespace Eigen {
^
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator
namespace Eigen {
               ^
               ;
In file included from &lt;built-in&gt;:1:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:
In file included from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Dense:1:
/Library/Frameworks/R.framework/Versions/4.1/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found
#include &lt;complex&gt;
         ^~~~~~~~~
3 errors generated.
make: *** [foo.o] Error 1</code></pre>
</div>
</div>
<ul>
<li><p>if we want to set the same prior for different predictors, we can omit <code>coef = ...</code></p></li>
<li><p>the priors are normal distribution for the intercept (<span class="math inline">\alpha</span>) and the slope (<span class="math inline">\beta</span>), and a truncated normal distribution for the scale parameter <span class="math inline">\sigma</span>, which coincides with the standard deviation (because the likelihood is a normal distribution)</p></li>
<li><p>inspect the output of the model:</p></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-88_f66d0ca5d0673b520bc67549d32f4e16">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_pupil)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-88-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-89_f68c998ba0911f75bf19660760cde335">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>fit_pupil</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: p_size ~ 1 + c_load 
   Data: df_pupil (Number of observations: 41) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   701.61     19.95   663.00   740.63 1.00     3505     2511
c_load       33.49     12.02     9.98    57.47 1.00     4313     2887

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma   128.32     15.67   102.44   165.09 1.00     3723     2641

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Sidebar: Intercepts in <code>brms</code>
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>when setting up a prior for the intercept in <code>brms</code>, we actually set a prior for an intercept assuming that all predictors are centered
<ul>
<li>if predictors are *not8 cnetered, there is a mismatch between the interpretation of the intercept as returned in the output and the interpretation of the intercept with respect to its prior specification</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="how-to-communicate-the-results" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="how-to-communicate-the-results"><span class="header-section-number">4.1.3</span> How to communicate the results</h3>
<ul>
<li>our research question was “What is the effect of attentional load on the subject’s pupil size?”
<ul>
<li>we need to examine what happens with the posterior distribution of <span class="math inline">\beta</span>, which is printed out as <code>c_load</code> in the model summary, and is 33.49</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-90_426c2259c28aabaf6e885061f3a8cd2b">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a><span class="co"># beta of c_load</span></span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb193-3"><a href="#cb193-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_draws_df</span>(fit_pupil)<span class="sc">$</span>b_c_load <span class="sc">%&gt;%</span> </span>
<span id="cb193-4"><a href="#cb193-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(),</span>
<span id="cb193-5"><a href="#cb193-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 33.49</code></pre>
</div>
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% CrI</span></span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">quantile</span>(<span class="fu">as_draws_df</span>(fit_pupil)<span class="sc">$</span>b_c_load,</span>
<span id="cb195-3"><a href="#cb195-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     2.5%     97.5% 
 9.981363 57.467231 </code></pre>
</div>
</div>
<ul>
<li>the model tells us that as attentional load increases, pupil size increases
<ul>
<li>to determine how likely it is that the pupil size increased rather than decreased, we can examine the proportion of samples above zero</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-91_9d591f7f1e3928e62ef12c513960fc83">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="co"># proportion of cases where the effect occured and was positive</span></span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">as_draws_df</span>(fit_pupil)<span class="sc">$</span>b_c_load <span class="sc">&gt;</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.997</code></pre>
</div>
</div>
<ul>
<li>this high probability does not mean the effect of load is non-zero
<ul>
<li>rather, it’s much more likely that the effect is positive rather than negative</li>
<li>to claim the effect is likely to be non-zero, we’d have to compare the model with an alternative model in which the model assumes that the efefct of load is 0 (more on this in chapter 14)</li>
</ul></li>
</ul>
</section>
<section id="descriptive-adequacy" class="level3" data-number="4.1.4">
<h3 data-number="4.1.4" class="anchored" data-anchor-id="descriptive-adequacy"><span class="header-section-number">4.1.4</span> Descriptive adequacy</h3>
<ul>
<li>our model converged and we obtained a posterior distribution</li>
<li>however there is no guarantee that our model is good enough to represent our data! So let’s run some posterior predictive checks
<ul>
<li>it can be useful to customise the PPC to visualise the fit of the model</li>
</ul></li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-92_10cde3d616c3c518cdd5600252287d25">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>) { <span class="co"># for the cognitive load levels 0:4</span></span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>  df_sub_pupil <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_pupil, load <span class="sc">==</span> l) <span class="co"># filter out other loads</span></span>
<span id="cb199-3"><a href="#cb199-3" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_pupil, <span class="co"># run pp_check</span></span>
<span id="cb199-4"><a href="#cb199-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"dens_overlay"</span>,</span>
<span id="cb199-5"><a href="#cb199-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">ndraws =</span> <span class="dv">100</span>,</span>
<span id="cb199-6"><a href="#cb199-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> df_sub_pupil <span class="co"># using this new data with filtering</span></span>
<span id="cb199-7"><a href="#cb199-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb199-8"><a href="#cb199-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and plot it</span></span>
<span id="cb199-9"><a href="#cb199-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> df_sub_pupil, <span class="fu">aes</span>(<span class="at">x =</span> p_size, <span class="at">y =</span> <span class="fl">0.0001</span>)) <span class="sc">+</span></span>
<span id="cb199-10"><a href="#cb199-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"load: "</span>, l)) <span class="sc">+</span></span>
<span id="cb199-11"><a href="#cb199-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">400</span>, <span class="dv">1000</span>))</span>
<span id="cb199-12"><a href="#cb199-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(p)</span>
<span id="cb199-13"><a href="#cb199-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-92-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-92-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-92-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-92-4.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-92-5.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>we don’t have enough data to make any strong claims; both the predictive distributions and our data are pretty wide spread, and it’s hard to tell if the distribution of the observations could’ve been generated by our model
<ul>
<li>for now let’s say it doesn’t look so bad</li>
</ul></li>
<li>let’s look instead at the distribution of summary statistics</li>
</ul>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-93_3b74fdef59fbe231a13670719ff9b494">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>  df_sub_pupil <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_pupil, load <span class="sc">==</span> l)</span>
<span id="cb200-3"><a href="#cb200-3" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_pupil,</span>
<span id="cb200-4"><a href="#cb200-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"stat"</span>,</span>
<span id="cb200-5"><a href="#cb200-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">ndraws =</span> <span class="dv">1000</span>,</span>
<span id="cb200-6"><a href="#cb200-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> df_sub_pupil,</span>
<span id="cb200-7"><a href="#cb200-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">stat =</span> <span class="st">"mean"</span></span>
<span id="cb200-8"><a href="#cb200-8" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb200-9"><a href="#cb200-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> df_sub_pupil, <span class="fu">aes</span>(<span class="at">x =</span> p_size, <span class="at">y =</span> <span class="fl">0.1</span>)) <span class="sc">+</span></span>
<span id="cb200-10"><a href="#cb200-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">"load: "</span>, l)) <span class="sc">+</span></span>
<span id="cb200-11"><a href="#cb200-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">400</span>, <span class="dv">1000</span>))</span>
<span id="cb200-12"><a href="#cb200-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(p)</span>
<span id="cb200-13"><a href="#cb200-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and store object as p_l</span></span>
<span id="cb200-14"><a href="#cb200-14" aria-hidden="true" tabindex="-1"></a>  name <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"p_"</span>,l)</span>
<span id="cb200-15"><a href="#cb200-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">assign</span>(name, p)</span>
<span id="cb200-16"><a href="#cb200-16" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-93-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-93-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-93-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-93-4.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-93-5.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell" data-hash="book_notes_cache/html/unnamed-chunk-94_3c5613acb06b03dc83fc9928faa825ef">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>ggpubr<span class="sc">::</span><span class="fu">ggarrange</span>(</span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a>  p_0 <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb201-3"><a href="#cb201-3" aria-hidden="true" tabindex="-1"></a>  p_1 <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb201-4"><a href="#cb201-4" aria-hidden="true" tabindex="-1"></a>  p_2 <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb201-5"><a href="#cb201-5" aria-hidden="true" tabindex="-1"></a>  p_3 <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb201-6"><a href="#cb201-6" aria-hidden="true" tabindex="-1"></a>  p_4 <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb201-7"><a href="#cb201-7" aria-hidden="true" tabindex="-1"></a>  cowplot<span class="sc">::</span><span class="fu">get_legend</span>(p_4),</span>
<span id="cb201-8"><a href="#cb201-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow=</span><span class="dv">3</span> , <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-94-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>the observed means for no load and for load = 1 are falling in the tails of the distribution of means
<ul>
<li>the data may be indicating the relevant difference is simply between no load and some load: the likelihood (the dark line) doesn’t move much between load = 1:4 (is about 700-740), but is much lower for load=0 (about 550)</li>
<li>but given the uncertainty in the posterior predictive distributions and that in the observed means are contained somewhere int he predicted distributions, we could just be overinterpreting noise</li>
</ul></li>
</ul>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>