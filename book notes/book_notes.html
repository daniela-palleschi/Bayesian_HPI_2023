<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daniela Palleschi">

<title>Chapter notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="book_notes_files/libs/clipboard/clipboard.min.js"></script>
<script src="book_notes_files/libs/quarto-html/quarto.js"></script>
<script src="book_notes_files/libs/quarto-html/popper.min.js"></script>
<script src="book_notes_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="book_notes_files/libs/quarto-html/anchor.min.js"></script>
<link href="book_notes_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="book_notes_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="book_notes_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="book_notes_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="book_notes_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
</head><body>\usepackage{hyperref} \usepackage{apacite}

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="styles.css">




<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#set-up" id="toc-set-up" class="nav-link active" data-scroll-target="#set-up">Set up</a></li>
  <li><a href="#ch.-1---intro" id="toc-ch.-1---intro" class="nav-link" data-scroll-target="#ch.-1---intro"><span class="toc-section-number">1</span>  Ch. 1 - Intro</a>
  <ul class="collapse">
  <li><a href="#probability" id="toc-probability" class="nav-link" data-scroll-target="#probability"><span class="toc-section-number">1.1</span>  Probability</a>
  <ul class="collapse">
  <li><a href="#conditional-probability-and-bayes-rule" id="toc-conditional-probability-and-bayes-rule" class="nav-link" data-scroll-target="#conditional-probability-and-bayes-rule"><span class="toc-section-number">1.1.1</span>  Conditional probability and Bayes’ rule</a></li>
  <li><a href="#law-of-total-probability" id="toc-law-of-total-probability" class="nav-link" data-scroll-target="#law-of-total-probability"><span class="toc-section-number">1.1.2</span>  Law of total probability</a></li>
  </ul></li>
  <li><a href="#discrete-random-variables" id="toc-discrete-random-variables" class="nav-link" data-scroll-target="#discrete-random-variables"><span class="toc-section-number">1.2</span>  Discrete random variables</a>
  <ul class="collapse">
  <li><a href="#the-mean-and-variance-of-the-binomial-distribution" id="toc-the-mean-and-variance-of-the-binomial-distribution" class="nav-link" data-scroll-target="#the-mean-and-variance-of-the-binomial-distribution"><span class="toc-section-number">1.2.1</span>  The mean and variance of the binomial distribution</a></li>
  <li><a href="#compute-probability-of-a-particular-outcome-discrete-dibinom" id="toc-compute-probability-of-a-particular-outcome-discrete-dibinom" class="nav-link" data-scroll-target="#compute-probability-of-a-particular-outcome-discrete-dibinom"><span class="toc-section-number">1.2.2</span>  Compute probability of a particular outcome (discrete): dibinom</a></li>
  <li><a href="#compute-cumulative-probability-pbinom" id="toc-compute-cumulative-probability-pbinom" class="nav-link" data-scroll-target="#compute-cumulative-probability-pbinom"><span class="toc-section-number">1.2.3</span>  Compute cumulative probability: pbinom</a></li>
  <li><a href="#compute-the-inverse-of-the-cdf-quantile-function-qbinom" id="toc-compute-the-inverse-of-the-cdf-quantile-function-qbinom" class="nav-link" data-scroll-target="#compute-the-inverse-of-the-cdf-quantile-function-qbinom"><span class="toc-section-number">1.2.4</span>  Compute the inverse of the CDF (quantile function): qbinom</a></li>
  </ul></li>
  <li><a href="#continuous-random-variables" id="toc-continuous-random-variables" class="nav-link" data-scroll-target="#continuous-random-variables"><span class="toc-section-number">1.3</span>  Continuous random variables</a>
  <ul class="collapse">
  <li><a href="#an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" id="toc-an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" class="nav-link" data-scroll-target="#an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables"><span class="toc-section-number">1.3.1</span>  An important distinction: probability vs.&nbsp;densitiy in continuous random variables</a></li>
  <li><a href="#truncating-a-normal-distribution" id="toc-truncating-a-normal-distribution" class="nav-link" data-scroll-target="#truncating-a-normal-distribution"><span class="toc-section-number">1.3.2</span>  Truncating a normal distribution</a></li>
  </ul></li>
  <li><a href="#bivariate-and-multivariate-distributions" id="toc-bivariate-and-multivariate-distributions" class="nav-link" data-scroll-target="#bivariate-and-multivariate-distributions"><span class="toc-section-number">1.4</span>  Bivariate and multivariate distributions</a>
  <ul class="collapse">
  <li><a href="#generate-simulated-bivariate-multivariate-data" id="toc-generate-simulated-bivariate-multivariate-data" class="nav-link" data-scroll-target="#generate-simulated-bivariate-multivariate-data"><span class="toc-section-number">1.4.1</span>  Generate simulated bivariate (multivariate) data</a></li>
  </ul></li>
  <li><a href="#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" id="toc-an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" class="nav-link" data-scroll-target="#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter"><span class="toc-section-number">1.5</span>  An important concept: the marginal likelihood (integrating out a parameter)</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">1.6</span>  Exercises</a></li>
  </ul></li>
  <li><a href="#ch.-2---intro-to-bayesian-data-analysis" id="toc-ch.-2---intro-to-bayesian-data-analysis" class="nav-link" data-scroll-target="#ch.-2---intro-to-bayesian-data-analysis"><span class="toc-section-number">2</span>  Ch. 2 - Intro to Bayesian data analysis</a>
  <ul class="collapse">
  <li><a href="#terms" id="toc-terms" class="nav-link" data-scroll-target="#terms">Terms</a></li>
  <li><a href="#bayes-rule" id="toc-bayes-rule" class="nav-link" data-scroll-target="#bayes-rule"><span class="toc-section-number">2.1</span>  Bayes’ Rule</a></li>
  <li><a href="#deriving-the-posterior-using-bayes-rule-an-analystical-example" id="toc-deriving-the-posterior-using-bayes-rule-an-analystical-example" class="nav-link" data-scroll-target="#deriving-the-posterior-using-bayes-rule-an-analystical-example"><span class="toc-section-number">2.2</span>  Deriving the posterior using Bayes’ Rule: an analystical example</a></li>
  <li><a href="#choosing-a-likelihood" id="toc-choosing-a-likelihood" class="nav-link" data-scroll-target="#choosing-a-likelihood"><span class="toc-section-number">2.3</span>  Choosing a likelihood</a></li>
  <li><a href="#choosinga-a-prior-for-theta" id="toc-choosinga-a-prior-for-theta" class="nav-link" data-scroll-target="#choosinga-a-prior-for-theta"><span class="toc-section-number">2.4</span>  Choosinga a prior for <span class="math inline">\theta</span></a></li>
  <li><a href="#using-bayes-rule-to-computer-the-posterior-pthetank" id="toc-using-bayes-rule-to-computer-the-posterior-pthetank" class="nav-link" data-scroll-target="#using-bayes-rule-to-computer-the-posterior-pthetank"><span class="toc-section-number">2.5</span>  Using Baye’s rule to computer the posterior <em>p(</em><span class="math inline">\theta</span><em>|n,k)</em></a></li>
  <li><a href="#summary-of-the-procedure" id="toc-summary-of-the-procedure" class="nav-link" data-scroll-target="#summary-of-the-procedure"><span class="toc-section-number">2.6</span>  Summary of the procedure</a></li>
  <li><a href="#visualising-the-prior-likelihood-and-the-posterior" id="toc-visualising-the-prior-likelihood-and-the-posterior" class="nav-link" data-scroll-target="#visualising-the-prior-likelihood-and-the-posterior"><span class="toc-section-number">2.7</span>  Visualising the prior, likelihood, and the posterior</a></li>
  <li><a href="#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" id="toc-the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" class="nav-link" data-scroll-target="#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood"><span class="toc-section-number">2.8</span>  The posterior distribution is ac ompromise between the prior and the likelihood</a></li>
  <li><a href="#incremental-knowledge-gain-using-prior-knowledge" id="toc-incremental-knowledge-gain-using-prior-knowledge" class="nav-link" data-scroll-target="#incremental-knowledge-gain-using-prior-knowledge"><span class="toc-section-number">2.9</span>  Incremental knowledge gain using prior knowledge</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="toc-section-number">2.10</span>  Summary</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter notes</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Daniela Palleschi </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>These notes are based on <span class="citation" data-cites="nicenboim_introduction_nodate">Nicenboim, Schad, and Vasishth (<a href="#ref-nicenboim_introduction_nodate" role="doc-biblioref">n.d.</a>)</span>, both from a PDF version supplied by the authors and the html version available <a href="https://vasishth.github.io/bayescogsci/book/">here</a> (accessed in early 2023). Much of the notes are taken verbatim from the book, as are code snippets.</p>
<div id="refs" class="references csl-bib-body hanging-indent" data-custom-style="Bibliography" role="doc-bibliography">
<div id="ref-nicenboim_introduction_nodate" class="csl-entry" role="doc-biblioentry">
Nicenboim, Bruno, Daniel Schad, and Shravan Vasishth. n.d. <span>“An Introduction to Bayesian Data Analysis for Cognitive Science.”</span>
</div>
</div>
<div class="cell">

</div>
<section id="set-up" class="level1 unnumbered">
<h1 class="unnumbered">Set up</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># suppress scientific notation</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">999</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="do">## create list of package names</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>packages <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="co">#"SIN", # this package was removed from the CRAN repository</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>               <span class="st">"MASS"</span>, <span class="st">"dplyr"</span>, <span class="st">"tidyr"</span>, <span class="st">"purrr"</span>, <span class="st">"extraDistr"</span>, <span class="st">"ggplot2"</span>, <span class="st">"loo"</span>, <span class="st">"bridgesampling"</span>, <span class="st">"brms"</span>, <span class="st">"bayesplot"</span>, <span class="st">"tictoc"</span>, <span class="st">"hypr"</span>, <span class="st">"bcogsci"</span>, <span class="st">"papaja"</span>, <span class="st">"grid"</span>, <span class="st">"kableExtra"</span>, <span class="st">"gridExtra"</span>, <span class="st">"lme4"</span>, <span class="st">"cowplot"</span>, <span class="st">"pdftools"</span>, <span class="st">"cmdstanr"</span>, <span class="st">"rootSolve"</span>, <span class="st">"rstan"</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># NB: if you haven't already installed bcogsci through devtools, it won't be loaded</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Now load or install &amp; load all</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>package.check <span class="ot">&lt;-</span> <span class="fu">lapply</span>(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  packages,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">install.packages</span>(x, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">library</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># this is also required, taken from the textbook</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Save compiled models:</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Parallelize the chains using all the cores:</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># To solve some conflicts between packages</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>select <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>select</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>extract <span class="ot">&lt;-</span> rstan<span class="sc">::</span>extract</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="ch.-1---intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Ch. 1 - Intro</h1>
<ul>
<li>given some data, how to use Bayes’ theorem to <strong><em>quantify uncertainty about our belief</em></strong> regarding a scientific question of interest</li>
<li>topics to be understood:
<ul>
<li>the basic concepts behind probability</li>
<li>the concept of random variables</li>
<li>probability distributions</li>
<li>the concept of likelihood</li>
</ul></li>
</ul>
<section id="probability" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="probability"><span class="header-section-number">1.1</span> Probability</h2>
<p>Frequency-based versus uncertain-belief perspective of probability:</p>
<ol type="1">
<li>repeatable events, like rolling a die and getting a 6, are <em>frequentist</em> because <strong>probability</strong> is related to the <em>frequency</em> at which we’d observe an outcome given repeated observations</li>
<li>one-of-a-kind events, like earthquakes, don’t work with this idea of probability</li>
</ol>
<ul>
<li>the probability of an earthquake expresses our <em>uncertainty</em> about an event happening</li>
<li>we also be <em>uncertain</em> about how probable an event is: being 90% sure something is 50% likely to happen</li>
<li>this is what we’re interested in: how uncertain we are of an estimate</li>
</ul>
<p>In Bayesian analysis, we want to express our uncertainty about the probability of observing an outcome (<em>prior distribution</em>).</p>
<section id="conditional-probability-and-bayes-rule" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="conditional-probability-and-bayes-rule"><span class="header-section-number">1.1.1</span> Conditional probability and Bayes’ rule</h3>
<ul>
<li>A = “the streets are wet”</li>
<li>B = “it was raining”</li>
<li>P(A|B) = the probability of A given B</li>
<li>P(A,B) = P(A|B)P(B) (the probability of A and B happening)</li>
</ul>
</section>
<section id="law-of-total-probability" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="law-of-total-probability"><span class="header-section-number">1.1.2</span> Law of total probability</h3>
<ul>
<li>dunno</li>
</ul>
</section>
</section>
<section id="discrete-random-variables" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="discrete-random-variables"><span class="header-section-number">1.2</span> Discrete random variables</h2>
<p>Generating random sequences of simulated data with a binomial distribution. Imagine a cloze task, where we consider a particular word a success (1) and any other word a failure (0). If we run the experiment 20 times with a sample size of 10, the cloze probabilities for these 20 experiments would be:</p>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="at">n =</span> <span class="dv">20</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[1] 5 2 4 7 6 5 5 6 3 7 5 6 5 7 7 8 6 3 5 7</p>
<p>For discrete random variables such as the binomial, the probability distribution <em>p(y|<span class="math inline">\theta</span>)</em> is called a probability mass function (PMF) . The PMF defines the probability of each possible outcome. With <em>n</em> = 10 trials, there are 11 possible outcomes (0, 1, 2,…10 succeses). Which outcome is most probable depends on the parameter <span class="math inline">\theta</span> that represents the probability of success. Above, we set <span class="math inline">\theta</span> to <code>0.5</code>.</p>
<section id="the-mean-and-variance-of-the-binomial-distribution" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="the-mean-and-variance-of-the-binomial-distribution"><span class="header-section-number">1.2.1</span> The mean and variance of the binomial distribution</h3>
<p>In real exerimental situations we never know the true value of <span class="math inline">\theta</span> (probability of an outcome), but it can be derived from the data: <em><span class="math inline">\theta</span> hat = k/n</em>, where <em>k</em> = number of observed successess, <em>n</em> = number of trials, and <em><span class="math inline">\theta</span> hat</em> = observed proportion of successes. <em><span class="math inline">\theta</span> hat</em> = <strong><em>maximum likelihood estimate</em></strong> of the true but unknown parameter <em><span class="math inline">\theta</span></em>. Basically, the <strong>mean</strong> of the binomial distribution. The <strong>variance</strong> can also be estimated by computing <em>(n(<span class="math inline">\theta</span>))(1 - <span class="math inline">\theta</span>)</em>. These estimates can be be used for statistical inference.</p>
</section>
<section id="compute-probability-of-a-particular-outcome-discrete-dibinom" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="compute-probability-of-a-particular-outcome-discrete-dibinom"><span class="header-section-number">1.2.2</span> Compute probability of a particular outcome (discrete): dibinom</h3>
<p><code>dbinom</code> calculates probability of <em>k</em> successes out of <em>n</em> given a particular <em><span class="math inline">\theta</span></em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2460938</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.001488035</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.001488035</code></pre>
</div>
</div>
<p>With continuous data, the probability of obtaining an exact value will always be zero. We’ll come ot this later.</p>
</section>
<section id="compute-cumulative-probability-pbinom" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="compute-cumulative-probability-pbinom"><span class="header-section-number">1.2.3</span> Compute cumulative probability: pbinom</h3>
<p>The cumulative distribution function (CDF): essentially the sum of all probabilities of the values of <em>k</em> you are interested in. E.g., the probability of observing 2 successes or fewer (0, 1, or 2) is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sum of probabilities for exact k's</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">0</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbinom</span>(<span class="dv">1</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or use pbinom()</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0546875</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># conversely, what is the $\theta$ of observing THREE successes or more?</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">2</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9453125</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> .<span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9453125</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the probability of observing 10 or fewer successes (out of 10 trials)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">10</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
</section>
<section id="compute-the-inverse-of-the-cdf-quantile-function-qbinom" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="compute-the-inverse-of-the-cdf-quantile-function-qbinom"><span class="header-section-number">1.2.4</span> Compute the inverse of the CDF (quantile function): qbinom</h3>
<p>The quantile function (the inverse CDF) obtains the value of <em>k</em> (the quantile) given the probability of obtaining <em>k</em> or less than <em>k</em> successes given some specific probability value <em>p</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse of dbinom(2,10,.5) would be:</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="fl">0.0546875</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">prob=</span>.<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>
<section id="generage-simulated-data-from-binomial-distribtion-rbinom" class="level4">
<h4 class="anchored" data-anchor-id="generage-simulated-data-from-binomial-distribtion-rbinom">Generage simulated data from binomial distribtion: rbinom</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># given 1 iteration of 10 trials where p = .5, produce a random value of k</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, .<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="continuous-random-variables" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="continuous-random-variables"><span class="header-section-number">1.3</span> Continuous random variables</h2>
<p>Imagine vector of reading times data with a normal distribution, defined by its <em>mean</em> and its <em>sd</em>. The <strong><em>probability density function</em></strong> (PDF) for particular values of mean and sd (assuming a normal distribution) can be calculated using <code>dnorm</code>. The CDF can be found using <code>pnorm</code>, and the inverse CDF using <code>qnorm</code>. These are 3 different ways of looking at the infrmation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p of observing a mean of 250ms when the true mean is 500 &amp; sd = 100 (PDF)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">400</span>,<span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.002419707</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p of observing 400ms *or lower* when the true mean is 500 &amp; sd = 100 (CDF)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">400</span>,<span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1586553</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k with a CDF of 0.1586553 when the true mean is 500 &amp; sd = 100 (inverse CDF)</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.1586553</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 400</code></pre>
</div>
</div>
<p>Question: what is the probability of observing values between 200 and 700 from a normal distribution where mean = 500 and sd = 100?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">700</span>,<span class="dv">500</span>,<span class="dv">100</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">200</span>,<span class="dv">500</span>,<span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9759</code></pre>
</div>
</div>
<p>With continuous data, it is only meaningful to ask about probabilities between two point values (e.g., probability that Y lies between a and b).</p>
<p>What is the quantile <em>q</em> such that the probability of observing that value or something less (or more) than it is 0.975 (given the normal(500,100) distribution)?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="at">m=</span><span class="dv">500</span>, <span class="at">sd=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 695.9964</code></pre>
</div>
</div>
<p>Next task: generate simulated data. generate 10 data points using the <code>rnorm</code> function and use this simulated data to compute the mean and stanrdard devaition.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">500</span>,<span class="dv">100</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 487.7183</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 99.44979</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># can also computer lower and upper bounds of 95% CIs</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(x, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    2.5%    97.5% 
350.9656 661.4838 </code></pre>
</div>
</div>
<section id="an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="an-important-distinction-probability-vs.-densitiy-in-continuous-random-variables"><span class="header-section-number">1.3.1</span> An important distinction: probability vs.&nbsp;densitiy in continuous random variables</h3>
<p>The probability density function (PDF):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># density with default m = 0 and sd = 1</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2419707</code></pre>
</div>
</div>
<p>This is not the probability of observing 1 in this distribution, as the probability of a single value in a continous distribtion will always be 0. This is becaue probability in a continuous distritubion is the <strong><em>area under the curve</em></strong>, and at a single point there is no area under the curve (i.e., p = 0). The <code>pnorm</code> function allows us to find the cumulative distribution function (CDF) for the normal distribution.</p>
<p>For example, the probability of obseving a value etween +/-2 in a normal distribution with mean 0 and sd 1:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">2</span>, <span class="at">m =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="at">m =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9544997</code></pre>
</div>
</div>
<p>For <strong><em>discrete</em></strong> random variables, the situation is different. These have a probability <strong>mass</strong> function (PMF), the binomial distribution that we saw before. Here, the PMF maps the possible <em>y</em> values to the probabilities of those exact values occurring.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">2</span>,<span class="at">size=</span><span class="dv">10</span>,<span class="at">prob=</span>.<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.04394531</code></pre>
</div>
</div>
</section>
<section id="truncating-a-normal-distribution" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="truncating-a-normal-distribution"><span class="header-section-number">1.3.2</span> Truncating a normal distribution</h3>
<p>Refers to positive values only (truncating at 0).</p>
</section>
</section>
<section id="bivariate-and-multivariate-distributions" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="bivariate-and-multivariate-distributions"><span class="header-section-number">1.4</span> Bivariate and multivariate distributions</h2>
<p>Consider a case where two discrete responses were recorded: a binary yes/no response, and a Likert acceptability rating (1-7).</p>
<p>The <strong><em>joint probability mass function</em></strong> is the joint PMF of two random variables.</p>
<p>Let’s play around with some such data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run if package is not loaded</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(bcogsci)</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_discreteagrmt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="marginal-distributions" class="level4">
<h4 class="anchored" data-anchor-id="marginal-distributions">Marginal distributions</h4>
<p>The marginal distribution of each pair of values (let’s say <em>x</em> = the binary response, <em>y</em> = the Likert response) is computed by summing up</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rowSums</span>(probs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong><em>object <code>probs</code> is not defined in the book</em></strong></p>
</section>
<section id="generate-simulated-bivariate-multivariate-data" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="generate-simulated-bivariate-multivariate-data"><span class="header-section-number">1.4.1</span> Generate simulated bivariate (multivariate) data</h3>
<p>Suppose we want to generate 100 pairs of correlated data, with correlation rho = 0.6. The two random variables have mean 0, and standard deviations 5 and 10 respectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="do">## define a variance-covariance matrix:</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">5</span><span class="sc">^</span><span class="dv">2</span>, <span class="dv">5</span> <span class="sc">*</span> <span class="dv">10</span> <span class="sc">*</span> .<span class="dv">6</span>, <span class="dv">5</span> <span class="sc">*</span> <span class="dv">10</span> <span class="sc">*</span> .<span class="dv">6</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">byrow =</span> <span class="cn">FALSE</span>, <span class="at">ncol =</span> <span class="dv">2</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="do">## generate data:</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sigma =</span> Sigma</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(u, <span class="at">n =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]      [,2]
[1,]  5.692388 10.872355
[2,]  5.610516 -5.100308
[3,] -5.211772 -4.441897</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">u_1 =</span> u[, <span class="dv">1</span>], <span class="at">u_2 =</span> u[, <span class="dv">2</span>]), <span class="fu">aes</span>(u_1, u_2)) <span class="sc">+</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter"><span class="header-section-number">1.5</span> An important concept: the marginal likelihood (integrating out a parameter)</h2>
</section>
<section id="exercises" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="exercises"><span class="header-section-number">1.6</span> Exercises</h2>
<p>1.1 Practice with pnorm Part 1</p>
<p>Given a normal distribution with mean 500 and standard deviation 100, use the pnorm function to calculate the probability of obtaining values between 200 and 800 from this distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">200</span>, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9973002</code></pre>
</div>
</div>
<p>1.2 Practice with pnorm Part 2</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">700</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2524925</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">900</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2524925</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>, <span class="dv">800</span>, <span class="dv">150</span>, <span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5</code></pre>
</div>
</div>
<p>1.3 Practice with pnorm Part 3</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">550</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4012937</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">800</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T) <span class="sc">-</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pnorm</span>(<span class="dv">300</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7745375</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">900</span>,<span class="dv">600</span>,<span class="dv">200</span>,<span class="at">lower.tail=</span>F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0668072</code></pre>
</div>
</div>
<p>Exercise 1.4 Practice using the qnorm function - Part 1</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>),<span class="at">mean=</span><span class="dv">1</span>,<span class="at">sd=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.2815516  2.2815516</code></pre>
</div>
</div>
<p>Exercise 1.5 Practice using the qnorm function - Part 2</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="at">mean=</span><span class="dv">650</span>, <span class="at">sd=</span><span class="dv">125</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 489.8061 810.1939</code></pre>
</div>
</div>
<p>Exercise 1.6 Practice getting summaries from samples - Part 1</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>data_gen1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">300</span>, <span class="dv">200</span>)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 295.4031</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sd</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 196.139</code></pre>
</div>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># q1 and q2</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="fu">mean</span>(data_gen1), <span class="fu">sd</span>(data_gen1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  44.04084 546.76543</code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exercise 1.7 Practice getting summaries from samples - Part 2</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data with truncated normal distribution</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>data_gen1 <span class="ot">&lt;-</span> <span class="fu">rtnorm</span>(<span class="dv">1000</span>, <span class="dv">300</span>, <span class="dv">200</span>, <span class="at">a =</span> <span class="dv">0</span>)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># mean</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 329.0476</code></pre>
</div>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sd</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 177.6832</code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># q1 and q2</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">9</span>), <span class="fu">mean</span>(data_gen1), <span class="fu">sd</span>(data_gen1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 101.3374 556.7578</code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_gen1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exercise 1.8 Practice with a variance-covariance matrix for a bivariate distribution</p>
</section>
</section>
<section id="ch.-2---intro-to-bayesian-data-analysis" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Ch. 2 - Intro to Bayesian data analysis</h1>
<ul>
<li>simple but crucial point: the posterior distribution of a parameter is a compromise between the prior and the likelihood</li>
</ul>
<section id="terms" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="terms">Terms</h2>
<ul>
<li><em>posterior</em>, <em>p(</em>$theta$<em>|y)</em>: probability distribution of the parameters conditional on the <strong>data</strong></li>
<li><em>likelihood</em>, <em>p(y|</em>$theta$<em>)</em>: the PMF or PDF expressed as a function of <span class="math inline">\theta</span></li>
<li><em>prior</em>, $theta$: the initial probability distribution of paramters <strong><em>before seeing the data</em></strong></li>
<li><em>marginal likelihood, p(y)</em>: standardizes the posterior distribution to ensure the AUC sums to 1; it ensure the posterior is a valid probability distribution</li>
</ul>
</section>
<section id="bayes-rule" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="bayes-rule"><span class="header-section-number">2.1</span> Bayes’ Rule</h2>
<ul>
<li>Bayes’ rule: when <em>A</em> and <em>B</em> are observable discrete events (like “it has been raining” or “the streets are wet”), we can state the rule as follows:</li>
</ul>
<p><span class="math display">\begin{equation}
P(A\mid B) = \frac{P(B\mid A) P(A)}{P(B)}
\tag{2.1}
\end{equation}</span></p>
<ul>
<li>given a vector of data <em>y</em>, we can work out the posterior distributions of parameters of interest which we represent as the vector of parameters <span class="math inline">\theta</span></li>
<li>to do this, we can re-write equation 2.1 as 2.2:</li>
</ul>
<p><span class="math display">\begin{equation}
p(\boldsymbol{\Theta}|\boldsymbol{y}) = \cfrac{ p(\boldsymbol{y}|\boldsymbol{\Theta}) \cdot p(\boldsymbol{\Theta}) }{p(\boldsymbol{y})}
\tag{2.2}
\end{equation}</span></p>
<ul>
<li>now, Bayes’ rule is writen in terms of probability distributions, where p() is the probability density function (continuous) or probability mass function (discrete)</li>
<li>in words, this simply means:</li>
</ul>
<p><span class="math display">\begin{equation}
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
\end{equation}</span></p>
</section>
<section id="deriving-the-posterior-using-bayes-rule-an-analystical-example" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="deriving-the-posterior-using-bayes-rule-an-analystical-example"><span class="header-section-number">2.2</span> Deriving the posterior using Bayes’ Rule: an analystical example</h2>
<ul>
<li><p>participants are shown sentences like <em>It’s raining. I’m going to take the…</em></p></li>
<li><p>if 100 participants complete the sentence, and 80 complete the sentence with <em>bus</em>, the estimated cloze probability would be <span class="math inline">\frac{80}{100}</span>=0.8</p>
<ul>
<li>this is the <strong>maximum likelihood estimate</strong> of the probability of producing the word; as this is an estimate let’s add a hat: <span class="math inline">\hat \theta</span>=0.8</li>
</ul></li>
<li><p>in the frequentist paradigm, <span class="math inline">\hat \theta</span>=0.8 is an estimate of an <strong>unknown point value</strong> <span class="math inline">\theta</span> “out there in nature”</p></li>
<li><p>N.B., the variability in the estimate will be influenced by the sample size</p>
<ul>
<li>if the <em>true</em> value of <span class="math inline">\theta</span> is really 0.80, we will still get some variability in the estimated proportion from a sample size of say 10 pariticpants</li>
<li>let’s carry out 100 simulated experiments and compute their variability:</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="co"># generate 100 random binomial data sets</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs each</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">prob =</span> .<span class="dv">8</span>) <span class="sc">/</span> <span class="dv">10</span> <span class="co"># with prob 8, now divide these by 10 to get 100 means (k/n)</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co"># what is the sd of these 100 means?</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.141</code></pre>
</div>
</div>
<ul>
<li>instead, let’s imagine that <span class="math inline">\theta</span> is a <strong><em>random variable</em></strong>; i.e., it has a PDF associated with it
<ul>
<li>this PDDF would now represent our <strong><em>belief</em></strong> about possible values of <span class="math inline">\theta</span> <em>before we have any data</em></li>
<li>e.g., if we believe from the outset that all possible values between 0 and 1 are equally likely, we would have a uniform prior of <span class="math inline">\theta \sim \mathit{Uniform}</span>(0,1)</li>
<li>let’s re-run our simulated experiments, but with <em>two</em> sources of variability: the data and our uncertainty associated with <span class="math inline">\theta</span></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>) <span class="co"># simulate 100 numbers between 0:1</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="co"># generate random binomial data that has...</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, <span class="co"># 100x</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> theta <span class="co"># with prob = theta</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>)<span class="sc">/</span><span class="dv">10</span> <span class="co"># divided by 10 to give us the mean for each</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sd of the means from these 100 'experiments'</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.324</code></pre>
</div>
</div>
<ul>
<li>the higher standard deviation, representing variability int he estimate of the parameter, comes frm the added uncertainty from the <span class="math inline">\theta</span> parameter
<ul>
<li>what would happen if we had tighter expectations, i.e., a very tight PDF for <span class="math inline">\theta</span>, say (0.7,0.9)?</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="fl">0.7</span>, <span class="at">max =</span> <span class="fl">0.9</span>) <span class="co"># simulate 100 numbers between 0:1</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>estimated_means <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="co"># generate random binomial data that has...</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, <span class="co"># 100x</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">10</span>, <span class="co"># of 10 obvs</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> theta <span class="co"># with prob = theta</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>)<span class="sc">/</span><span class="dv">10</span> <span class="co"># divided by 10 to give us the mean for each</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sd of the means from these 100 'experiments'</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(estimated_means),<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.145</code></pre>
</div>
</div>
<ul>
<li><p>the variability is smaller; so the greater the uncertainty associated with the <span class="math inline">\theta</span> parameter, the greater the variability in the data</p></li>
<li><p>this is very different from the frequentist assumption that <span class="math inline">\theta</span> is a point value; in Bayesian <span class="math inline">\theta</span> is a <strong>random variable</strong> with a probability density/mass function associated with it</p></li>
<li><p>this PDF is called a <strong>prior distribution</strong> and represents our prior belief or knowledge about a possible value of this parameter</p></li>
<li><p>once we obtain data, these data serve to modify our prior belief about the distribution, called our <strong>posterior distribution</strong></p></li>
</ul>
</section>
<section id="choosing-a-likelihood" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="choosing-a-likelihood"><span class="header-section-number">2.3</span> Choosing a likelihood</h2>
<ul>
<li>with a binomial distribution like the cloze probability (chose ‘bus’ or not), the PMF can be written as:</li>
</ul>
<p><span class="math display">\begin{equation}
p(k|n,\theta) = \binom{n}
{k} \theta^k (1-\theta)^{n-k}
\tag{2.3}
\end{equation}</span></p>
<ul>
<li><em>k</em> = the number of times “bus” was given as an answer</li>
<li><em>n</em> = the total number of answers given</li>
<li>if we collect 100 data points (<em>n</em> = 100), and find <em>k</em> = 80, we now have 2 fixed data points, <em>n</em> and <em>k</em>. The only variable is now <span class="math inline">\theta</span></li>
</ul>
<p><span class="math display">\begin{equation}
p(k=80 | n= 100,  \theta) = \binom{n}{k} \theta^{80} (1-\theta)^{20}
\end{equation}</span></p>
<ul>
<li><p>this is now a continuous function of the value of <span class="math inline">\theta</span>, which can have a possible value between 0 and 1</p></li>
<li><p>by contrast, the PMF of the binomial treats <span class="math inline">\theta</span> as a <strong>fixed</strong> value and defines a discrete distribution over the n+1 possible discrete values <em>k</em> that we can observe</p></li>
<li><p>recall: the PMF and the likelihood are the same function seen from different points of view: the only difference being what is considered fixed (PMF: <span class="math inline">\theta</span>, likelihood: data) and what is varying (PMF: data, likelihood: <span class="math inline">\theta</span>)</p>
<ul>
<li><strong>PMF</strong>: <span class="math inline">\theta</span> is fixed, data varies</li>
<li><strong>likelihood function</strong>: data is fixed, <span class="math inline">\theta</span> varies</li>
</ul></li>
</ul>
<p>Now we go back to our main foal: using Bayes’ rule to find out the posterior distribution of <span class="math inline">\theta</span> given our data: <em>p(</em><span class="math inline">\theta</span>*|n,k). We first need to define a prior distribution over the parameter <span class="math inline">theta</span>, thereby expressing our prior uncertainty about plausible values of <span class="math inline">\theta</span></p>
</section>
<section id="choosinga-a-prior-for-theta" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="choosinga-a-prior-for-theta"><span class="header-section-number">2.4</span> Choosinga a prior for <span class="math inline">\theta</span></h2>
<ul>
<li><p>priors for a <span class="math inline">\theta</span> in a binominal distribution: the parameter <span class="math inline">\theta</span> is a random variable with a PDF whose range is [0,1]</p></li>
<li><p>the <strong><em>beta distribution</em></strong>, which is a PDF for a continuous random variable, is commonly used as a prior for parameters representing probabilities, and has the following PDF:</p></li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|a,b)=  \frac{1}{B(a,b)} \theta^{a - 1} (1-\theta)^{b-1}   
\tag{2.4}
\end{equation}</span></p>
<ul>
<li><em>B(a,b)</em> is a normalising constant that ensures that the area under the curve sums to 1, so that <em>p(</em><span class="math inline">\theta</span>|<em>a,b)</em> is a probability</li>
<li>the beta distribution’s paramters <em>a</em> and <em>b</em> express our prior beliefs about the probability of a success:
<ul>
<li><em>a</em> = number of “successes” (answering “bus”)</li>
<li><em>b</em> = number of “failures” (not answering “bus”)</li>
</ul></li>
<li>the different beta distributions shapes given different values of a and b are shown below (in r, a = <code>shape1</code> and b = <code>shape2</code>)</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">1</span>,<span class="at">shape2=</span><span class="dv">1</span>), <span class="dv">0</span>,<span class="dv">1</span>,</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Beta density"</span>,</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">1.1</span>,<span class="st">"a=1,b=1"</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">3</span>,<span class="at">shape2=</span><span class="dv">3</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">1.6</span>,<span class="st">"a=3,b=3"</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">6</span>,<span class="at">shape2=</span><span class="dv">6</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">2.8</span>,<span class="st">"a=6,b=6"</span>)</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">2</span>,<span class="at">shape2=</span><span class="dv">6</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">15</span>,<span class="fl">2.9</span>,<span class="st">"a=2,b=6"</span>)</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">6</span>,<span class="at">shape2=</span><span class="dv">2</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">85</span>,<span class="fl">2.9</span>,<span class="st">"a=6,b=2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>to express our uncertainty, we could compute 95% <strong><em>credible</em></strong> intervales, i.e., the region over which we are 95% certain the value of the parameter lies</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 95% CrIs</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="co"># at what quantiles (points on the x-axis)</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), <span class="co"># would the PDF cover 95% AUC</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape1 =</span> <span class="dv">4</span>, <span class="co"># where a = 4</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape2 =</span> <span class="dv">4</span>), <span class="co"># and b = 4</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">3</span>) <span class="co"># rounded to 3 decimal points</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.184 0.816</code></pre>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Sidebar
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>in a unimodal distribution, one could use the narrowest interval that contains the mode (the <strong>highest posterior density interval</strong> (HDI))</li>
<li>in skewed posterior distirbutions, the equal-tailed CrI and the HDI will not be identical, because the HDI will have unequal tail probabilities; this book uses the equal-tailed interval (like we computed above) because it’s the standard output in <code>Stan</code> and <code>brms</code></li>
</ul>
</div>
</div>
<ul>
<li>if we were to choose <em>a</em> = 10 and <em>b</em> = 10, we would still be assuming a prior that “bus” is just as likely as some other word, but now our prior uncertainty about this mean is lower, meaning we have a tighter prior:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 95% CrIs</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="co"># at what quantiles (points on the x-axis)</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>), <span class="co"># would the PDF cover 95% AUC</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape1 =</span> <span class="dv">10</span>, <span class="co"># where a = 4</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">shape2 =</span> <span class="dv">10</span>), <span class="co"># and b = 4</span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">3</span>) <span class="co"># rounded to 3 decimal points</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.289 0.711</code></pre>
</div>
</div>
<ul>
<li>compare the AUC for the two beta distributions in Figure </li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">4</span>,<span class="at">shape2=</span><span class="dv">4</span>), <span class="dv">0</span>,<span class="dv">1</span>,</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Beta density"</span>,</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>))</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">2.35</span>,<span class="st">"a=4,b=4"</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cf">function</span>(x) </span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(x,<span class="at">shape1=</span><span class="dv">10</span>,<span class="at">shape2=</span><span class="dv">10</span>),<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">add=</span><span class="cn">TRUE</span>,</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">"density"</span>,<span class="at">xlab=</span><span class="st">"theta"</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>))</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(.<span class="dv">5</span>,<span class="fl">3.7</span>,<span class="st">"a=10,b=10"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beta2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="book_notes_files/figure-html/fig-beta2-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Beta distributions with varying a and b values</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li>but which prior should we choose? This depends on our prior knowledge
<ul>
<li>if we don’t have much prior information, we could use <em>a</em> = <em>b</em> = 1; this is a uniform prior <span class="math inline">\mathit{Uniform}</span>(0,1), often clled a <strong><em>flat</em></strong>, <strong><em>non-informative</em></strong>, or <strong><em>uninformative prior</em></strong></li>
<li>if we have a lot of prior knowledge or a strong belief regarding the range of plausible values for <span class="math inline">\theta</span>, we can use a different set of <em>a</em> and <em>b</em> values</li>
<li>if we were to use <em>a</em> = 4 and <em>b</em> = 4, then our prior for <span class="math inline">\theta</span> would be:</li>
</ul></li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta) = \frac{1}{B(4,4)} \theta^{3} (1-\theta)^{3}
\end{equation}</span></p>
</section>
<section id="using-bayes-rule-to-computer-the-posterior-pthetank" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="using-bayes-rule-to-computer-the-posterior-pthetank"><span class="header-section-number">2.5</span> Using Baye’s rule to computer the posterior <em>p(</em><span class="math inline">\theta</span><em>|n,k)</em></h2>
<ul>
<li>recall the equation from earlier:</li>
</ul>
<p><span class="math display">\begin{equation}
\hbox{Posterior} = \frac{\hbox{Likelihood} \cdot \hbox{Prior}}{\hbox{Marginal Likelihood}}
\end{equation}</span></p>
<ul>
<li>now that we’ve got the likelihood and the prior, we can use Bayes’ rule to calculate <em>p(</em><span class="math inline">\theta</span>|<em>n,k)</em>, as follows:</li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) = \frac{\left[\binom{100}{80} \theta^{80} \cdot (1-\theta)^{20}\right]  \times \left[\frac{1}{B(4,4)} \times \theta^{3} (1-\theta)^{3}\right]}{p(k=80)}
\tag{2.6}
\end{equation}</span></p>
<ul>
<li>constant values are those that do not depend on the unknown parameter of interest, <span class="math inline">\theta</span>; so <em>p(k = 80)</em> will be a constant once we know the number of successes
<ul>
<li>once <em>k</em> is known, we already have several constant values</li>
</ul></li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
\end{equation}</span></p>
<ul>
<li>we can gather all the constants (in the square brackets below):</li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) =   \left[ \frac{\binom{100}{80}}{B(4,4)\times p(k=80)} \right]   [\theta^{80} (1-\theta)^{20} \times  \theta^{3} (1-\theta)^{3}]
\tag{2.7}
\end{equation}</span></p>
<ul>
<li>and ignore the constants for now, which will later on make the AUC sum up to 1; so now we say the posterior is proportional to the right-hand side of the equation:</li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) \propto   [\theta^{80} (1-\theta)^{20} \times \theta^{3} (1-\theta)^{3} ]
\tag{2.8}
\end{equation}</span></p>
<ul>
<li>in other words:</li>
</ul>
<p><span class="math display">\begin{equation}
\hbox{Posterior} \propto \hbox{Likelihood} \times \hbox{Prior}
\end{equation}</span></p>
<ul>
<li>now we just have to add up the exponents</li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) \propto   [\theta^{80+3} (1-\theta)^{20+3}] = \theta^{83} (1-\theta)^{23}
\tag{2.9}
\end{equation}</span></p>
<ul>
<li>recall that the beta distribution involves <span class="math inline">\theta</span> exponentiated to the power of <em>a</em>-1 and <em>b</em>-1 (see equation 2.4)
<ul>
<li>therefore, the expression in 2.9 above corresponds to a beta distribution with parameters <em>a</em> = 84 and <em>b</em> = 24 (because 83 and 23 +1 is 84 and 24)</li>
<li>all we need now is our normalising constant to make the AUC sum to one; let’s check this:</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>PostFun <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>  theta<span class="sc">^</span><span class="dv">83</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span><span class="dv">23</span></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>(AUC <span class="ot">&lt;-</span> <span class="fu">integrate</span>(PostFun, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000000000000000000000000831619</code></pre>
</div>
</div>
<ul>
<li>this doesn’t add up to 1, it’s not a probability distribution</li>
<li>but we can use it to figure out what our normalising constant is; what is the constant <em>k</em> such that the AUC sums to 1:</li>
</ul>
<p><span class="math display">\begin{equation}
k \int_{0}^{1} \theta^{83} (1-\theta)^{23} = 1
\end{equation}</span></p>
<ul>
<li>we know what _{0}^{1} ^{83} (1-)^{23} is, because we just computed it above (and called it AUC), so:</li>
</ul>
<p><span class="math display">\begin{equation}
k  = \frac{1}{\int_{0}^{1} \theta^{83} (1-\theta)^{23}} = \frac{1}{AUC}
\end{equation}</span></p>
<ul>
<li>we now have the distribution or <span class="math inline">\theta</span> given the data, expressed as a PDF:</li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta|n=100,k=80) = \frac{1}{B(83,23)} \theta^{84-1} (1-\theta)^{24-1}
\end{equation}</span></p>
<ul>
<li>and our function will now sum to one if we divide it all by AUC</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>PostFun <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>  theta<span class="sc">^</span><span class="dv">83</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span><span class="dv">23</span> <span class="sc">/</span> AUC</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(PostFun, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
</section>
<section id="summary-of-the-procedure" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="summary-of-the-procedure"><span class="header-section-number">2.6</span> Summary of the procedure</h2>
<ul>
<li>we started with a binomial likelihood
<ul>
<li>multiplied it with the prior <span class="math inline">\theta \sim \mathit{Beta}(4,4)</span></li>
<li>obtained the posterior <em>p(</em><span class="math inline">\theta</span>|<em>n,k)</em> <span class="math inline">\sim \mathit{Beta}(4,4)</span></li>
<li>we ignored the constants when carrying out the multiplication (i.e., computer the posterior <em>up to proportionality</em>)</li>
<li>then we rescaled the posterior to become a probability distribution by including a proportionality constant (AUC)</li>
</ul></li>
<li>this was an example of a <strong>conjugate</strong> analysis: the posterior on the parameter has thes ame form (belongs to the same family of probability distributions) as the prior</li>
<li>this combo of likelihood and prior is called the <strong><em>beta-binomial conjugate case</em></strong>
<ul>
<li><p>conjugacy is defined as: Given the likelihood <em>p(y</em>|<span class="math inline">\theta</span><em>)</em>, if the prior <em>p(</em><span class="math inline">\theta</span>*)( results in a posterior <span class="math inline">p(\theta|y)</span> that has some form as <span class="math inline">p(\theta)</span>, then we call <span class="math inline">p(\theta)</span> a conjugate prior</p></li>
<li><p>given a <span class="math inline">Binomial(n,k|\theta)</span> likelihood, and a <span class="math inline">Beta(a,b)</span> prior on <span class="math inline">\theta</span>, the posterior will be <span class="math inline">Beta(a + k, b + n - k)</span></p></li>
</ul></li>
</ul>
</section>
<section id="visualising-the-prior-likelihood-and-the-posterior" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="visualising-the-prior-likelihood-and-the-posterior"><span class="header-section-number">2.7</span> Visualising the prior, likelihood, and the posterior</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>binom_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x=</span>k, <span class="at">size =</span>n, <span class="at">prob =</span> theta)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">integrate</span>(<span class="at">f =</span> binom_lh, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>binom_scaled_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) <span class="dv">1</span><span class="sc">/</span>K <span class="sc">*</span> <span class="fu">binom_lh</span>(theta)</span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>p_beta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)), <span class="fu">aes</span>(theta)) <span class="sc">+</span></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb100-15"><a href="#cb100-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> a, <span class="at">shape2 =</span> b),</span>
<span id="cb100-16"><a href="#cb100-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Prior"</span>)</span>
<span id="cb100-17"><a href="#cb100-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-18"><a href="#cb100-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"density"</span>) <span class="sc">+</span></span>
<span id="cb100-19"><a href="#cb100-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-20"><a href="#cb100-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb100-21"><a href="#cb100-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> k <span class="sc">+</span> a, <span class="at">shape2 =</span> n <span class="sc">-</span> k <span class="sc">+</span> b), <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Posterior"</span>)</span>
<span id="cb100-22"><a href="#cb100-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-23"><a href="#cb100-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb100-24"><a href="#cb100-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> binom_scaled_lh,</span>
<span id="cb100-25"><a href="#cb100-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Scaled likelihood"</span>)</span>
<span id="cb100-26"><a href="#cb100-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb100-27"><a href="#cb100-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb100-28"><a href="#cb100-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb100-29"><a href="#cb100-29" aria-hidden="true" tabindex="-1"></a>p_beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>if we wanted to produce the 95% credible interval, i.e., the range over which we are 95% certain the true value of <span class="math inline">\theta</span> lies, give <em>a</em> = 84 and <em>b</em> = 24:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">shape1 =</span> <span class="dv">84</span>, <span class="at">shape2 =</span> <span class="dv">24</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>  ,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.695 0.851</code></pre>
</div>
</div>
</section>
<section id="the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood"><span class="header-section-number">2.8</span> The posterior distribution is ac ompromise between the prior and the likelihood</h2>
<ul>
<li>let’s take four different beta priors with increasing certainty:
<ul>
<li><span class="math inline">Beta(a = 2, b = 2)</span></li>
<li><span class="math inline">Beta(a = 3, b = 3)</span></li>
<li><span class="math inline">Beta(a = 6, b = 6)</span></li>
<li><span class="math inline">Beta(a = 21, b = 21)</span></li>
</ul></li>
<li>each reflects a believe that <span class="math inline">\theta</span> = 0.5 but with a varying degree of certainty
<ul>
<li>we can now “just” plug in the likelihood and the prior to the beta-binomial case to get the posterior:</li>
</ul></li>
</ul>
<p><span class="math display">\begin{equation}
p(\theta | n,k) \propto p(k |n,\theta) p(\theta)
\end{equation}</span></p>
<ul>
<li>if we plot the tightest case (<span class="math inline">a = 21, b = 21</span>), we see how the posterior is affected</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">21</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">21</span></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>binom_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x=</span>k, <span class="at">size =</span>n, <span class="at">prob =</span> theta)</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">integrate</span>(<span class="at">f =</span> binom_lh, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)<span class="sc">$</span>value</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>binom_scaled_lh <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) <span class="dv">1</span><span class="sc">/</span>K <span class="sc">*</span> <span class="fu">binom_lh</span>(theta)</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>p_beta <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)), <span class="fu">aes</span>(theta)) <span class="sc">+</span></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> a, <span class="at">shape2 =</span> b),</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Prior"</span>)</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"density"</span>) <span class="sc">+</span></span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dbeta,</span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> k <span class="sc">+</span> a, <span class="at">shape2 =</span> n <span class="sc">-</span> k <span class="sc">+</span> b), <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Posterior"</span>)</span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> binom_scaled_lh,</span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"Scaled likelihood"</span>)</span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>p_beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="book_notes_files/figure-html/unnamed-chunk-37-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ul>
<li>we can say the following about the likelihood-prior-posterior relationship:
<ul>
<li>the posterior distribution is ac ompromise between the prior and the likelihood</li>
<li>for a given set of data, the great the certainty in the prior, the more heavily the posterior will be influenced by the prior mean</li>
<li>conversely, for a given set of data, the greater the <strong>un</strong>certainty in the prior, the more heavily the posterior will be influenced by the likelihood</li>
<li>but because <em>n</em> and <em>k</em> are included in the posterior Beta distribution (<span class="math inline">Beta(a + k, b + n - k)</span>), the posterior mean will be influenced more heavily by larger sample sizes
<ul>
<li>sensitivity analyses can help check whether your parameter of interest is sensitive to the prior specification</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="incremental-knowledge-gain-using-prior-knowledge" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="incremental-knowledge-gain-using-prior-knowledge"><span class="header-section-number">2.9</span> Incremental knowledge gain using prior knowledge</h2>
<ul>
<li><p>we can incrementally gain information about a research question by using information from previous studies and deriving a position, and then using that posterior as a prior for the next experiment</p></li>
<li><p>e.g., in the example above, we currently had a prior <span class="math inline">Beta(4,4)</span> and observed <span class="math inline">k = 80</span> successes of <span class="math inline">n = 100</span> observations, deriving a posterior <span class="math inline">Beta(84,24)</span></p>
<ul>
<li>if we were to run this experiment again and had <span class="math inline">k = 60, n = 100</span>, we cwould have a posterior as follows <span class="math inline">\mathit{Beta}(a+k,b+n-k) = \mathit{Beta}(84+60,24+100-60)=\mathit{Beta}(144,64)</span></li>
<li>alternatively, if we collected all this data in the first place and had a prior <span class="math inline">Beta(4,4)</span> and for data <span class="math inline">k = 140, n = 200</span>, we’d have the same posterior: <span class="math inline">\mathit{Beta}(4+140,4+200-140)=\mathit{Beta}(144,64)</span></li>
</ul></li>
<li><p>so, we can keep building on our previous findings to inform future priors</p></li>
</ul>
</section>
<section id="summary" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="summary"><span class="header-section-number">2.10</span> Summary</h2>
<ul>
<li>we’ll continue down the same path we followed in this chapter moving forward:
<ol type="1">
<li>decide on an appropriate likelihood function</li>
<li>decide on prior for all the parameters involved in the likelihood function</li>
<li>using this model (the likelihood and the priors) derive the posterior distribution of each parameter</li>
<li>draw inferences about our research question basedon the posterior distribution of the parameter</li>
</ol></li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>